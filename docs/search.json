[
  {
    "objectID": "session.html",
    "href": "session.html",
    "title": "セッション情報",
    "section": "",
    "text": "R version 4.2.2 (2022-10-31)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] gt_0.8.0        forcats_0.5.2   stringr_1.5.0   dplyr_1.0.10   \n [5] purrr_0.3.5     readr_2.1.3     tidyr_1.2.1     tibble_3.1.8   \n [9] ggplot2_3.4.0   tidyverse_1.3.2\n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.0    xfun_0.35           haven_2.5.1        \n [4] gargle_1.2.1        colorspace_2.0-3    vctrs_0.5.1        \n [7] generics_0.1.3      htmltools_0.5.3     yaml_2.3.6         \n[10] utf8_1.2.2          rlang_1.0.6         pillar_1.8.1       \n[13] withr_2.5.0         glue_1.6.2          DBI_1.1.3          \n[16] dbplyr_2.2.1        readxl_1.4.1        modelr_0.1.10      \n[19] lifecycle_1.0.3     munsell_0.5.0       gtable_0.3.1       \n[22] cellranger_1.1.0    rvest_1.0.3         htmlwidgets_1.5.4  \n[25] evaluate_0.18       knitr_1.41          tzdb_0.3.0         \n[28] fastmap_1.1.0       fansi_1.0.3         broom_1.0.1        \n[31] backports_1.4.1     scales_1.2.1        googlesheets4_1.0.1\n[34] jsonlite_1.8.3      fs_1.5.2            hms_1.1.2          \n[37] digest_0.6.30       stringi_1.7.8       grid_4.2.2         \n[40] cli_3.4.1           tools_4.2.2         magrittr_2.0.3     \n[43] pacman_0.5.1        crayon_1.5.2        pkgconfig_2.0.3    \n[46] ellipsis_0.3.2      xml2_1.3.3          reprex_2.0.2       \n[49] googledrive_2.0.0   lubridate_1.9.0     timechange_0.1.1   \n[52] assertthat_0.2.1    rmarkdown_2.18      httr_1.4.4         \n[55] rstudioapi_0.14     R6_2.5.1            compiler_4.2.2"
  },
  {
    "objectID": "session.html#packages",
    "href": "session.html#packages",
    "title": "セッション情報",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\n  \n  \n    \n      Package\n      Version\n    \n  \n  \n    abind\n1.4-5\n    AER\n1.2-10\n    aod\n1.3.2\n    arm\n1.13-1\n    AsioHeaders\n1.22.1-1\n    askpass\n1.1\n    assertthat\n0.2.1\n    attempt\n0.3.1\n    backports\n1.4.1\n    BalanceR\n0.7.7\n    base\n4.2.2\n    base64enc\n0.1-3\n    bayestestR\n0.13.0\n    beautifyR\n0.3.1\n    BH\n1.78.0-0\n    bibtex\n0.5.0\n    bigD\n0.2.0\n    bit\n4.0.5\n    bit64\n4.0.5\n    bitops\n1.0-7\n    blob\n1.2.3\n    blogdown\n1.15\n    bookdown\n0.30\n    Boom\n0.9.11\n    BoomSpikeSlab\n1.2.5\n    boot\n1.3-28.1\n    brew\n1.0-8\n    brio\n1.1.3\n    broom\n1.0.1\n    broom.helpers\n1.10.0\n    bslib\n0.4.1\n    bsts\n0.9.9\n    cachem\n1.0.6\n    callr\n3.7.3\n    car\n3.1-1\n    carData\n3.0-5\n    CausalImpact\n1.3.0\n    cellranger\n1.1.0\n    checkmate\n2.1.0\n    chromote\n0.1.1\n    cjoint\n2.1.0\n    class\n7.3-20\n    classInt\n0.4-8\n    cli\n3.4.1\n    clipr\n0.8.0\n    cluster\n2.1.4\n    cobalt\n4.4.1\n    coda\n0.19-4\n    codetools\n0.2-18\n    collections\n0.3.6\n    colorspace\n2.0-3\n    colourpicker\n1.2.0\n    commonmark\n1.8.1\n    compiler\n4.2.2\n    config\n0.3.1\n    corpcor\n1.6.10\n    corrplot\n0.92\n    countrycode\n1.4.0\n    cowplot\n1.1.1\n    cpp11\n0.4.3\n    cranlogs\n2.1.1\n    crayon\n1.5.2\n    credentials\n1.3.2\n    cregg\n0.4.0\n    crosstalk\n1.2.0\n    crul\n1.3\n    cshapes\n2.0\n    curl\n4.3.3\n    cyclocomp\n1.1.0\n    dad\n4.0.0\n    dagitty\n0.3-1\n    data.table\n1.14.6\n    data.tree\n1.0.0\n    DataCombine\n0.2.21\n    datasets\n4.2.2\n    datawizard\n0.6.4\n    DBI\n1.1.3\n    dbplyr\n2.2.1\n    dcurver\n0.9.2\n    deldir\n1.0-6\n    democracyData\n0.3.0\n    dendextend\n1.16.0\n    Deriv\n4.1.3\n    desc\n1.4.2\n    DescTools\n0.99.47\n    devtools\n2.4.5\n    diffobj\n0.3.5\n    digest\n0.6.30\n    directlabels\n2021.1.13\n    doMC\n1.3.8\n    doParallel\n1.0.17\n    doRNG\n1.8.2\n    downlit\n0.4.2\n    dplyr\n1.0.10\n    DT\n0.26\n    dtplyr\n1.2.2\n    e1071\n1.7-12\n    ellipsis\n0.3.2\n    estimatr\n1.0.0\n    evaluate\n0.18\n    Exact\n3.2\n    expm\n0.999-6\n    extrafont\n0.18\n    extrafontdb\n1.0\n    fansi\n1.0.3\n    farver\n2.1.1\n    fastDummies\n1.6.3\n    fastmap\n1.1.0\n    FNN\n1.1.3.1\n    fontawesome\n0.4.0\n    forcats\n0.5.2\n    foreach\n1.5.2\n    foreign\n0.8-83\n    formatR\n1.12\n    formattable\n0.2.1\n    Formula\n1.2-4\n    fs\n1.5.2\n    future\n1.29.0\n    fuzzyjoin\n0.1.6\n    gamlss.dist\n6.0-5\n    gapminder\n0.3.0\n    gargle\n1.2.1\n    gdtools\n0.2.4\n    generics\n0.1.3\n    geojson\n0.3.4\n    geojsonio\n0.10.0\n    geojsonlint\n0.4.0\n    geojsonsf\n2.0.3\n    geometries\n0.2.0\n    geosphere\n1.5-18\n    gert\n1.9.2\n    ggalluvial\n0.12.3\n    GGally\n2.1.2\n    gganimate\n1.0.8\n    ggbump\n0.1.0\n    ggdag\n0.2.7\n    ggdendro\n0.1.23\n    ggExtra\n0.10.0\n    ggfittext\n0.9.1\n    ggforce\n0.4.1\n    ggh4x\n0.2.3\n    gghighlight\n0.4.0\n    ggmosaic\n0.3.3\n    ggplot2\n3.4.0\n    ggpubr\n0.5.0\n    ggraph\n2.1.0\n    ggrepel\n0.9.2\n    ggridges\n0.5.4\n    ggsci\n2.9\n    ggsignif\n0.6.4\n    ggstance\n0.3.6\n    gh\n1.3.1\n    ghibli\n0.3.3\n    gitcreds\n0.1.2\n    gld\n2.6.6\n    globals\n0.16.2\n    glue\n1.6.2\n    golem\n0.3.5\n    googledrive\n2.0.0\n    googlePolylines\n0.8.2\n    googlesheets4\n1.0.1\n    GPArotation\n2022.10-2\n    graphics\n4.2.2\n    graphlayouts\n0.8.4\n    grDevices\n4.2.2\n    grid\n4.2.2\n    gridExtra\n2.3\n    gsynth\n1.2.1\n    gt\n0.8.0\n    gtable\n0.3.1\n    gtsummary\n1.6.2\n    haven\n2.5.1\n    here\n1.0.1\n    highr\n0.9\n    Hmisc\n4.7-2\n    hms\n1.1.2\n    hrbrthemes\n0.8.0\n    htmlTable\n2.4.1\n    htmltools\n0.5.3\n    htmlwidgets\n1.5.4\n    httpcode\n0.3.0\n    httpuv\n1.6.6\n    httr\n1.4.4\n    icons\n0.2.0\n    ids\n1.0.1\n    igraph\n1.3.5\n    ini\n0.3.1\n    inline\n0.3.19\n    insight\n0.18.8\n    interactionTest\n1.2\n    interp\n1.1-3\n    interplot\n0.2.3\n    isoband\n0.2.6\n    ISOcodes\n2022.09.29\n    iterators\n1.0.14\n    jpeg\n0.1-10\n    jpmesh\n2.1.0\n    jpndistrict\n0.3.9.9000\n    jqr\n1.2.3\n    jquerylib\n0.1.4\n    jsonify\n1.2.2\n    jsonlite\n1.8.3\n    jsonvalidate\n1.3.2\n    juicyjuice\n0.1.0\n    kableExtra\n1.3.4\n    keras\n2.9.0\n    kernlab\n0.9-31\n    KernSmooth\n2.23-20\n    kldtools\n1.2\n    knitr\n1.41\n    labeling\n0.4.2\n    labelled\n2.10.0\n    languageserver\n0.3.14\n    later\n1.3.0\n    latex2exp\n0.9.6\n    lattice\n0.20-45\n    latticeExtra\n0.6-30\n    lazyeval\n0.2.2\n    leaflet\n2.1.1\n    leaflet.providers\n1.9.0\n    learnr\n0.11.2\n    lfe\n2.8-8\n    lifecycle\n1.0.3\n    lintr\n3.0.2\n    list\n9.2.4\n    listenv\n0.8.0\n    lme4\n1.1-31\n    lmom\n2.9\n    lmtest\n0.9-40\n    lobstr\n1.1.2\n    loo\n2.5.1\n    LowRankQP\n1.0.5\n    lpdensity\n2.3.2\n    lubridate\n1.9.0\n    magic\n1.6-1\n    magick\n2.7.3\n    magrittr\n2.0.3\n    mapproj\n1.2.9\n    maps\n3.4.1\n    maptools\n1.1-5\n    marginaleffects\n0.8.1\n    margins\n0.3.26\n    markdown\n1.4\n    MASS\n7.3-58.1\n    MatchIt\n4.5.0\n    Matrix\n1.5-3\n    MatrixModels\n0.5-1\n    matrixStats\n0.63.0\n    memoise\n2.0.1\n    metathis\n1.1.2\n    methods\n4.2.2\n    mgcv\n1.8-41\n    mime\n0.12\n    miniUI\n0.1.1.1\n    minqa\n1.2.5\n    mirt\n1.37.1\n    mitools\n2.4\n    modelr\n0.1.10\n    modelsummary\n1.2.0\n    munsell\n0.5.0\n    mvtnorm\n1.1-3\n    naniar\n0.6.1\n    nlme\n3.1-160\n    nloptr\n2.0.3\n    nnet\n7.3-18\n    norm\n1.0-10.0\n    numDeriv\n2016.8-1.1\n    openssl\n2.0.5\n    openxlsx\n4.2.5.1\n    optimx\n2022-4.30\n    packageRank\n0.7.2\n    packrat\n0.8.1\n    pacman\n0.5.1\n    pagedown\n0.19\n    pander\n0.6.5\n    panelView\n1.1.11\n    parallel\n4.2.2\n    parallelly\n1.32.1\n    parameters\n0.20.0\n    parsedate\n1.3.1\n    pbapply\n1.6-0\n    pbkrtest\n0.5.1\n    performance\n0.10.1\n    permute\n0.9-7\n    pillar\n1.8.1\n    pkgbuild\n1.4.0\n    pkgconfig\n2.0.3\n    pkgdown\n2.0.6\n    pkgload\n1.3.2\n    pkgsearch\n3.1.2\n    plotly\n4.10.1\n    plyr\n1.8.8\n    png\n0.1-8\n    polyclip\n1.10-4\n    polynom\n1.4-1\n    ppcor\n1.1\n    praise\n1.0.0\n    PRcalc\n0.7.0\n    prediction\n0.3.14\n    prettyunits\n1.1.1\n    prismatic\n1.1.1\n    processx\n3.8.0\n    productplots\n0.1.1\n    profvis\n0.3.7\n    progress\n1.2.2\n    promises\n1.2.0.1\n    protolite\n2.1.3\n    proxy\n0.4-27\n    pryr\n0.1.5\n    ps\n1.7.2\n    psData\n0.2.2\n    purrr\n0.3.5\n    q2c\n0.2.0\n    qrcode\n0.2.0\n    quadprog\n1.5-8\n    qualtRics\n3.1.7\n    quantreg\n5.94\n    quarto\n1.2\n    R.cache\n0.16.0\n    R.methodsS3\n1.8.2\n    R.oo\n1.25.0\n    R.utils\n2.12.2\n    R6\n2.5.1\n    R7\n0.0.0.9000\n    ragg\n1.2.4\n    rapidjsonr\n1.2.0\n    rappdirs\n0.3.3\n    rapportools\n1.1\n    raster\n3.6-11\n    rcmdcheck\n1.4.0\n    RColorBrewer\n1.1-3\n    Rcpp\n1.0.9\n    RcppArmadillo\n0.11.4.2.1\n    RcppEigen\n0.3.3.9.3\n    RcppParallel\n5.1.5\n    RcppProgress\n0.4.2\n    RcppTOML\n0.1.7\n    RCurl\n1.98-1.9\n    rdd\n0.57\n    rddensity\n2.3\n    rdrobust\n2.1.1\n    readr\n2.1.3\n    readxl\n1.4.1\n    RefManageR\n1.4.0\n    rematch\n1.0.1\n    rematch2\n2.1.2\n    remotes\n2.4.2\n    renv\n0.16.0\n    reprex\n2.0.2\n    reshape\n0.8.9\n    reshape2\n1.4.4\n    reticulate\n1.26\n    rex\n1.2.1\n    rgenoud\n5.9-0.3\n    rgeos\n0.5-9\n    rio\n0.5.29\n    rJava\n1.0-6\n    rlang\n1.0.6\n    rmapshaper\n0.4.6\n    rmarkdown\n2.18\n    rmdja\n0.4.6.9\n    rnaturalearth\n0.1.0\n    rnaturalearthdata\n0.1.0\n    rnaturalearthhires\n0.2.0\n    rngtools\n1.5.2\n    rootSolve\n1.8.2.3\n    roxygen2\n7.2.2\n    rpart\n4.1.19\n    rprojroot\n2.0.3\n    rqog\n0.4.2022\n    rsconnect\n0.8.28\n    rstan\n2.21.7\n    rstatix\n0.7.1\n    rstudioapi\n0.14\n    Rttf2pt1\n1.3.11\n    rversions\n2.1.2\n    rvest\n1.0.3\n    s2\n1.1.1\n    sandwich\n3.0-2\n    sass\n0.4.4\n    scales\n1.2.1\n    selectr\n0.4-2\n    servr\n0.25\n    sessioninfo\n1.2.2\n    sf\n1.0-9\n    sfheaders\n0.4.0\n    shades\n1.4.0\n    shiny\n1.7.3\n    shiny.i18n\n0.2.0\n    shinyBS\n0.61.1\n    shinyjs\n2.1.0\n    SimpleConjoint\n0.1.1\n    sjlabelled\n1.2.0\n    sourcetools\n0.1.7\n    sp\n1.5-1\n    SparseM\n1.81\n    spatial\n7.3-15\n    splines\n4.2.2\n    StanHeaders\n2.21.0-7\n    stargazer\n5.2.3\n    stats\n4.2.2\n    stats4\n4.2.2\n    stringdist\n0.9.10\n    stringi\n1.7.8\n    stringr\n1.5.0\n    styler\n1.8.1\n    sugrrants\n0.2.8\n    summarytools\n1.0.1\n    survey\n4.1-1\n    survival\n3.4-0\n    svglite\n2.1.0\n    Synth\n1.1-6\n    sys\n3.4.1\n    systemfonts\n1.0.4\n    tables\n0.9.10\n    tcltk\n4.2.2\n    tcltk2\n1.2-11\n    tensorflow\n2.9.0\n    terra\n1.6-47\n    testthat\n3.1.5\n    textshaping\n0.3.6\n    tfautograph\n0.3.2\n    tfprobability\n0.15.1\n    tfruns\n1.5.1\n    tibble\n3.1.8\n    tidyfast\n0.2.1\n    tidygraph\n1.2.2\n    tidyr\n1.2.1\n    tidyselect\n1.2.0\n    tidyverse\n1.3.2\n    timechange\n0.1.1\n    tinytex\n0.42\n    titanic\n0.1.0\n    tools\n4.2.2\n    treemapify\n2.5.5\n    triebeard\n0.3.0\n    tweenr\n2.0.2\n    tzdb\n0.3.0\n    units\n0.8-0\n    UpSetR\n1.4.0\n    urlchecker\n1.0.1\n    urlshorteneR\n1.5.7\n    urltools\n1.7.3\n    usethis\n2.1.6\n    usmap\n0.6.1\n    usmapdata\n0.1.0\n    utf8\n1.2.2\n    utils\n4.2.2\n    uuid\n1.1-0\n    V8\n4.2.2\n    vctrs\n0.5.1\n    vdemdata\n3.0\n    vegan\n2.6-4\n    VGAM\n1.1-7\n    viridis\n0.6.2\n    viridisLite\n0.4.1\n    visdat\n0.5.3\n    vroom\n1.6.0\n    waldo\n0.4.0\n    webshot\n0.5.4\n    websocket\n1.4.1\n    WeightIt\n0.13.1\n    whisker\n0.4.1\n    withr\n2.5.0\n    wk\n0.7.0\n    woRdle\n0.0.1\n    xaringan\n0.27\n    xaringanBuilder\n0.0.9\n    xaringanExtra\n0.7.0\n    xfun\n0.35\n    xlsx\n0.6.5\n    xlsxjars\n0.6.1\n    xml2\n1.3.3\n    xmlparsedata\n1.0.5\n    xopen\n1.0.0\n    xtable\n1.8-4\n    xts\n0.12.2\n    yaml\n2.3.6\n    zeallot\n0.1.0\n    zip\n2.2.2\n    zoo\n1.8-11"
  },
  {
    "objectID": "slide/did.html#マッチングの限界",
    "href": "slide/did.html#マッチングの限界",
    "title": "社会科学における因果推論",
    "section": "マッチングの限界",
    "text": "マッチングの限界\n条件付き独立の仮定 (Conditional Independent Assumption; CIA)\n\n処置変数 (T) と結果変数 (Y) の間に存在する交絡要因 (X) が全て観察されている場合\n\n\\({Y_i (T_i = 1), Y_i (T_i = 0) \\perp T_i | X_i}\\)\n\\(\\rightarrow\\) 交絡変数を共変量として統制する場合、観察データからも因果効果の推定が可能\n\nしかし、全ての交絡要因がデータに含まれる場合もほぼゼロ\n\n\\(\\rightarrow\\) 仮定としては強すぎるため、(回帰分析を含む) マッチングによる厳密な因果推論は困難\nただし、単純に処置変数と結果変数の単回帰分析よりは望ましい。\n\nより緩い仮定の下で可能な因果推論の手法\n\n\\(\\rightarrow\\) 自然実験 (Natural Experiment)"
  },
  {
    "objectID": "slide/did.html#自然実験とは",
    "href": "slide/did.html#自然実験とは",
    "title": "社会科学における因果推論",
    "section": "自然実験とは",
    "text": "自然実験とは\nRCTの3つの特徴 (Freedman, Pisani, and Purves 2007)\n\nThe response of experimental subjects assigned to receive a treatment is compared to the response of subjects assigned to a control group.\nThe assignment of subjects to treatment and control groups is done at random, through a randomizing device such as a coin flip.\nThe manipulation of the treatment—also known as the intervention—is under the control of an experimental researcher.\n\n\n自然実験は (Dunning 2012)\n\n同じ\n処置の有無は無作為のように決まる (as-if random)。\n処置内容などを研究者が操作することは不可能\n\n2と3は自然、制度などによって影響を受ける"
  },
  {
    "objectID": "slide/did.html#自然実験の例",
    "href": "slide/did.html#自然実験の例",
    "title": "社会科学における因果推論",
    "section": "自然実験の例",
    "text": "自然実験の例\n処置を受けるか否かが自然、制度、偶然などによって規定される\n\n多数代表制と比例代表制\n\n人口3500未満なら多数代表制、以上なら比例代表制を採用 (フランス 地方選挙)\n\n軍の経験と所得\n\nベトナム戦争時、徴兵対象がくじによって決まる (アメリカ)\n\n最低賃金の効果\n\n隣接するペンシルベニア州とニュージャージー州の最低賃金の格差\n\n現職効果\n\n惜敗・辛勝の場合、候補者間の質には大差ないはず\n\n選挙区定数の効果\n\n人口によって選挙区定数が決まる\n\nその他"
  },
  {
    "objectID": "slide/did.html#自然実験の方法",
    "href": "slide/did.html#自然実験の方法",
    "title": "社会科学における因果推論",
    "section": "自然実験の方法",
    "text": "自然実験の方法\n本講義では1と2を解説\n\n差分の差分法 (Difference-in-Difference; Diff-in-Diff/DID/DD)\n回帰不連続デザイン (Regression Discontinuity Design; RDD)\n\n中断時系列デザイン (Interrupted Time-series Design; ITS)\n\nRDDの時系列版であるが、自己相関などの対処が必要であるため本講義では省略\n\n\n操作変数 (Instrumental Variable; IV)\n集積分析 (Bunching Analysis)\nその他"
  },
  {
    "objectID": "slide/did.html#保育所の整備と母の就労率-1",
    "href": "slide/did.html#保育所の整備と母の就労率-1",
    "title": "社会科学における因果推論",
    "section": "保育所の整備と母の就労率 (1)",
    "text": "保育所の整備と母の就労率 (1)\nX軸：\\(\\frac{\\mbox{認可保育所定員}}{\\mbox{5歳以下子供数}}\\)；Y軸：女性の就労率（元ネタ: Asai, Kambayashi, and Yamaguchi (2015) / データは宋が収集）"
  },
  {
    "objectID": "slide/did.html#保育所の整備と母の就労率-2",
    "href": "slide/did.html#保育所の整備と母の就労率-2",
    "title": "社会科学における因果推論",
    "section": "保育所の整備と母の就労率 (2)",
    "text": "保育所の整備と母の就労率 (2)\n保育所が整備されると母は安心して働けるから就労率が上がる\n\n\n\nロジックとして問題はなさそう\n内生性は?\n\n(たとえば、)「県民性」の存在\n母親の就業意識が高く、地域社会もこの意識に好意的なら …\n\n\\(\\rightarrow\\) 就労率が上がる\n\\(\\rightarrow\\) 政治・行政も支持拡大のために保育所整備に力を入れる"
  },
  {
    "objectID": "slide/did.html#差分の差分法",
    "href": "slide/did.html#差分の差分法",
    "title": "社会科学における因果推論",
    "section": "差分の差分法",
    "text": "差分の差分法\nDifference in Difference (Diff-in-Diff, DID, DD)\n\n同一対象に対して複数の観測が前提\n\n保育所の整備と母の就労率を47都道府県に対して4回 (2000, 2005, 2010, 2015年) 観察\n「パネルデータ」\n\n個々の有権者を対象にした場合、パネルデータの収集は高費用\n\n日本の政治学だとJESが代表的\n\n国、自治体、選挙区、団体は集計データが整備され、公表されているため利用しやすい"
  },
  {
    "objectID": "slide/did.html#タバコの値段と消費量",
    "href": "slide/did.html#タバコの値段と消費量",
    "title": "社会科学における因果推論",
    "section": "タバコの値段と消費量",
    "text": "タバコの値段と消費量\n元ネタはカルフォルニア州のProposition99\n\n\\(t+1\\)期において、A州のみタバコの値上げ\n\\(t\\)期におけるA州のタバコ消費量(箱/人)：15\n\\(t+1\\)期におけるA州のタバコ消費量(箱/人)：10\n\n\\(\\rightarrow\\) 値上げ後、タバコの消費量が5箱\\(\\downarrow\\)\n\n\n\n\n実際の分析例は\n\nBreslow, M Johnson. 1993. “California’s Proposition 99 on Tobacco, and its Impact,” Annual Review of Public Health, 14: 585–604.\n他にも Proposition 99 の因果効果に関する研究多数\n\n以下は100%架空データ"
  },
  {
    "objectID": "slide/did.html#タバコの値段と消費量-1",
    "href": "slide/did.html#タバコの値段と消費量-1",
    "title": "社会科学における因果推論",
    "section": "タバコの値段と消費量",
    "text": "タバコの値段と消費量\nタバコ消費量の変化"
  },
  {
    "objectID": "slide/did.html#タバコの値段と消費量-2",
    "href": "slide/did.html#タバコの値段と消費量-2",
    "title": "社会科学における因果推論",
    "section": "タバコの値段と消費量",
    "text": "タバコの値段と消費量\n値上げ後、タバコの消費量が5箱減少\n\n「5箱減」は値上げによる効果か\n\nたまたま全国的な禁煙ブームと重なった?\nA州の喫煙量はもともと減少傾向だったかも?\n\n\\(\\rightarrow\\) 比較対象が必要"
  },
  {
    "objectID": "slide/did.html#b州の登場",
    "href": "slide/did.html#b州の登場",
    "title": "社会科学における因果推論",
    "section": "B州の登場",
    "text": "B州の登場\n値上げを行っていないB州におけるタバコ消費量"
  },
  {
    "objectID": "slide/did.html#潜在的結果枠組みから考える",
    "href": "slide/did.html#潜在的結果枠組みから考える",
    "title": "社会科学における因果推論",
    "section": "潜在的結果枠組みから考える",
    "text": "潜在的結果枠組みから考える\n因果推論の枠組みから考えると …\n\n処置変数（\\(T\\)）：タバコの値上げ\n結果変数（\\(Y\\)）：タバコの消費量\n\\(i\\)：観測単位（人/自治体/国/企業など）\n\\(t\\)：観測時期\n\n\n\n\n\n\n\n\n\n\nID ( \\(i\\) )\n\\(\\quad t \\quad\\)\n\\(\\quad T_{it} \\quad\\)\n\\(\\quad Y_{it} \\quad\\)\n\n\n\n\n1\n1\n0\n15\n\n\n1\n2\n1\n10\n\n\n2\n1\n0\n17\n\n\n2\n2\n0\n15"
  },
  {
    "objectID": "slide/did.html#潜在的結果枠組みから考える-1",
    "href": "slide/did.html#潜在的結果枠組みから考える-1",
    "title": "社会科学における因果推論",
    "section": "潜在的結果枠組みから考える",
    "text": "潜在的結果枠組みから考える\n\n\\(t = 2\\)において処置を受けた場合、\\(Z = 1\\)とする\n\\(Z = 1\\)であるA州の変化量（\\(\\Delta Y_1\\)）：10 − 15 = −5\n\\(Z = 0\\)であるB州の変化量（\\(\\Delta Y_2\\)）：15 − 17 = −2\n\n\n\n\nID（\\(i\\)）\n\\(\\quad Z_{i} \\quad\\)\n\\(\\quad \\Delta Y_{i} \\quad\\)\n\n\n\n\n1\n1\n-5\n\n\n2\n0\n-2"
  },
  {
    "objectID": "slide/did.html#潜在的結果枠組みから考える-2",
    "href": "slide/did.html#潜在的結果枠組みから考える-2",
    "title": "社会科学における因果推論",
    "section": "潜在的結果枠組みから考える",
    "text": "潜在的結果枠組みから考える\n\nA州が処置を受けなかった場合の潜在的結果としてB州のデータを用いる\n因果効果：\\(\\Delta Y(Z = 1) - \\Delta Y(Z = 0)\\)\n\n(−5) − (−2) = −3\n\nタバコ値上げの効果は-3箱\n\n\n\n\n\\(\\quad \\Delta Y(Z = 1) \\quad\\)\n\\(\\quad \\Delta Y(Z = 0) \\quad\\)\n差分\n\n\n\n\n-5\n-2\n-3"
  },
  {
    "objectID": "slide/did.html#潜在的結果枠組みから考える-3",
    "href": "slide/did.html#潜在的結果枠組みから考える-3",
    "title": "社会科学における因果推論",
    "section": "潜在的結果枠組みから考える",
    "text": "潜在的結果枠組みから考える\n数式で表すと\n\\[\\begin{align}\\Delta = & [\\mathbb{E}(Y_{t+1}(Z = 1)) - \\mathbb{E}(Y_t(Z = 1))] \\\\ & - [\\mathbb{E}(Y_{t+1}(Z = 0)) - \\mathbb{E}(Y_t(Z = 0))]\\end{align}\\]\n\n\\(t + 1\\)期に処置を受けたら\\(Z = 1\\)、受けなかったら\\(Z = 0\\)\n\\(t\\)期は誰も処置を受けていない\n\n初期状態は一緒で、一部のユニットだけ処置を受ける"
  },
  {
    "objectID": "slide/did.html#図ならもっと分かりやすい",
    "href": "slide/did.html#図ならもっと分かりやすい",
    "title": "社会科学における因果推論",
    "section": "図なら、もっと分かりやすい",
    "text": "図なら、もっと分かりやすい"
  },
  {
    "objectID": "slide/did.html#並行トレンドの仮定",
    "href": "slide/did.html#並行トレンドの仮定",
    "title": "社会科学における因果推論",
    "section": "並行トレンドの仮定",
    "text": "並行トレンドの仮定\nParallel Trend Assumption\n\n差分の差分法から推定された値が因果効果になるための前提\n\nA州が値上げしなかったらB州並に消費量が減っただろうというのが前提\n\n処置を受けたユニットが、もし処置を受けなかった場合、結果変数の変化は統制群の変化と一致する\n\n処置群の潜在的結果は観測された統制群の動きと並行する\n= A州が値上げしなかったら、B州のように2箱減に留まる"
  },
  {
    "objectID": "slide/did.html#並行トレンドの仮定どう確認するか",
    "href": "slide/did.html#並行トレンドの仮定どう確認するか",
    "title": "社会科学における因果推論",
    "section": "並行トレンドの仮定:どう確認するか",
    "text": "並行トレンドの仮定:どう確認するか\n一般的に2つの方法\n\n他の処置群や統制群を見つけて追加する\n\n同じく値上げをしていないC州を追加\n\n3期以上のデータを用意する\n\n\\(t − 1\\)期のデータも投入する\nむろん、\\(t − 1\\)期のA州は値上げ前\n\n上記2つの方法を組み合わせる\n\n実質的にはこれがメイン"
  },
  {
    "objectID": "slide/did.html#統制群を増やしてみた",
    "href": "slide/did.html#統制群を増やしてみた",
    "title": "社会科学における因果推論",
    "section": "統制群を増やしてみた",
    "text": "統制群を増やしてみた\n並行トレンドの仮定が満たされている場合 \\(\\rightarrow\\) どの州を潜在的結果として使ってもOK"
  },
  {
    "objectID": "slide/did.html#統制群を増やしてみた-1",
    "href": "slide/did.html#統制群を増やしてみた-1",
    "title": "社会科学における因果推論",
    "section": "統制群を増やしてみた",
    "text": "統制群を増やしてみた\n並行トレンドの仮定が満たされていない場合 \\(\\rightarrow\\) どの州を潜在的結果として用いるか"
  },
  {
    "objectID": "slide/did.html#t1のデータを入れてみた",
    "href": "slide/did.html#t1のデータを入れてみた",
    "title": "社会科学における因果推論",
    "section": "\\(t−1\\)のデータを入れてみた",
    "text": "\\(t−1\\)のデータを入れてみた\n並行トレンドの仮定が満たされている場合"
  },
  {
    "objectID": "slide/did.html#t1のデータを入れてみた-1",
    "href": "slide/did.html#t1のデータを入れてみた-1",
    "title": "社会科学における因果推論",
    "section": "\\(t−1\\)のデータを入れてみた",
    "text": "\\(t−1\\)のデータを入れてみた\n並行トレンドの仮定が満たされていない場合 (1) \\(\\rightarrow\\) 潜在的結果は15、または13"
  },
  {
    "objectID": "slide/did.html#t1のデータを入れてみた-2",
    "href": "slide/did.html#t1のデータを入れてみた-2",
    "title": "社会科学における因果推論",
    "section": "\\(t−1\\)のデータを入れてみた",
    "text": "\\(t−1\\)のデータを入れてみた\n並行トレンドの仮定が満たされていない場合 (2) \\(\\rightarrow\\) 潜在的結果は10、または13"
  },
  {
    "objectID": "slide/did.html#回帰分析による差分の差分法",
    "href": "slide/did.html#回帰分析による差分の差分法",
    "title": "社会科学における因果推論",
    "section": "回帰分析による差分の差分法",
    "text": "回帰分析による差分の差分法\nデータが2期のみ（\\(t \\in \\{0, 1\\}\\)）の場合\n\\[\\hat{Y} = \\beta_0 + \\beta_1 T + \\beta_2 \\mbox{POST} + \\delta T \\cdot \\mbox{Post}\\]\n\nT: 処置群か否か\nPOST: 処置が行われた後か否か\nY: 結果変数\n\n\n\n\nID\nName\nPOST\nT\nY\n\n\n\n\n1\nA州\n0\n1\n15\n\n\n2\nA州\n1\n1\n10\n\n\n3\nB州\n0\n0\n17\n\n\n4\nB州\n1\n0\n15"
  },
  {
    "objectID": "slide/did.html#回帰分析による差分の差分法-1",
    "href": "slide/did.html#回帰分析による差分の差分法-1",
    "title": "社会科学における因果推論",
    "section": "回帰分析による差分の差分法",
    "text": "回帰分析による差分の差分法\nデータが2期のみ（\\(t \\in \\{0, 1\\}\\)）の場合\n\\[\\hat{Y} = \\beta_0 + \\beta_1 T + \\beta_2 \\mbox{POST} + \\delta T \\cdot \\mbox{Post}\\]\n\n処置群の差分：\\(\\hat{Y}(T = 1, POST = 1) − \\hat{Y}(T = 1,POST = 0)\\)\n\n\\(\\beta_2 + \\delta = \\underbrace{(\\beta_0 + \\beta_1 + \\beta_2 + \\delta)}_{\\hat{Y}(T = 1, POST = 1)} - \\underbrace{(\\beta_0 + \\beta_1)}_{\\hat{Y}(T = 1,POST = 0)}\\)\n\n統制群の差分：\\(\\hat{Y}(T = 0, POST = 1) − \\hat{Y}(T = 0,POST = 0)\\)\n\n\\(\\beta_2 = \\underbrace{(\\beta_0 + \\beta_2)}_{\\hat{Y}(T = 0, POST = 1)} - \\underbrace{(\\beta_0)}_{\\hat{Y}(T = 0,POST = 0)}\\)\n\n差分の差分：\\(\\delta = (\\beta_2 + \\delta) - \\beta_2\\)\n\n\\(\\delta\\)：処置効果"
  },
  {
    "objectID": "slide/did.html#一般化された回帰モデル",
    "href": "slide/did.html#一般化された回帰モデル",
    "title": "社会科学における因果推論",
    "section": "一般化された回帰モデル",
    "text": "一般化された回帰モデル\n先ほどのモデルの限界\n\n期間が2期のみ\n\n実際にはもっとデータがあるはず\n\n観察されたユニットが2個 (A州とB州)のみ\n\n実際にはもっとデータがあるはず\n\n処置変数が {0, 1} のバイナリー変数\n\n保育所整備の例の場合、処置変数は連続変数（\\(T = [0, 1]\\)）\n\n\n\n以下では、保育所整備の例で解説"
  },
  {
    "objectID": "slide/did.html#一般化された回帰モデル-1",
    "href": "slide/did.html#一般化された回帰モデル-1",
    "title": "社会科学における因果推論",
    "section": "一般化された回帰モデル",
    "text": "一般化された回帰モデル\nより一般化されたモデル\n\\[\\hat{Y}_{pt} = \\beta + \\delta \\mbox{Treat}_{pt} + \\sum_{k = \\mbox{Aomori}}^{\\mbox{Okinawa}}\\gamma_k \\cdot \\mbox{Pref}_{kp} + \\sum_{j = 2005}^{2015} \\psi_j \\cdot \\mbox{Year}_{jt}\\]\n\n\\(Y_{pt}\\)：\\(t\\)期における\\(p\\)県の女性就労率（\\(= [0, 1]\\)）\n\\(\\mbox{Treat}_{pt}\\)：\\(t\\)期における \\(p\\)県の保育所の整備率（\\(= [0, 1]\\)）\n\\(\\mbox{Pref}_p\\)：\\(p\\)県か否かを表す各都道府県ダミー変数（\\(\\in \\{0, 1\\}\\)）\n\\(\\mbox{Year}_t\\)：\\(t\\)期か否かわ表す年ダミー変数（\\(\\in \\{0, 1\\}\\)）\n\n\n\n標準誤差はクラスター標準誤差を使用\n\n上記の例だと、都道府県単位でクラスター化"
  },
  {
    "objectID": "slide/did.html#一般化された回帰モデル-2",
    "href": "slide/did.html#一般化された回帰モデル-2",
    "title": "社会科学における因果推論",
    "section": "一般化された回帰モデル",
    "text": "一般化された回帰モデル\n単回帰分析と差分の差分法推定量の比較\n\n保育所の整備率と母の就労率の間に統計的有意な関係が見られない\n\n\n\n\n\n \n  \n      \n    Model 1 \n    Model 2 \n  \n \n\n  \n    保育所の整備率 \n    0.358 \n    −0.003 \n  \n  \n     \n    (0.022) \n    (0.030) \n  \n  \n    Num.Obs. \n    188 \n    188 \n  \n  \n    R2 \n    0.510 \n    0.987 \n  \n  \n    R2 Adj. \n    0.508 \n    0.982 \n  \n  \n    AIC \n    −640.9 \n    −1222.7 \n  \n  \n    BIC \n    −631.2 \n    −1054.4 \n  \n  \n    RMSE \n    0.04 \n    0.007 \n  \n  \n    Std.Errors \n     \n    by: Pref_J \n  \n  \n    都道府県ダミー \n    X \n    O \n  \n  \n    年ダミー \n    X \n    O"
  },
  {
    "objectID": "slide/did.html#平行トレンドは",
    "href": "slide/did.html#平行トレンドは",
    "title": "社会科学における因果推論",
    "section": "平行トレンドは?",
    "text": "平行トレンドは?\n回帰モデルでも平行トレンドの仮定は必要\n\n処置変数がバイナリー変数なら平行トレンドの仮定が満たされているか否かを可視化可能\n\n例) 電子投票の導入と投票率 (京都市)"
  },
  {
    "objectID": "slide/did.html#平行トレンドは-1",
    "href": "slide/did.html#平行トレンドは-1",
    "title": "社会科学における因果推論",
    "section": "平行トレンドは?",
    "text": "平行トレンドは?\n回帰モデルでも平行トレンドの仮定は必要\n\n処置変数が連続変数の場合、平行トレンドの仮定を視覚的に確認することは困難\n都道府県ダミーと年ダミー変数を投入したということは…\n\n都道府県ごとに切片のみが異なる\n各年の就労率の変動は全都道府県で共通\n= 平行トレンド\n\n\n\n\n都道府県ごとに切片だけでなく、異なる傾きまで許容するモデル\n\nトレンド変数の投入\n\n簡単だが、都道府県ごとのトレンド効果が線形という仮定\n\n都道府県レベルの共変量の投入\n\n柔軟だが、適切な共変量の発見が重要"
  },
  {
    "objectID": "slide/did.html#トレンド変数",
    "href": "slide/did.html#トレンド変数",
    "title": "社会科学における因果推論",
    "section": "トレンド変数",
    "text": "トレンド変数\n処置を受けていない場合も、傾きが都道府県ごとに異なる場合\n\n都道府県ダミーとトレンド変数 (連続変数としての年など) の交差項を投入\n仮定:都道府県間は平行でなくても、都道府県のトレンドは線形\n\n\n\\[\\hat{Y}_{pt} = \\beta + \\delta \\mbox{Treat}_{pt} + \\sum_{k = \\mbox{Aomori}}^{\\mbox{Okinawa}}\\gamma_k \\cdot \\mbox{Pref}_{kp} + \\sum_{j = 2005}^{2015} \\psi_j \\cdot \\mbox{Year}_{jt} + \\sum_{k = \\mbox{Aomori}}^{\\mbox{Okinawa}}\\theta_k (\\mbox{Pref}_{kp} \\cdot t)\\]\n\n\\(t\\): トレンド変数 (2000年: \\(t = 1\\)、2005年: \\(t = 2\\)、…)\n\n\\(\\mbox{Year}_t\\)はダミー変数であるが、トレンド変数は連続変数"
  },
  {
    "objectID": "slide/did.html#トレンド変数-1",
    "href": "slide/did.html#トレンド変数-1",
    "title": "社会科学における因果推論",
    "section": "トレンド変数",
    "text": "トレンド変数\n結果の比較\n\n\n\n\n \n  \n      \n    Model 1 \n    Model 2 \n    Model 3 \n  \n \n\n  \n    保育所の整備率 \n    0.358 \n    −0.003 \n    −0.009 \n  \n  \n     \n    (0.022) \n    (0.030) \n    (0.028) \n  \n  \n    Num.Obs. \n    188 \n    188 \n    188 \n  \n  \n    R2 \n    0.510 \n    0.987 \n    0.997 \n  \n  \n    R2 Adj. \n    0.508 \n    0.982 \n    0.995 \n  \n  \n    AIC \n    −640.9 \n    −1222.7 \n    −1439.2 \n  \n  \n    BIC \n    −631.2 \n    −1054.4 \n    −1122.0 \n  \n  \n    RMSE \n    0.04 \n    0.007 \n    0.003 \n  \n  \n    Std.Errors \n     \n    by: Pref_J \n    by: Pref_J \n  \n  \n    都道府県ダミー \n    X \n    O \n    O \n  \n  \n    年ダミー \n    X \n    O \n    O \n  \n  \n    トレンド変数 \n    X \n    X \n    O"
  },
  {
    "objectID": "slide/did.html#共変量の投入",
    "href": "slide/did.html#共変量の投入",
    "title": "社会科学における因果推論",
    "section": "共変量の投入",
    "text": "共変量の投入\n\n既存のモデルは年度ごとに就労率の伸びは変化するものの、その変化の度合いは全都道府県において共通していると仮定\n景気が良いと母の就労率が上がる\n\nしかし、都道府県ごとに景気変動の度合いは異なることが一般的\n都道府県の失業率など、各都道府県の景気状況を表す変数を投入\n\n\n\\[\\hat{Y}_{pt} = \\beta + \\delta \\mbox{Treat}_{pt} + \\sum_{k = \\mbox{Aomori}}^{\\mbox{Okinawa}}\\gamma_k \\cdot \\mbox{Pref}_{kp} + \\sum_{j = 2005}^{2015} \\psi_j \\cdot \\mbox{Year}_{jt} + \\theta \\mbox{Unemp}_{pt}\\]\n\n\\(\\mbox{Unemp}_{pt}\\) : \\(t\\)期における\\(p\\)県の完全失業率\nトレンド変数は、「同じ都道府県なら、傾きは変わらない」と仮定しているが、共変量を統制する場合、このような仮定は必要としない\n\n適切な共変量の選択はトレンド変数よりも有効\n共変量は母の就労率、保育所の整備率、両方と関係のあるもの"
  },
  {
    "objectID": "slide/did.html#共変量の投入-1",
    "href": "slide/did.html#共変量の投入-1",
    "title": "社会科学における因果推論",
    "section": "共変量の投入",
    "text": "共変量の投入\n結果の比較\n\n\n\n\n \n  \n      \n    Model 1 \n    Model 2 \n    Model 3 \n    Model 4 \n    Model 5 \n  \n \n\n  \n    保育所の整備率 \n    0.358 \n    −0.003 \n    −0.009 \n    0.002 \n    0.003 \n  \n  \n     \n    (0.022) \n    (0.030) \n    (0.028) \n    (0.030) \n    (0.024) \n  \n  \n    Num.Obs. \n    188 \n    188 \n    188 \n    188 \n    188 \n  \n  \n    R2 \n    0.510 \n    0.987 \n    0.997 \n    0.987 \n    0.998 \n  \n  \n    R2 Adj. \n    0.508 \n    0.982 \n    0.995 \n    0.982 \n    0.995 \n  \n  \n    AIC \n    −640.9 \n    −1222.7 \n    −1439.2 \n    −1322.0 \n    −1543.8 \n  \n  \n    BIC \n    −631.2 \n    −1054.4 \n    −1122.0 \n    −1312.3 \n    −1385.2 \n  \n  \n    RMSE \n    0.04 \n    0.007 \n    0.003 \n    0.007 \n    0.003 \n  \n  \n    Std.Errors \n     \n    by: Pref_J \n    by: Pref_J \n    by: Pref_J \n    by: Pref_J \n  \n  \n    都道府県ダミー \n    X \n    O \n    O \n    O \n    O \n  \n  \n    年ダミー \n    X \n    O \n    O \n    O \n    O \n  \n  \n    トレンド変数 \n    X \n    X \n    O \n    X \n    O \n  \n  \n    共変量 \n    X \n    X \n    X \n    O \n    O"
  },
  {
    "objectID": "slide/did.html#結果の比較",
    "href": "slide/did.html#結果の比較",
    "title": "社会科学における因果推論",
    "section": "結果の比較",
    "text": "結果の比較\n処置効果の点推定値と95%信頼区間\n\n保育所の整備が女性の就労率を上げるとは言えない"
  },
  {
    "objectID": "slide/did.html#並行トレンドのチェック",
    "href": "slide/did.html#並行トレンドのチェック",
    "title": "社会科学における因果推論",
    "section": "並行トレンドのチェック",
    "text": "並行トレンドのチェック\n並行トレンドをどう確認するか\n\nより多くの時点のデータを収集し、プロット\n\n検定 (test) ではなく、診断 (diagnostics)\n\nプラセボ・テスト\n\n方法1: \\(t = 3\\)が処置を受けた時期なら、\\(t = 3\\)をデータから除外し、\\(t = 2\\)を処置とコーディングしてDIDを実行 (3期以上のデータが必要)\n方法2: 統制群の一部を処置群とコーディング&処置群をデータから除外してDIDを実行 (3つ以上の対象が必要)\n検定の結果、DID推定量が統計的有意であったら平行トレンドが満たされていないと判断する（並行トレンドの仮定が満たされていることは示せない）"
  },
  {
    "objectID": "slide/did.html#実習用データ",
    "href": "slide/did.html#実習用データ",
    "title": "社会科学における因果推論",
    "section": "実習用データ",
    "text": "実習用データ\nスライドで使ったデータ\n\ndid_data1.csv: 保育所の整備と母の就労率\ndid_data2.csv: 電子投票の導入と投票率\n\n実習用データ\n\ndid_data3.csv: 学校内銃撃事件と政治参加（LMSからダウンロード）\n\nLaura García-Montoya, Ana Arjona, and Matthew Lacombe. 2022. “Violence and Voting in the United States: How School Shootings Affect Elections,” American Political Science Review, 116 (3): 807-826."
  },
  {
    "objectID": "slide/did.html#データの説明",
    "href": "slide/did.html#データの説明",
    "title": "社会科学における因果推論",
    "section": "データの説明",
    "text": "データの説明\nGarcía-Montoya, Arjona, and Lacombe (2022)のFigure 3&4の一部を再現\n\n銃撃事件は前回の選挙から今回の選挙の間に発生した場合1とし、今後続く。\n銃撃事件の深刻さは死者の有無で判定\n\n\n\n\n変数名\n説明\n\n\n\n\ncounty\nカウンティー（郡）のID\n\n\nstate\n州ID\n\n\nyear\n年\n\n\nshooting\n学校内銃撃事件の発生\n\n\nfatal_shooting\n深刻な学校内銃撃事件の発生\n\n\nnon_fatal_shooting\n軽微な学校内銃撃事件の発生\n\n\nturnout\n大統領選挙の投票率\n\n\ndemvote\n民主党候補者の得票率\n\n\npopulation\n人口（カウンティー）\n\n\nnon_white\n非白人の割合（カウンティー）\n\n\nchange_unem_rate\n失業率の変化（カウンティー）"
  },
  {
    "objectID": "slide/did.html#実習内容",
    "href": "slide/did.html#実習内容",
    "title": "社会科学における因果推論",
    "section": "実習内容",
    "text": "実習内容\n\n{estimatr}パッケージ（lm_robust()関数）の使い方\n推定結果の可視化\n\n\n\n\nhttps://www.jaysong.net/kandai-ci"
  },
  {
    "objectID": "slide/intro.html#講義概要-1",
    "href": "slide/intro.html#講義概要-1",
    "title": "社会科学における因果推論",
    "section": "講義概要",
    "text": "講義概要\n\n科目名: 社会科学における因果推論\n講師: 宋財泫 (ソン ジェヒョン)\n所属: 関西大学総合情報学部\n\nE-mail: song [at] kansai-u.ac.jp\nHomepage: https://www.jaysong.net\n\n時間: 月曜日2限（10:40〜12:10）\n教室: TD106"
  },
  {
    "objectID": "slide/intro.html#内容",
    "href": "slide/intro.html#内容",
    "title": "社会科学における因果推論",
    "section": "内容",
    "text": "内容\n\n\n因果推論の考え方\n\n因果推論とは\n内生性（自己選択バイアス）\n因果推論の根本問題\n\n\n因果推論の理論と方法\n\n無作為化比較試験\n回帰分析とその拡張\n\n共変量調整\nマッチング\n差分の差分法\n回帰不連続デザイン\n操作変数法"
  },
  {
    "objectID": "slide/intro.html#実習",
    "href": "slide/intro.html#実習",
    "title": "社会科学における因果推論",
    "section": "実習",
    "text": "実習\n実習はRで行う。4・5回目はRの導入および使い方についても解説（復習レベル）する。\n\n本講義の分析はExcel, SPSS, Stata, Julia, Pythonなどでも可能\n\n\n\n宋のR環境\n\nmacOS 12.5 “Monterey”\nR version 4.2.2 (2022-10-31)\n\nR > 4.1ならOK\n\nRStudio 2022.11.0+105 “Elsbeth Geranium”\nスライド、サポートページ、実習用資料の執筆環境\n\nQuarto 1.2.269\nR package {quarto} 1.2"
  },
  {
    "objectID": "slide/intro.html#前提知識",
    "href": "slide/intro.html#前提知識",
    "title": "社会科学における因果推論",
    "section": "前提知識",
    "text": "前提知識\n第4回講義までに以下の本の内容が理解できていれば問題ない。\n\n浅野正彦・矢内勇生. 2019『Rによる計量政治学』オーム社.\n\n\n\n\n統計学\n\n仮説検定\n統計的有意性検定\n\n\\(p\\)値\\(\\neq\\)帰無仮説が正しい確率\n\n回帰分析\n\n\nR\n\nデータクリーニング、回帰分析、可視化などができるならベスト\n第4・5回にはRの復習を行う\n以下の内容が分かればOK\n\nhttps://www.jaysong.net/micro-book/\n『私たちのR』を読もう！"
  },
  {
    "objectID": "slide/intro.html#サポートページ",
    "href": "slide/intro.html#サポートページ",
    "title": "社会科学における因果推論",
    "section": "サポートページ",
    "text": "サポートページ\n\nhttps://www.jaysong.net/kandai-ci/（ブラウザーの「お気に入り」に登録）"
  },
  {
    "objectID": "slide/intro.html#教科書",
    "href": "slide/intro.html#教科書",
    "title": "社会科学における因果推論",
    "section": "教科書",
    "text": "教科書\n\nなし（サポートページ、およびスライドのみ使用）"
  },
  {
    "objectID": "slide/intro.html#参考書r",
    "href": "slide/intro.html#参考書r",
    "title": "社会科学における因果推論",
    "section": "参考書（R）",
    "text": "参考書（R）\n\n宋財泫・矢内勇生.『私たちのR: ベストプラクティスの探求』（Web-book）\n松村優哉 他. 2021. 『改訂2版 RユーザのためのRStudio[実践]入門』技術評論社\nGarrett Grolemund and Hadley Wickham. 2017. R for Data Science. O’Reilly."
  },
  {
    "objectID": "slide/intro.html#参考書因果推論",
    "href": "slide/intro.html#参考書因果推論",
    "title": "社会科学における因果推論",
    "section": "参考書（因果推論）",
    "text": "参考書（因果推論）\n\n理論\n\n初級: 松林哲也. 2021.『政治学と因果推論』岩波書店.\n初級: Angrist, Joahua D., and Jorn-steffen Pischke. 2014. Mastering ’Metrics: The Path from Cause to Effect. Princeton University Press.\n中級: Angrist, Joahua D., and Jorn-steffen Pischke. 2008. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press.（『「ほとんど無害」な計量経済学―応用経済学のための実証分析ガイド』）\n\n実装\n\nCunningham, Scott. 2021. Causal Inference: The Mixtape. Yale University Press.\n安井翔太. 2020. 『効果検証入門』技術評論社.\n高橋将宜. 2022. 『統計的因果推論の理論と実装』共立出版.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "slide/intro.html#評価-1",
    "href": "slide/intro.html#評価-1",
    "title": "社会科学における因果推論",
    "section": "評価",
    "text": "評価\n期末課題の詳細は学期末（12月頃）アナウンス\n\n平常点: 70%\n\n授業への貢献度\n\n期末課題: 30%\n\n研究構想の発表"
  },
  {
    "objectID": "slide/intro.html#オフィスアワー",
    "href": "slide/intro.html#オフィスアワー",
    "title": "社会科学における因果推論",
    "section": "オフィス・アワー",
    "text": "オフィス・アワー\n宋が研究室に待機し、事前予約なしに相談、質問などが可能な時間\n\n場所：TA227研究室（A棟の2階）\n毎週火曜日3限 (13:00〜14:30)\n上記の時間外は事前予約が必要（メール、対面）\n\n song@kansai-u.ac.jp"
  },
  {
    "objectID": "slide/intro.html#分析環境の準備",
    "href": "slide/intro.html#分析環境の準備",
    "title": "社会科学における因果推論",
    "section": "分析環境の準備",
    "text": "分析環境の準備\n自分のPCにR + RStudioがインストールされている場合\n\nRのバージョンが4.1.2以上であればOK\n\n\n自分のPCにR + RStudioがインストールされていない場合\n\\(\\Rightarrow\\) 少しでも不安があれば宋と相談しよう！\n\n\n方法1: 自分のPCにインストールする。\n\n参考資料: https://yukiyanai.github.io/jp/resources/\n\n\n方法2: クラウド版のR/RStudioを使用する。\n\n参考資料: サポートページ > Rの使い方\n\n\n\n\n\n\nhttps://www.jaysong.net/kandai-ci"
  },
  {
    "objectID": "slide/rct.html#信頼できるateの条件",
    "href": "slide/rct.html#信頼できるateの条件",
    "title": "社会科学における因果推論",
    "section": "信頼できるATEの条件",
    "text": "信頼できるATEの条件\n内生性の存在 \\(\\rightarrow\\) ATE推定値の信頼性\\(\\downarrow\\)\n例) やる気のある学生だけがソンさんの講義を履修した場合\n\n自己選択バイアス\n\nソンさんの講義は鬼畜すぎるため、やる気満々の学生には役に立つものの、やる気のない学生にとってはむしろ学習意欲が低下\n\n疑似相関\n\nやる気のある学生はいろんな方面で頑張るから、将来年収が高くなる。\n\n測定誤差\n\n履修者の年収はジンバブエ・ドルで測定されている可能性も（これはないか）\n\n\n\n\n内生性は因果推論の敵! どうすれば…?\n\\(\\downarrow\\)\n無作為割当 (Random Assignment)"
  },
  {
    "objectID": "slide/rct.html#無作為割当とは",
    "href": "slide/rct.html#無作為割当とは",
    "title": "社会科学における因果推論",
    "section": "無作為割当とは",
    "text": "無作為割当とは\n無作為割当 (Random Assignment)\n\n処置を受けるかどうかを無作為に割り当てる方法\n\n完全無作為割当: 全ての被験者において、どのグループに属するかの確率が等しい\n\\(Pr(T_i = 1) = Pr(T_j = 1) \\text{ where } i \\neq j\\)\n\\(Pr(T_i = 0) = Pr(T_j = 0) \\text{ where } i \\neq j\\)\n無作為割当の方法は色々\n\n無作為に割り当てると、処置を受けないグループと処置を受けるグループは「集団」として同質なグループになる。\n\n受けないグループ: 統制群 (Control Group)\n受けるグループ: 処置群 (Treatment Group)\n\n一つの集団を一人の個人として扱い、ITEを測定 ⇒ ATE"
  },
  {
    "objectID": "slide/rct.html#無作為割当の力",
    "href": "slide/rct.html#無作為割当の力",
    "title": "社会科学における因果推論",
    "section": "無作為割当の力",
    "text": "無作為割当の力\nコインを投げ、表( \\(H\\) )なら統制群、裏( \\(T\\) )なら処置群に割当\n\nデータ生成Dataの中身\n\n\n\nset.seed(19861008)\nData <- tibble(ID = 1:20,\n               Female = sample(0:1, 20, replace = TRUE, \n                               prob = c(0.4, 0.6)),\n               Age    = round(rnorm(20, 38, 10), 0))\n\nData |>\n   summarise(Female = mean(Female),\n             Age    = mean(Age))\n\n# A tibble: 1 × 2\n  Female   Age\n   <dbl> <dbl>\n1   0.55    38\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      ID\n      Female\n      Age\n      \n      ID\n      Female\n      Age\n    \n  \n  \n    1\n1\n31\n\n11\n0\n38\n    2\n1\n41\n\n12\n1\n29\n    3\n0\n31\n\n13\n0\n21\n    4\n1\n46\n\n14\n0\n26\n    5\n1\n37\n\n15\n1\n36\n    6\n1\n37\n\n16\n1\n40\n    7\n0\n30\n\n17\n0\n50\n    8\n1\n46\n\n18\n0\n42\n    9\n1\n56\n\n19\n0\n29\n    10\n0\n47\n\n20\n1\n47"
  },
  {
    "objectID": "slide/rct.html#無作為割当の力-1",
    "href": "slide/rct.html#無作為割当の力-1",
    "title": "社会科学における因果推論",
    "section": "無作為割当の力",
    "text": "無作為割当の力\nコイン投げの結果\n\nコイン投げDataの中身\n\n\n\nset.seed(19861008)\nCoin <- sample(c(\"H\", \"T\"), 20, replace = TRUE)\nCoin\n\n [1] \"H\" \"T\" \"T\" \"T\" \"H\" \"H\" \"H\" \"T\" \"H\" \"H\" \"H\" \"T\" \"H\" \"T\" \"H\" \"T\" \"T\" \"T\" \"H\"\n[20] \"H\"\n\ntable(Coin)\n\nCoin\n H  T \n11  9 \n\nData$Coin <- Coin\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      ID\n      Female\n      Age\n      Coin\n      \n      ID\n      Female\n      Age\n      Coin\n    \n  \n  \n    1\n1\n31\nH\n\n11\n0\n38\nH\n    2\n1\n41\nT\n\n12\n1\n29\nT\n    3\n0\n31\nT\n\n13\n0\n21\nH\n    4\n1\n46\nT\n\n14\n0\n26\nT\n    5\n1\n37\nH\n\n15\n1\n36\nH\n    6\n1\n37\nH\n\n16\n1\n40\nT\n    7\n0\n30\nH\n\n17\n0\n50\nT\n    8\n1\n46\nT\n\n18\n0\n42\nT\n    9\n1\n56\nH\n\n19\n0\n29\nH\n    10\n0\n47\nH\n\n20\n1\n47\nH"
  },
  {
    "objectID": "slide/rct.html#無作為割当の力-2",
    "href": "slide/rct.html#無作為割当の力-2",
    "title": "社会科学における因果推論",
    "section": "無作為割当の力",
    "text": "無作為割当の力\n統制群と処置群が比較的同質的なグループに\n\n統制群（11名）: 女性比率が54.5%、平均年齢が37.2歳\n処置群 (9名): 女性比率が55.6%、平均年齢が39歳\n\n\nData |>\n  group_by(Coin) |>\n  summarise(Female = mean(Female),\n            Age    = mean(Age),\n            N      = n())\n\n# A tibble: 2 × 4\n  Coin  Female   Age     N\n  <chr>  <dbl> <dbl> <int>\n1 H      0.545  37.2    11\n2 T      0.556  39       9"
  },
  {
    "objectID": "slide/rct.html#無作為割当の力-3",
    "href": "slide/rct.html#無作為割当の力-3",
    "title": "社会科学における因果推論",
    "section": "無作為割当の力",
    "text": "無作為割当の力\n集団として処置群と統制群は、母集団とほぼ同質\n\n\\(n \\rightarrow \\infty\\) なら2つのグループはより同質的に（大数の弱法則）\n\n\n\n\n\n女性の割合\n平均年齢\n\n\n\n\n母集団 (\\(n=20\\))\n55.0%\n38.0歳\n\n\n統制群 (\\(n=11\\))\n54.5%\n37.2歳\n\n\n処置群 (\\(n=9\\))\n55.6%\n39.0歳\n\n\n\n\n統制群と処置群、母集団はそれぞれ交換可能 (exchangeable)\n\n処置群に処置を与えること = 母集団全体に処置を与えること\n統制群に処置を与えないこと = 母集団全体に処置を与えないこと\n\n統制群と処置群の比較で集団を一つの単位としたITE (= ATE)が推定可能\n\n処置を与えた母集団 vs. 処置を与えなかった母集団"
  },
  {
    "objectID": "slide/rct.html#無作為割当の力-4",
    "href": "slide/rct.html#無作為割当の力-4",
    "title": "社会科学における因果推論",
    "section": "無作為割当の力",
    "text": "無作為割当の力\n無作為割当は均質な複数のグループを作る手法\n\n講義履修と年収の例だと、無作為割当をすることによって …\n\n各グループにやる気のある学生とない学生が均等に\n\n自己選択バイアス、擬似相関の除去\n\nジンバブエ・ドルで測定される学生も均等に（これはないか）\n\n測定誤差の除去\n\n\n内生性:処置変数（講義の履修）と誤差項（やる気など）間の相関\n\nコイン投げの結果は被験者（学生）の性質と無関係に行われるため、誤差項と相関がない。\n外生変数 (Exogenous variable)\n学生の性質 (X) と処置有無 (T) は独立している ⇒ \\(X \\perp T\\)\n\n\n\n\n無作為割当は内生性を除去する最良の手法"
  },
  {
    "objectID": "slide/rct.html#無作為抽出と無作為割当",
    "href": "slide/rct.html#無作為抽出と無作為割当",
    "title": "社会科学における因果推論",
    "section": "無作為抽出と無作為割当",
    "text": "無作為抽出と無作為割当\n\n無作為抽出によってサンプル（標本）と母集団が交換可能（実はここが難しい）\n無作為割当によって各グループとサンプルに交換可能（=各グループ間で交換可能）\n無作為抽出&無作為割当によって各グループと母集団が交換可能（グループへの刺激=母集団への刺激）"
  },
  {
    "objectID": "slide/rct.html#ランダム化比較試験とは",
    "href": "slide/rct.html#ランダム化比較試験とは",
    "title": "社会科学における因果推論",
    "section": "ランダム化比較試験とは",
    "text": "ランダム化比較試験とは\nRandomized Controlled Trial (RCT)\n\n無作為割当で複数のグループを作り上げた上で、異なる刺激・処置を与え、結果を観察する手法\n\n社会科学でいう「実験」の多くはこれを指す\n因果推論の王道\n\n因果効果をもたらす(と想定される)処置変数が外生的\n\nグループ間における結果変数の差 = 因果効果\n\nデータ生成過程(Data Generating Process; DGP)への直接介入\n\n「真のモデル」が分かる\n\n\n\n\n\n参考）データ生成過程について\n\nKing, Gary. 1989. Unifying Political Methodology, Michigan University Press.（Ch.1-4）\n豊田秀樹. 2022.『統計学入門 II: 尤度によるデータ生成過程の表現』朝倉書店"
  },
  {
    "objectID": "slide/rct.html#データ生成過程への介入",
    "href": "slide/rct.html#データ生成過程への介入",
    "title": "社会科学における因果推論",
    "section": "データ生成過程への介入",
    "text": "データ生成過程への介入\n\\[\n\\text{Income} = \\beta_0 + \\beta_1 \\cdot \\text{Quant} + \\varepsilon\n\\]\n\nIncome: 10年後の年収 (\\(\\in [0, \\infty)\\))\nQuant:ソンさんの講義を履修したか否か (\\(\\in \\{0, 1\\})\\) )\n誤差項(\\(\\varepsilon\\))には「やる気」や「真面目さ」が含まれるため、Quantと相関がある (\\(\\rightarrow\\) 内生性)\n無作為割当で受講有無を決めると、「やる気」や「真面目さ」はQunatと無関係 (独立) になる\n\n例) 受講有無をコイン投げ（W）で決める場合、コインの結果は誤差項（やる気や真面目さ）と独立（ただし、全員がコイン投げの結果に従うと仮定）\n\\(\\Rightarrow\\) 内生性がなくなる!"
  },
  {
    "objectID": "slide/rct.html#実験の方法",
    "href": "slide/rct.html#実験の方法",
    "title": "社会科学における因果推論",
    "section": "実験の方法",
    "text": "実験の方法\nHyde (2015) による分類\n\nフィールド実験: 実際の社会を舞台に行う実験\n\nGerber, Alan S. and Donald P. Green. 2012. Field Experiments, Norton.\n\n実験室実験: 人為的に作られた（=統制された）環境内で行う実験\nサーベイ実験: 世論調査に埋め込む実験\n\nSONG Jaehyun・秦正樹. 2020. 「オンライン・サーベイ実験の方法: 理論編」『理論と方法』35 (1): 92-108.\n秦正樹・SONG Jaehyun. 2020. 「オンライン・サーベイ実験の方法: 実践編」『理論と方法』35 (1): 109-127."
  },
  {
    "objectID": "slide/rct.html#フィールド実験1",
    "href": "slide/rct.html#フィールド実験1",
    "title": "社会科学における因果推論",
    "section": "フィールド実験（1）",
    "text": "フィールド実験（1）\n実際の社会を舞台に行う実験\n\n例1例2\n\n\nIto, Koichiro, Takanori Ida, and Makoto Tanaka. 2018. “Moral Suasion and Economic Incentives: Field Experimental Evidence from Energy Demand,” American Economic Journal: Economic Policy, 10 (1): 240-267.\n\n京都府内の691世帯が対象\n電気メーターを設置し、統制群と処置群1、処置群2に分割\n\n設置のみ (153) / 単純節電要請 (154) / 動機づけ節電要請 (384)\n\n電気使用量の比較\n\n\n\nGerber, Alan S., Donald P. Green, and Christopher W. Larimer. 2010. “An Experiment Testing the Relative Effectiveness of Encouraging Voter Participation by Inducing Feelings of Pride or Shame,” Political Behavior, 32: 409-422.\n\nミシガン州の18万世帯が対象\n4つの処置群にそれぞれ異なる投票を促す内容の葉書を発送\n\n統制群: 99,999世帯 / 処置群1: 20,001世帯 / 処置群2: 20,002世帯 / 処置群3: 20,00 世帯 / 処置群4: 20,000世帯\n\nそれぞれのグループ間の投票率を比較"
  },
  {
    "objectID": "slide/rct.html#フィールド実験2",
    "href": "slide/rct.html#フィールド実験2",
    "title": "社会科学における因果推論",
    "section": "フィールド実験（2）",
    "text": "フィールド実験（2）\n\nメリット\n\n実際の社会と対象にするため、高い外的妥当性\n\n一般的に外的妥当性は実験研究の最大の弱点とも言われる\nただし、全国民ではなく、一部の地域を対象にするケースが多いため、限界もある\n\nIto, Ida and Tanaka (2018) は外的妥当性の確保のために同様の実験を京都以外でも実施 (京都市、横浜市、北九州市、豊田市)\n\n\n\nデメリット\n\n高費用\n\nGerber, Green, and Larimer (2010) は安い方?\n\nアメリカで切手は100円以上の場合が多いため、18万世帯$$100円だけでも1800万円\n葉書もタダじゃない (Amazon.comで100枚12ドル程度)\n\nIto, Ida and Tanaka (2018) は . . .\n\n\n政府や企業などの協力なしでは実施が困難なケースが多い"
  },
  {
    "objectID": "slide/rct.html#実験室実験1",
    "href": "slide/rct.html#実験室実験1",
    "title": "社会科学における因果推論",
    "section": "実験室実験（1）",
    "text": "実験室実験（1）\n人為的に作られた環境内で行う実験\n\n例1例2\n\n\nBlais, André, Simon Labbé-St-Vincent, Laslier Jean-François, Nicolas Sauger, and Karine Van der Straeten. 2011. “Strategic Vote Choice in One-Round and Two-Round Elections: An Experimental Study,” Political Research Quarterly, 64(3): 637–645.\n\n42名 \\(\\times\\) 2グループ\n\nグループ1: 一回投票制4回 \\(\\rightarrow\\) 二回投票制4回\nグループ2: 二回投票制4回 \\(\\rightarrow\\) 一回投票制4回\n\n投票方式による戦略投票 (Strategic Vote) の傾向を比較\n\n\n\nMueller, Pam A. and Daniel M. Oppenheimer. 2014. “The Pen Is Mightier Than the Keyboard: Advantages of Longhand Over Laptop Note Taking,” Psychological Science, 25(6): 1159-1168.\n\n学生を2グループに分割\n\nグループ 1: ノートパソコンでノートテイキング\nグループ 2: ノートとペンでノートテイキング\n\nレクチャーの理解度をグループごとに比較"
  },
  {
    "objectID": "slide/rct.html#実験室実験2",
    "href": "slide/rct.html#実験室実験2",
    "title": "社会科学における因果推論",
    "section": "実験室実験（2）",
    "text": "実験室実験（2）\n\nメリット\n\n環境を自由に操作できる\n被験者の訓練・統制が容易\n\n実験前のルールの説明など\n\n\nデメリット\n\n被験者の属性が偏りやすい \\(\\Rightarrow\\) 低い外的妥当性\n\n主に学生が動員される\nHovland (1959): “College sophomores may not be people.”\n\n\nトレードオフ\n\n一般的に、被験者が少数\n\nSmall \\(N\\) \\(\\leftrightarrow\\) 低コスト(単位を餌にする研究者ならタダでできる)"
  },
  {
    "objectID": "slide/rct.html#サーベイ実験1",
    "href": "slide/rct.html#サーベイ実験1",
    "title": "社会科学における因果推論",
    "section": "サーベイ実験（1）",
    "text": "サーベイ実験（1）\n世論調査に実験を埋め込む方法\n\n例1例2\n\n\nAsaba, Yuki, Kyu S Hahn, Seulgi Jang, Tetsuro Kobayashi, and Atsushi Tago. 2020. “38 seconds above the 38th parallel: how short video clips produced by the US military can promote alignment despite antagonism between Japan and Korea,” International Relations of the Asia-Pacific, 20(2): 253–273.\n\nサーベイの回答者1500名を2グループに分割\n\n統制群: 38秒の日米韓軍事協力に関するPACOM制作の動画を視聴\n処置群: ほぼ同じ長さのPACOM制作の動画を視聴 (日韓の言及はなし)\n\nアメリカに対する感情温度、日韓協力に対する態度を測定\nグループごとに結果を比較\n\n\n\nSong, Jaehyun, Takeshi Iida, Yuriko Takahashi, and Jesús Tovar. 2022 (forthcoming). “Buying Votes across Borders? A List Experiment on Mexican Immigrants in the US,” Canadian Journal of Political Science.\n\n回答者621名を統制群と処置群に割当\n統制群に以下のように質問\n\n\n\n\nNow we are going to show you four activities that some people may experience during the electoral campaign. After you read all four, just answer HOW MANY activities you experienced during the last electoral campaign. (We do NOT want to know which ones, just how many.)\n\nI saw public debates between candidates for presidential elections on TV.\nI saw official websites/blogs of politicians and candidates.\nMy family/friends told me about the election.\nCampaign activists threatened me to vote for a candidate.\n\n\n\n\n\n処置群には「Campaign activists gave any monetary benefits or did a favor to me or my family in Mexico.」を追加\n結果の平均値を比較"
  },
  {
    "objectID": "slide/rct.html#サーベイ実験2",
    "href": "slide/rct.html#サーベイ実験2",
    "title": "社会科学における因果推論",
    "section": "サーベイ実験（2）",
    "text": "サーベイ実験（2）\n\nメリット\n\nコストが低い (数万円で一応実施可能OK)\n大規模の実験が可能（数百人〜数千人）\n機動性が高い\nSUTVA（後述）が満たされやすい\n\nデメリット\n\n実際の環境を再現するのが困難（外的妥当性の問題）\n「行動」を対象とした場合、測定尺度の問題\n不良回答者（satisficer）の存在\n実験のトラブルに対応するのが困難"
  },
  {
    "objectID": "slide/rct.html#rctの例",
    "href": "slide/rct.html#rctの例",
    "title": "社会科学における因果推論",
    "section": "RCTの例",
    "text": "RCTの例\nBertrand, Marianne, and Sendhil Mullainathan. 2004. “Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination,” American Economic Review, 94(4): 991-1013.\n\n労働市場における人種差別\n約5000人分の架空の履歴書を求人中の会社へ送る\n\n履歴書の内容 (性別、人種、能力など) は完全無作為\n履歴書に人種は記入できないため、白人っぽい名前 (Emily など)、黒人っぽい名前 (Jamal など) を記入\n\n後は、返事を待つだけ\n\n処置変数: 人種 ( \\(\\in \\{\\text{black}, \\text{white}\\}\\) )\n結果変数: 連絡の有無 ( \\(\\in \\{0, 1\\}\\) )"
  },
  {
    "objectID": "slide/rct.html#内生性の可能性",
    "href": "slide/rct.html#内生性の可能性",
    "title": "社会科学における因果推論",
    "section": "内生性の可能性",
    "text": "内生性の可能性\n\n\n\n\n\n\n\n\n\n\n\n\n誤差項には教育水準、親の所得、居住地などが含まれる\n\n実際に人種と上記の要因には相関あり\n人種 (処置) と誤差項間の相関関係 \\(\\rightarrow\\) 内生性\n\n黒人が採用されなかった場合…\n\n黒人だから? \\(\\leftarrow\\) 人種差別\\(\\bigcirc\\)\n教育水準が低いから \\(\\leftarrow\\) 人種差別\\(\\times\\)\n\n\n\n \\(\\Rightarrow\\) 内生性がある限り、因果効果の識別は困難  \\(\\Rightarrow\\) ケースによって政策的含意が変わる。"
  },
  {
    "objectID": "slide/rct.html#rctの力",
    "href": "slide/rct.html#rctの力",
    "title": "社会科学における因果推論",
    "section": "RCTの力",
    "text": "RCTの力\n\n\n\n\n白人の名前\n黒人の名前\n\n\n\n\nFemale\n76.42%\n77.45%\n\n\nHighQuality\n50.23%\n50.23%\n\n\nCall Rate\n9.65%\n6.45%\n\n\n計 (人)\n2435\n2435\n\n\n\n\n無作為割当の結果、人種と性別・能力の相関がほぼ0に\n\n内生性のない状態\nこの場合、労働市場における人種の因果効果は\n\nATE = 黒人の平均連絡率 − 白人の平均連絡率\n黒人という理由だけで会社から連絡が来る確率が 3.2%p\\(\\downarrow\\)\n-3.2%p: 人種の因果効果 or 処置効果 (treatment effect)"
  },
  {
    "objectID": "slide/rct.html#バランスチェック",
    "href": "slide/rct.html#バランスチェック",
    "title": "社会科学における因果推論",
    "section": "バランスチェック",
    "text": "バランスチェック\n無作為割当が行われているか否かを確認\n\n\n\n\n\n\n\n\n\n\n\n\n標準化差分を使用\n\nStandardized Bias (or Difference)\n\nサンプルサイズの影響\\(\\times\\)\n統計的検定ではない\n\n\\(t\\) 検定、ANOVA、 \\(\\chi^2\\) 検定は\\(\\times\\)\n\nバランスチェックに統計的有意性検定は使わない\n\n{cobalt}、{BalanceR}など"
  },
  {
    "objectID": "slide/rct.html#標準化差分について",
    "href": "slide/rct.html#標準化差分について",
    "title": "社会科学における因果推論",
    "section": "標準化差分について",
    "text": "標準化差分について\n連続変数\n\\[\n\\text{SB}_{T-C} = 100 \\cdot \\frac{\\bar{X}_T - \\bar{X}_C}{\\sqrt{0.5 \\cdot (s_T^2 + s_C^2)}}\n\\]\n二値変数\n\\[\n\\text{SB}_{T-C} = 100 \\cdot \\frac{\\bar{X}_T - \\bar{X}_C}{\\sqrt{0.5 \\cdot (\\bar{X}_T(1-\\bar{X}_T) + \\bar{X}_C(1-\\bar{X}_C))}}\n\\]\n\n\\(\\bar{X}_T\\) : 処置群におけるXの平均値\n\\(s_T^2\\) : 処置群におけるXの分散\n|SB|が小さいほどバランス\n\n明確な基準はないが、3、5、10、25などを使用\n\nグループが3つ以上の場合、それぞれのペアで実行"
  },
  {
    "objectID": "slide/rct.html#因果効果の推定",
    "href": "slide/rct.html#因果効果の推定",
    "title": "社会科学における因果推論",
    "section": "因果効果の推定",
    "text": "因果効果の推定\n\n平均値の差分の検定単回帰分析\n\n\n方法1: グループ間の結果変数の差分の検定 (\\(t\\)検定)\n\n因果効果 (ATE): \\(\\mathbb{E}[\\mbox{Call}|\\mbox{Race = Black}] - \\mathbb{E}[\\mbox{Call}|\\mbox{Race = White}] = -0.032\\)\nATE = 0の帰無仮説の検定\n\n\\(t_{\\text{df} = 4711.7} = −4.117\\); \\(p\\) < 0.001; 95% CI = [−0.047, −0.017]\n\n応答変数の尺度に応じてノンパラメトリック分析\n\n\n\n方法2: 単回帰分析 (線形 or ロジスティックス/プロビット)\n\n\n\n\n\n線形回帰分析（LPM）\n\n\nCovriates\nEst.\nS.E.\n\n\n\n\nIntercept\n0.064\n0.006\n\n\nRace: White\n0.032\n0.008\n\n\n\n\n\n\nロジスティック回帰分析\n\n\nCovriates\nEst.\nS.E.\n\n\n\n\nIntercept\n-2.675\n0.083\n\n\nRace: White\n0.438\n0.107\n\n\n\n\n\n\nプロビット回帰分析\n\n\nCovriates\nEst.\nS.E.\n\n\n\n\nIntercept\n-1.518\n0.039\n\n\nRace: White\n0.217\n0.053\n\n\n\n\n\n\n\n\n\n\n\n\n参考）Freedman, David A. 2008. “Randomization Does Not Justify Logistic Regression,” Statistical Science Statistical Science, 23(2): 237-249.\n\nLogit: 一致推定量\\(\\times\\) & 不偏推定量\\(\\times\\)\nLinear: 一致推定量\\(\\bigcirc\\) & 不偏推定量\\(\\times\\)\n一致性と不偏性の違いについて"
  },
  {
    "objectID": "slide/rct.html#因果効果の推定-重回帰分析は",
    "href": "slide/rct.html#因果効果の推定-重回帰分析は",
    "title": "社会科学における因果推論",
    "section": "因果効果の推定: 重回帰分析は?",
    "text": "因果効果の推定: 重回帰分析は?\n無作為割当のおかげですべての変数が互いに独立\n\n重回帰分析をしても人種のATEは変化しない (OVB がない)\n\n無作為割当の場合、回帰はしてもしなくても良い\n\n現実的に完全にバランスが取れていないため、若干の変化はある\n\n\n\n\nCovriates\nEst.\nS.E.\n\n\n\n\nIntercept\n0.057\n0.007\n\n\nRace: White\n0.032\n0.08\n\n\nFemale\n0.007\n0.009\n\n\nMilitary\n-0.027\n0.014\n\n\nEducation\n-0.002\n0.005\n\n\nHigh Quality\n0.019\n0.008"
  },
  {
    "objectID": "slide/rct.html#因果効果の不均一性",
    "href": "slide/rct.html#因果効果の不均一性",
    "title": "社会科学における因果推論",
    "section": "因果効果の不均一性",
    "text": "因果効果の不均一性\n因果効果が下位グループによって異なる場合\n\n因果効果の不均一性 (heterogeneous treatment effects)\n\n例) 性別によって薬の効果が異なる場合\n薬の効果が男性なら 1、女性なら 2 の場合\n\n男女比が1:1なら、ATEは1.5に\n\n薬の効果が男性なら 4、女性なら-1 の場合\n\n男女比が1:1なら、ATEは1.5だが…\n\n\n方法1: 男女に分けてATEを推定\n方法2: 性別と処置有無の交差項を投入した重回帰分析\n\n\n\n参考) Bryan, Christopher J., Elizabeth Tipton and David S. Yeager. 2021. “Behavioural science is unlikely to change the world without a heterogeneity revolution,” Nature Human Behaviour. 5: 980–989."
  },
  {
    "objectID": "slide/rct.html#因果効果の不均一性intro_data2.csv",
    "href": "slide/rct.html#因果効果の不均一性intro_data2.csv",
    "title": "社会科学における因果推論",
    "section": "因果効果の不均一性（intro_data2.csv）",
    "text": "因果効果の不均一性（intro_data2.csv）\n\ndata2 <- read_csv(\"data/intro_data2.csv\")\n\ndata2\n\n# A tibble: 500 × 4\n      ID Outcome Treatment Female\n   <dbl>   <dbl>     <dbl>  <dbl>\n 1     1  1.09           0      1\n 2     2  0.0281         0      1\n 3     3  1.65           0      0\n 4     4  3.83           1      1\n 5     5  2.65           1      1\n 6     6  1.24           1      1\n 7     7  0.136          1      0\n 8     8  0.507          0      1\n 9     9  2.99           1      1\n10    10  4.34           1      1\n# … with 490 more rows"
  },
  {
    "objectID": "slide/rct.html#因果効果の不均一性-1",
    "href": "slide/rct.html#因果効果の不均一性-1",
    "title": "社会科学における因果推論",
    "section": "因果効果の不均一性",
    "text": "因果効果の不均一性\n方法1: 男女に分けてATEを推定\n\n比較コード1コード2コード3\n\n\n\n\n\n\n統制群\n処置群\nATE\n\\(t\\)\n\\(p\\)\n\n\n\n\n男性のみ\n0.611\n1.561\n0.951\n-7.521\n< 0.001\n\n\n女性のみ\n0.493\n2.480\n1.987\n-15.573\n< 0.001\n\n\n全体\n0.551\n2.057\n1.506\n-15.945\n< 0.001\n\n\n\n\n\n男性のみ\n\nt.test(Outcome ~ Treatment, data = data2, subset = (Female == 0))\n\n\n    Welch Two Sample t-test\n\ndata:  Outcome by Treatment\nt = -7.5211, df = 235.95, p-value = 1.132e-12\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -1.1996845 -0.7016501\nsample estimates:\nmean in group 0 mean in group 1 \n      0.6105137       1.5611810 \n\n\n\n\n女性のみ\n\nt.test(Outcome ~ Treatment, data = data2, subset = (Female == 1))\n\n\n    Welch Two Sample t-test\n\ndata:  Outcome by Treatment\nt = -15.573, df = 259.72, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -2.238053 -1.735599\nsample estimates:\nmean in group 0 mean in group 1 \n      0.4931905       2.4800169 \n\n\n\n\n全体\n\nt.test(Outcome ~ Treatment, data = data2)\n\n\n    Welch Two Sample t-test\n\ndata:  Outcome by Treatment\nt = -15.945, df = 494.24, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -1.692061 -1.320817\nsample estimates:\nmean in group 0 mean in group 1 \n      0.5509135       2.0573524"
  },
  {
    "objectID": "slide/rct.html#因果効果の不均一性-2",
    "href": "slide/rct.html#因果効果の不均一性-2",
    "title": "社会科学における因果推論",
    "section": "因果効果の不均一性",
    "text": "因果効果の不均一性\n方法2: 性別と処置有無の交差項を投入した重回帰分析\n\n\n\nlm(Outcome ~ Treatment * Female, \n   data = data2) |>\n   summary()\n\n\n\n\n\n \n  \n      \n    Model 1 \n  \n \n\n  \n    (Intercept) \n    0.611 (0.091) \n  \n  \n    Treatment \n    0.951 (0.131) \n  \n  \n    Female \n    −0.117 (0.127) \n  \n  \n    Treatment × Female \n    1.036 (0.180) \n  \n  \n    Num.Obs. \n    500 \n  \n  \n    R2 Adj. \n    0.398 \n  \n  \n    F \n    110.905 \n  \n\n\n\n\n\n\n\\[\n\\begin{align}\n\\hat{y} = & \\beta_0 + \\beta_1 \\mbox{Treatment} + \\beta_2 \\mbox{Female} + \\\\\n& \\beta_3 \\mbox{Treatment} \\cdot \\mbox{Female} \\\\\n= & \\beta_0 + (\\beta_1 + \\beta_3 \\mbox{Female}) \\mbox{Treatment} + \\beta_2 \\mbox{Female}.\n\\end{align}\n\\]\n\n処置効果はTreatmentの係数\n\n\\(\\beta_1 + \\beta_3 \\mbox{Female}\\)\n\\(\\Rightarrow\\) 処置効果がFemaleの値にも依存\n\n男性のATE: \\(\\beta_1 + \\beta_3 \\cdot 0 = \\beta_1\\) = 0.951\n女性のATE: \\(\\beta_1 + \\beta_3 \\cdot 1 = \\beta_1 + \\beta_3\\) = 1.987"
  },
  {
    "objectID": "slide/rct.html#因果推論の前提sutva",
    "href": "slide/rct.html#因果推論の前提sutva",
    "title": "社会科学における因果推論",
    "section": "因果推論の前提:SUTVA",
    "text": "因果推論の前提:SUTVA\nStable Unit Treatment Value Assumption\n\n非干渉性処置の無分散性サーベイ実験の場合\n\n\n非干渉性: 他人の処置・統制有無が処置効果に影響を与えないこと\n\n例) AさんITEは\n\n例1) Bさんが統制群の場合は10、処置群の場合は5 \\(\\leftarrow\\)  \n例2) Bさんが統制群の場合も、処置群の場合も、5 \\(\\leftarrow\\)  \n\n\n\n\n\n\n\n例1\n\n\n\nAさんが統制群\nAさんが処置群\n\n\n\n\nBさんが統制群\n0\n10\n\n\nBさんが処置群\n15\n20\n\n\n\n\n\n\n例2\n\n\n\nAさんが統制群\nAさんが処置群\n\n\n\n\nBさんが統制群\n5\n10\n\n\nBさんが処置群\n15\n20\n\n\n\n\n\n\n\n\n\n処置の無分散性: 同じグループに属する対象は同じ処置を受けること\n\n手術の場合: 医者、設備、手順、環境など\n投票参加: 当日、期日前など\n\n\n\n\nサーベイ実験ではSUTVAが満たされやすい。\n\n実験室実験、フィールド実験の場合、「非干渉性」には気をつける。\n例) 隣の人が見てるのとと私が見てるのが違いますが…?"
  },
  {
    "objectID": "slide/rct.html#二重盲検法",
    "href": "slide/rct.html#二重盲検法",
    "title": "社会科学における因果推論",
    "section": "二重盲検法",
    "text": "二重盲検法\n二重盲検法 (Double Blind Test):ある被験者がどのような処置を受けているかについて研究者と被験者両方において不明な状態で実験を行う\n\n二重盲検法を使えば以下の問題点に対処することが可能\n\nプラセボ効果 (placebo effect):偽薬が与えられても、薬だと信じ込む 事によって何らかの効果が生じる\nホーソン効果 (Hawthorne effect):自分が観察されていることを認知さ れることによって何らかの効果が生じる\n観察者効果 (observer/experimenter effect):研究者の期待により被験者へ の対応が異なったり、被験者がその期待に添えるように行動すること"
  },
  {
    "objectID": "slide/rct.html#用意するもの",
    "href": "slide/rct.html#用意するもの",
    "title": "社会科学における因果推論",
    "section": "用意するもの",
    "text": "用意するもの\n\nノートPC\n\nデスクトップを持ち込む自信があるなら、デスクトップでもOK\n\nRの導入\n\n自分のPCにR/RStudioをインストール\nクラウド版のR + RStudioの利用\n分からない場合は至急、宋と相談すること\n\nブラインドタッチのスキル\n\n\n\n\nhttps://www.jaysong.net/kandai-ci"
  },
  {
    "objectID": "slide/foundation.html#社会科学における因果推論の意味",
    "href": "slide/foundation.html#社会科学における因果推論の意味",
    "title": "社会科学における因果推論",
    "section": "社会科学における因果推論の意味",
    "text": "社会科学における因果推論の意味\nMorgan and Winship (2014) Counterfactuals and Causal Inference: Methods And Principles For Social Research. Cambridge.\n\nMore has been learned about causal inference in the last few decades than sum total of everything that had been learned about it in all prior recorded history. (Gary King)"
  },
  {
    "objectID": "slide/foundation.html#相関から因果へ",
    "href": "slide/foundation.html#相関から因果へ",
    "title": "社会科学における因果推論",
    "section": "相関から因果へ",
    "text": "相関から因果へ\n原因 (\\(X\\)) と結果 (\\(Y\\)) の関係: 啓発活動と投票率の関係（架空の例）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\bigcirc\\): 啓発活動が行われる選挙区の投票率は低い（相関関係）\n\\(\\times\\): 啓発活動は投票率を下げる（因果関係）\n\\(\\Rightarrow\\) 統計分析から得られる結果は相関関係のみ\n\n\n\n理論/デザインを用い、観察された相関関係が因果関係であることを説得\n\n因果関係を担保してくれる統計的手法はない。\n\n「これは相関関係でなく因果関係である」と主張するためには、内生性がないことを示す必要がある。"
  },
  {
    "objectID": "slide/foundation.html#同時性",
    "href": "slide/foundation.html#同時性",
    "title": "社会科学における因果推論",
    "section": "同時性",
    "text": "同時性\nSimultaneity\n\n\n\n\n\n\n\n\n原因と結果の間に双方向の因果関係が存在\n\n例) お酒 (原因; X) とストレス (結果; Y) の関係\n\n酒を飲むとストレスが貯まる\nストレス解消のために酒を飲む\n酒を飲むとストレスが貯まる\nストレス解消のために酒を飲む\n酒を飲むとストレスが貯まる\n…\n\n\\(\\rightarrow\\) 地獄のような無限ループ\n\n\\(\\Rightarrow\\) 酒がストレスに与える影響は?"
  },
  {
    "objectID": "slide/foundation.html#見かけ上の相関",
    "href": "slide/foundation.html#見かけ上の相関",
    "title": "社会科学における因果推論",
    "section": "見かけ上の相関",
    "text": "見かけ上の相関\nSpurious Correlation、擬似相関\n\nたまたま相関関係がある場合\n\n例) メイン州の離婚率一人当たりマーガリンの消費量"
  },
  {
    "objectID": "slide/foundation.html#見かけ上の相関-1",
    "href": "slide/foundation.html#見かけ上の相関-1",
    "title": "社会科学における因果推論",
    "section": "見かけ上の相関",
    "text": "見かけ上の相関\nSpurious Correlation、擬似相関\n\n共通の要因からの影響（ビールとアイスクリーム消費量）"
  },
  {
    "objectID": "slide/foundation.html#見かけ上の相関-2",
    "href": "slide/foundation.html#見かけ上の相関-2",
    "title": "社会科学における因果推論",
    "section": "見かけ上の相関",
    "text": "見かけ上の相関\nSpurious Correlation、擬似相関\n\n共通の要因からの影響（ゲームをやると身長が伸びる説）"
  },
  {
    "objectID": "slide/foundation.html#逆の因果",
    "href": "slide/foundation.html#逆の因果",
    "title": "社会科学における因果推論",
    "section": "逆の因果",
    "text": "逆の因果\nReverse Causality\n\n例) 心臓移植と生存率の例\n\n\n\n\n\n\n5年後に死亡\n5年後に生存\n\n\n\n\n心臓移植を\n受けた\n10名\n5名\n\n\n\n受けなかった\n5名\n10名\n\n\n\n\n心臓移植を受けたら死亡確率が上がる?\n死亡確率が高い人が心臓移植を受ける?"
  },
  {
    "objectID": "slide/foundation.html#逆の因果-1",
    "href": "slide/foundation.html#逆の因果-1",
    "title": "社会科学における因果推論",
    "section": "逆の因果",
    "text": "逆の因果\nReverse Causality\n\n「人気だから4文字に略されるのか、4文字に略せるからヒットす るのか、どっちなんでしょうね」"
  },
  {
    "objectID": "slide/foundation.html#欠落変数バイアス",
    "href": "slide/foundation.html#欠落変数バイアス",
    "title": "社会科学における因果推論",
    "section": "欠落変数バイアス",
    "text": "欠落変数バイアス\nOmitted Variable Bias\n例) 真のモデルが\\(Y = \\beta_0 + \\beta_1 \\cdot X + \\beta_2 \\cdot Z + e\\)の場合\n\n\n\n\n\n\n\n\n\n\n\n\n\nモデルに\\(Z\\)が含まれていなくても\\(\\beta_1\\)の推定値は変化\\(\\times\\)\n\n\\(X\\)と\\(Z\\)は独立（\\(X \\perp Z\\)）\n\\(\\sigma_{X, Z} = 0\\)"
  },
  {
    "objectID": "slide/foundation.html#欠落変数バイアス-1",
    "href": "slide/foundation.html#欠落変数バイアス-1",
    "title": "社会科学における因果推論",
    "section": "欠落変数バイアス",
    "text": "欠落変数バイアス\nOmitted Variable Bias\n例) 真のモデルが\\(Y = \\beta_0 + \\beta_1 \\cdot X + \\beta_2 \\cdot Z + e\\)の場合\n\n\n\n\n\n\n\n\n\n\n\n\n\nモデルに\\(Z\\)が含まれていない場合、\\(\\beta_1\\)の推定値にバイアス\n\n\\(Z \\rightarrow X\\)の関係が存在\n\\(\\sigma_{X, Z} \\neq 0\\)\n\n\\(\\beta_1\\)の真の値（=不偏推定量）を推定するためには\\(X\\)と\\(Y\\)両方と相関する変数すべてが必要\n\nそもそも、「真の値」とは？\n\\(X\\)と\\(Y\\)両方と相関するすべての変数は特定可能? 測定可能?\n\n\\(\\rightarrow\\) データ分析から得られた結果はあくまでも「分析モデルが想定している世界」のものに過ぎない\n\n定量的手法は反証可能性を高めやすい手法（=科学的な手法になりやすい）であって、科学そのものも、得られた結果が真理であることを保障するものでもない。"
  },
  {
    "objectID": "slide/foundation.html#自己選択バイアス",
    "href": "slide/foundation.html#自己選択バイアス",
    "title": "社会科学における因果推論",
    "section": "自己選択バイアス",
    "text": "自己選択バイアス\n(Self-)Selection Bias\n\n例1) 職業訓練と期待収入\n\n\n\n\n\n\n3年後の収入\n\n\n\n\n職業訓練を\n受けた\n6349ドル\n\n\n\n受けなかった\n6984ドル\n\n\n\n\n職業訓練を受けたら収入が上がる?\nもともと低収入の人が職業訓練を受けようとする?\n参考) 心臓移植の例も自己選択のバイアスとして解釈可能\n参考) 交絡因子の不在として解釈可能（就労意欲など）"
  },
  {
    "objectID": "slide/foundation.html#内生性",
    "href": "slide/foundation.html#内生性",
    "title": "社会科学における因果推論",
    "section": "内生性",
    "text": "内生性\nこれまでの多くの例は内生性（endogeneity）の問題\n\n内生性: 説明変数と誤差項間に相関が存在\n\n誤差項と相関のある説明変数: 内生変数（endogenous variable）\n\n内生性がある場合、推定値は一致推定量でも、不偏推定量でもはない\n\nサンプルサイズ（\\(N\\)）をいくら増やしても無駄\n\n内生性の原因\n\n同時性\n欠落変数バイアス\n（体系的な）測定誤差\n自己選択バイアス\n\n最近の教科書はこれはすべてを自己選択バイアスや欠落変数バイアスでまとめる傾向"
  },
  {
    "objectID": "slide/foundation.html#単純比較の罠",
    "href": "slide/foundation.html#単純比較の罠",
    "title": "社会科学における因果推論",
    "section": "単純比較の罠",
    "text": "単純比較の罠\n啓発活動と投票率の関係（架空の例）\n\n\n\n\n\n\n\n\n\n\n\n\n\n単純比較の手法\n\n平均値の比較、平均値の差の検定（\\(t\\)検定、ANOVA）、単回帰分析など\n啓発ありの投票率 - 啓発なしの投票率 = -10%p\n\n内生性がない場合、「啓発活動は投票率を-10%p下げる」と主張できる。\n本当に、本当に、本当に、内生性はないのか。"
  },
  {
    "objectID": "slide/foundation.html#内生性は",
    "href": "slide/foundation.html#内生性は",
    "title": "社会科学における因果推論",
    "section": "内生性は?",
    "text": "内生性は?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\): 投票率\n\\(X\\): 啓発活動の有無\n\\(W\\): 若者の割合\n\\(Z\\): これまでの投票率\n\\(e\\): \\(X\\)と\\(Z\\)以外に、\\(Y\\)に影響を与える要因\n\n\n\n投票率が低い選挙区ほど、啓発活動を行う傾向\n投票率が元々低い選挙区の場合、今回の投票率も低い傾向\n\n\\(\\Rightarrow\\) 自己選択バイアス/欠落変数バイアスの存在\n\n本当に比較すべき対象は…\n\n啓発活動を行わなかったA市 vs. 行ったA市\n啓発活動を行わなかったB市 vs. 行ったB市\nこれらは比較可能か?"
  },
  {
    "objectID": "slide/foundation.html#相関から因果へ-1",
    "href": "slide/foundation.html#相関から因果へ-1",
    "title": "社会科学における因果推論",
    "section": "相関から因果へ",
    "text": "相関から因果へ\n内生性の除外 \\(\\rightarrow\\) 因果効果の推定"
  },
  {
    "objectID": "slide/foundation.html#因果関係の例",
    "href": "slide/foundation.html#因果関係の例",
    "title": "社会科学における因果推論",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\nオバマ君の場合: ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果\n\n処置: ソンさんの講義を履修するか否か\n効果: 履修した場合の年収 − 履修しなかった場合の年収"
  },
  {
    "objectID": "slide/foundation.html#因果関係の例-1",
    "href": "slide/foundation.html#因果関係の例-1",
    "title": "社会科学における因果推論",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\nオバマ君の場合: ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果（ケース1）\n\nオバマ君がソンさんの授業を履修しなくても年収5000万円なら\n\nソンさんの講義の因果効果は0\n\n\n\n\n\n\n履修しなかった場合の年収(A)\n履修した場合の年収(B)\n効果(B-A)\n\n\n\n\nケース1\n5000万\n5000万\n0万"
  },
  {
    "objectID": "slide/foundation.html#因果関係の例-2",
    "href": "slide/foundation.html#因果関係の例-2",
    "title": "社会科学における因果推論",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\nオバマ君の場合: ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果（ケース2）\n\nオバマ君がソンさんの授業を履修しなかった場合、年収1000万円なら\n\nソンさんの講義の因果効果は4000万円\n一生ソンさんには頭が上がらない\n\n\n\n\n\n\n履修しなかった場合の年収(A)\n履修した場合の年収(B)\n効果(B-A)\n\n\n\n\nケース2\n1000万\n5000万\n4000万"
  },
  {
    "objectID": "slide/foundation.html#因果関係の例-3",
    "href": "slide/foundation.html#因果関係の例-3",
    "title": "社会科学における因果推論",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\nオバマ君の場合: ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果（ケース3）\n\nオバマ君がソンさんの授業を履修しなかった場合、年収8000万円なら\n\nソンさんの講義の因果効果は-3000万\nソンさんは悪くない\n\n\n\n\n\n\n履修しなかった場合の年収(A)\n履修した場合の年収(B)\n効果(B-A)\n\n\n\n\nケース3\n8000万\n5000万\n-3000万"
  },
  {
    "objectID": "slide/foundation.html#因果関係の例-4",
    "href": "slide/foundation.html#因果関係の例-4",
    "title": "社会科学における因果推論",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\nオバマ君の場合: ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果\n\nソンさんの講義を履修しなかった場合のオバマ君の年収は…?\n\n個人（オバマ君）における処置効果を推定する際にはこれが不可欠\n\n\n\n\n\n\n履修しなかった場合の年収(A)\n履修した場合の年収(B)\n効果(B-A)\n\n\n\n\nケース1\n5000万\n5000万\n0万\n\n\nケース2\n1000万\n5000万\n4000万\n\n\nケース3\n8000万\n5000万\n-3000万"
  },
  {
    "objectID": "slide/foundation.html#潜在的結果枠組み",
    "href": "slide/foundation.html#潜在的結果枠組み",
    "title": "社会科学における因果推論",
    "section": "潜在的結果枠組み",
    "text": "潜在的結果枠組み\nNeyman-Rubin-HollandのPotential Outcome Framework\n\n\\(i\\) : 学生ID ( \\(i = 1,2,3,...,N\\) )\n\\(T\\) : 処置\n\n学生 \\(i\\) が謎の薬を飲んだ ( \\(T_i = 1\\) )\n学生 \\(i\\) が謎の薬を飲まなかった ( \\(T_i = 0\\) )\n\n\\(Y_i(T_i = 1)\\) : 学生 \\(i\\) が謎の薬を飲んだ場合の数学成績\n\\(Y_i(T_i = 0)\\) : 学生 \\(i\\) が謎の薬を飲まなかった場合の数学成績\n\\(ITE_i = Y_i(T_i = 1) − Y_i(T_i = 0)\\) : 学生iにおける薬の処置効果\n\nITE: Individual Treatment Effect (個人における処置効果)\n\n= UTE: Unit Treatment Effect\n\n全く同じ個人において薬を飲んだ場合と飲まなかった場合の数学成績の差 = 謎の薬の因果効果"
  },
  {
    "objectID": "slide/foundation.html#薬の効果は",
    "href": "slide/foundation.html#薬の効果は",
    "title": "社会科学における因果推論",
    "section": "薬の効果は?",
    "text": "薬の効果は?\nITEの平均値は−4であり、個人差はあるものの、全体的に薬は成績に負の影響\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(ITE_i\\)\n\n\n\n\n1\n1\n77\n85\n8\n\n\n2\n1\n49\n59\n10\n\n\n3\n1\n60\n66\n6\n\n\n4\n0\n61\n44\n-17\n\n\n5\n0\n50\n39\n-11\n\n\n6\n0\n75\n55\n-20\n\n\n平均\n\n62\n58\n-4"
  },
  {
    "objectID": "slide/foundation.html#因果推論の根本問題-1",
    "href": "slide/foundation.html#因果推論の根本問題-1",
    "title": "社会科学における因果推論",
    "section": "因果推論の根本問題",
    "text": "因果推論の根本問題\nしかし、観察できるのは\\(Y_i(T_i = 1)\\)か\\(Y_i(T_i = 0)\\)、片方のみ\n\n\\(Y_i(T_i = 0)\\)は反実仮想（counterfactual）であり、観察不可 (\\(i \\in \\{1,2,3\\}\\))\n\\(Y_i(T_i = 1)\\)も反実仮想(\\(i \\in \\{4,5,6\\}\\))\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(ITE_i\\)\n\n\n\n\n1\n1\n?\n85\n?\n\n\n2\n1\n?\n59\n?\n\n\n3\n1\n?\n66\n?\n\n\n4\n0\n61\n?\n?\n\n\n5\n0\n50\n?\n?\n\n\n6\n0\n75\n?\n?\n\n\n平均\n\n62\n70\n8\n\n\n\n\n\n「みんなで薬やろうぜ」って言っていいのか"
  },
  {
    "objectID": "slide/foundation.html#世界一受けたいソンさんの授業",
    "href": "slide/foundation.html#世界一受けたいソンさんの授業",
    "title": "社会科学における因果推論",
    "section": "世界一受けたいソンさんの授業",
    "text": "世界一受けたいソンさんの授業\n履修者5名と非履修者5名の年収の比較\n\nITEは分からないが、平均値の差分を見ると、+100万円の効果\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(ITE_i\\)\n\n\n\n\n1\n1\n?\n700\n?\n\n\n2\n1\n?\n1000\n?\n\n\n3\n1\n?\n550\n?\n\n\n4\n1\n?\n350\n?\n\n\n5\n1\n?\n400\n?\n\n\n6\n0\n400\n?\n?\n\n\n7\n0\n500\n?\n?\n\n\n8\n0\n350\n?\n?\n\n\n9\n0\n750\n?\n?\n\n\n10\n0\n500\n?\n?\n\n\n平均\n\n500\n600\n100"
  },
  {
    "objectID": "slide/foundation.html#世界一受けたいソンさんの授業-1",
    "href": "slide/foundation.html#世界一受けたいソンさんの授業-1",
    "title": "社会科学における因果推論",
    "section": "世界一受けたいソンさんの授業",
    "text": "世界一受けたいソンさんの授業\n履修者5名と非履修者5名の年収の比較（ケース1）\n\nITEは分からないが、平均値の差分を見ると、+100万円の効果\n80万円の価値があるソンさんの講義、みんなで履修しよう!\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(ITE_i\\)\n\n\n\n\n1\n1\n550\n700\n150\n\n\n2\n1\n650\n1000\n350\n\n\n3\n1\n600\n550\n-50\n\n\n4\n1\n300\n350\n50\n\n\n5\n1\n300\n400\n100\n\n\n6\n0\n400\n300\n-100\n\n\n7\n0\n500\n700\n200\n\n\n8\n0\n350\n600\n250\n\n\n9\n0\n750\n700\n-50\n\n\n10\n0\n500\n400\n-100\n\n\n平均\n\n490\n570\n80"
  },
  {
    "objectID": "slide/foundation.html#世界一受けたいソンさんの授業-2",
    "href": "slide/foundation.html#世界一受けたいソンさんの授業-2",
    "title": "社会科学における因果推論",
    "section": "世界一受けたいソンさんの授業",
    "text": "世界一受けたいソンさんの授業\n履修者5名と非履修者5名の年収の比較（ケース2）\n\nITEは分からないが、平均値の差分を見ると、+100万円の効果\nソンさんは悪くない\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(ITE_i\\)\n\n\n\n\n1\n1\n800\n700\n-100\n\n\n2\n1\n650\n1000\n350\n\n\n3\n1\n600\n550\n-50\n\n\n4\n1\n400\n350\n-50\n\n\n5\n1\n350\n400\n50\n\n\n6\n0\n400\n300\n-100\n\n\n7\n0\n500\n500\n0\n\n\n8\n0\n350\n400\n50\n\n\n9\n0\n750\n500\n-250\n\n\n10\n0\n500\n400\n-100\n\n\n平均\n\n530\n510\n-20"
  },
  {
    "objectID": "slide/foundation.html#因果推論の根本問題-2",
    "href": "slide/foundation.html#因果推論の根本問題-2",
    "title": "社会科学における因果推論",
    "section": "因果推論の根本問題",
    "text": "因果推論の根本問題\n\n\\(Y_i(T_i = 1)\\)か\\(Y_i(T_i = 0)\\)、片方のみしか観察できない状態においてITEから因果効果を推定することは不可能\n\n因果推論の根本問題 (The Fundamental Problem of Causal Inference)\n\n\n\n\n解決方法\n\nもう一回、過去に戻って異なる処置を行う"
  },
  {
    "objectID": "slide/foundation.html#因果推論の根本問題-3",
    "href": "slide/foundation.html#因果推論の根本問題-3",
    "title": "社会科学における因果推論",
    "section": "因果推論の根本問題",
    "text": "因果推論の根本問題\n\n\\(Y_i(T_i = 1)\\)か\\(Y_i(T_i = 0)\\)、片方のみしか観察できない状態において、ITEから因果効果を推定することは不可能\n\nただし、ドラえもんが存在する世界線を除く\n因果推論の根本問題 (The Fundamental Problem of Causal Inference)\n\n\n\n\n潜在的結果を直接観察する方法\n\nただし、個々人の潜在的結果ではなく、集団における潜在的結果\n平均処置効果 (ATE; Average Treatment Effect)\n\n平均値の差分から平均的な因果効果を推定\nしかし、…\n\n無作為割当の重要性"
  },
  {
    "objectID": "slide/foundation.html#平均取るだけでok",
    "href": "slide/foundation.html#平均取るだけでok",
    "title": "社会科学における因果推論",
    "section": "平均取るだけでOK?",
    "text": "平均取るだけでOK?\n観察されたデータから差分を計算するだけではATEは推定不可能\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(ITE_i\\)\n\n\n\n\n1\n1\n?\n700\n?\n\n\n2\n1\n?\n1000\n?\n\n\n3\n1\n?\n550\n?\n\n\n4\n1\n?\n350\n?\n\n\n5\n1\n?\n400\n?\n\n\n6\n0\n400\n?\n?\n\n\n7\n0\n500\n?\n?\n\n\n8\n0\n350\n?\n?\n\n\n9\n0\n750\n?\n?\n\n\n10\n0\n500\n?\n?\n\n\n平均\n\n500\n600\n100"
  },
  {
    "objectID": "slide/foundation.html#信頼できるateの条件",
    "href": "slide/foundation.html#信頼できるateの条件",
    "title": "社会科学における因果推論",
    "section": "信頼できるATEの条件",
    "text": "信頼できるATEの条件\nATE推定値の信頼性を損なう敵: 内生性 (しかも、常に存在する)\n例) やる気のある学生だけがソンさんの講義を履修した場合\n\n自己選択バイアス\n\nソンさんの講義は鬼畜すぎるため、やる気満々の学生には役に立つものの、やる気のない学生にとってはむしろ学習意欲が低下\n\n疑似相関\n\nやる気のある学生はいろんな方面で頑張るから、将来年収が高くなる。\n\n測定誤差\n\n履修者の年収はジンバブエ・ドルで測定されている可能性も（これはないか）\n\n\n\n\n内生性は因果推論の敵! どうすれば…?\n\\(\\downarrow\\)\n無作為割当 (Random Assignment)\n\n\n\n\nhttps://www.jaysong.net/kandai-ci"
  },
  {
    "objectID": "slide/matching.html#因果推論と内生性",
    "href": "slide/matching.html#因果推論と内生性",
    "title": "社会科学における因果推論",
    "section": "因果推論と内生性",
    "text": "因果推論と内生性\n内生性: 処置変数と誤差項間の相関関係\n\n内生性は因果推論の敵\n例\n\n処置変数 = ソンさんの講義を履修するか否か\n結果変数 = 10年後の年収\nもし、やる気のある学生が履修する傾向があるとしたら?\nやる気のある学生は履修の有無と関係なく、高所得者になりやすい。\n\\(\\rightarrow\\) 「やる気」は処置と結果、両方と連関している\n\n\n\n\n内生性を除去する最良の手法 \\(\\rightarrow\\) RCT"
  },
  {
    "objectID": "slide/matching.html#rctの限界",
    "href": "slide/matching.html#rctの限界",
    "title": "社会科学における因果推論",
    "section": "RCTの限界",
    "text": "RCTの限界\n\n高費用\n\n数万〜数億円\n\n倫理的な問題による実行不可能性\n\n喫煙と健康\nPhilip Zimbardo. 2008. The Lucifer Effect: How Good People Turn Evil. Rider.\n\n外的妥当性の問題\n\nMichael G. Findley, Kyosuke Kikuta, and Michael Denly. 2021. “External Validity,” Annual Review of Political Science, 24:365-393.\n\n回顧的因果推論には不向き\n\n主に介入 (intervention)の効果が推定対象"
  },
  {
    "objectID": "slide/matching.html#観察データを用いた因果推論",
    "href": "slide/matching.html#観察データを用いた因果推論",
    "title": "社会科学における因果推論",
    "section": "観察データを用いた因果推論",
    "text": "観察データを用いた因果推論\nもし、\\(X\\)をしたら（did）\\(Y\\)はどうなった（would）だろうか\n\n過去を対象にRCTを行うことは不可能\n過去に収集された観察データを使用した因果推論が必要\nマッチング、回帰不連続デザイン、差分の差分法、操作変数法など\n\n\n割当メカニズム (assignment mechanism)\n\nユニットが処置を受けるか否かを規定するメカニズム\n例) 「やる気」が「履修」を規定\n無作為割当なら無作為に処置を受けるか否かが決まるため、考える必要がない。"
  },
  {
    "objectID": "slide/matching.html#内生性への対処",
    "href": "slide/matching.html#内生性への対処",
    "title": "社会科学における因果推論",
    "section": "内生性への対処",
    "text": "内生性への対処\nmatching_data1.csvの例 (架空データ; 30行 \\(\\times\\) 4列)\n\n明らかに「やる気」と「履修」は連関\n履修有無による平均年収の差は約265.333万円\n\n\n\n\n\n\n# A tibble: 10 × 4\n      ID Income Yaruki Rishu\n   <dbl>  <dbl>  <dbl> <dbl>\n 1     1    659      0     1\n 2     2    587      1     1\n 3     3    628      1     1\n 4     4    563      1     1\n 5     5    531      1     1\n 6     6     79      0     0\n 7     7    356      0     1\n 8     8    176      0     0\n 9     9    339      0     0\n10    10    520      1     1\n\n\n\n\n# A tibble: 10 × 4\n      ID Income Yaruki Rishu\n   <dbl>  <dbl>  <dbl> <dbl>\n 1    11    239      0     0\n 2    12    276      1     0\n 3    13    609      1     1\n 4    14    254      0     0\n 5    15    423      0     1\n 6    16    172      0     1\n 7    17     20      0     0\n 8    18    447      1     0\n 9    19    498      1     1\n10    20    648      1     1\n\n\n\n\n# A tibble: 10 × 4\n      ID Income Yaruki Rishu\n   <dbl>  <dbl>  <dbl> <dbl>\n 1    21    155      0     0\n 2    22    768      1     1\n 3    23    463      1     0\n 4    24    309      1     0\n 5    25    304      0     0\n 6    26    408      1     1\n 7    27    259      0     0\n 8    28    516      1     1\n 9    29    476      1     0\n10    30    110      0     0"
  },
  {
    "objectID": "slide/matching.html#内生性への対処-1",
    "href": "slide/matching.html#内生性への対処-1",
    "title": "社会科学における因果推論",
    "section": "内生性への対処",
    "text": "内生性への対処\n方法: 処置変数と結果変数に影響を与える要因(交絡要因)を揃える\n\n「やる気」のない学生（Yaruki == 0）だけに絞ってみる\n履修有無による平均年収の差は209万円\n\n\n\n\n\ndf1 |>\n  filter(Yaruki == 0) |>\n  group_by(Rishu) |>\n  summarise(Inc = mean(Income)) |>\n  pull(Inc)\n\n[1] 193.5 402.5\n\n\n\n402.5 - 193.5\n\n[1] 209\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      ID\n      所得\n      やる気\n      履修\n      　\n      ID\n      所得\n      やる気\n      履修\n    \n  \n  \n    1\n659\n0\n1\n\n6\n79\n0\n0\n    7\n356\n0\n1\n\n8\n176\n0\n0\n    15\n423\n0\n1\n\n9\n339\n0\n0\n    16\n172\n0\n1\n\n11\n239\n0\n0\n    \n\n\n\n\n14\n254\n0\n0\n    \n\n\n\n\n17\n20\n0\n0\n    \n\n\n\n\n21\n155\n0\n0\n    \n\n\n\n\n25\n304\n0\n0\n    \n\n\n\n\n27\n259\n0\n0\n    \n\n\n\n\n30\n110\n0\n0\n    Mean\n402.5\n\n\n\nMean\n193.5"
  },
  {
    "objectID": "slide/matching.html#内生性への対処-2",
    "href": "slide/matching.html#内生性への対処-2",
    "title": "社会科学における因果推論",
    "section": "内生性への対処",
    "text": "内生性への対処\n方法: 処置変数と結果変数に影響を与える要因(交絡要因)を揃える\n\n「やる気」のある学生（Yaruki == 1）だけに絞ってみる\n履修有無による平均年収の差は176.3万円\n\n\n\n\n\ndf1 |>\n  filter(Yaruki == 1) |>\n  group_by(Rishu) |>\n  summarise(Inc = mean(Income)) |>\n  pull(Inc)\n\n[1] 394.2000 570.5455\n\n\n\n570.5455 - 394.2000\n\n[1] 176.3455\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      ID\n      所得\n      やる気\n      履修\n      　\n      ID\n      所得\n      やる気\n      履修\n    \n  \n  \n    2\n587\n1\n1\n\n12\n276\n1\n0\n    3\n628\n1\n1\n\n18\n447\n1\n0\n    4\n563\n1\n1\n\n23\n463\n1\n0\n    5\n531\n1\n1\n\n24\n309\n1\n0\n    10\n520\n1\n1\n\n29\n476\n1\n0\n    13\n609\n1\n1\n\n\n\n\n\n    19\n498\n1\n1\n\n\n\n\n\n    20\n648\n1\n1\n\n\n\n\n\n    22\n768\n1\n1\n\n\n\n\n\n    26\n408\n1\n1\n\n\n\n\n\n    28\n516\n1\n1\n\n\n\n\n\n    Mean\n570.5\n\n\n\nMean\n394.2"
  },
  {
    "objectID": "slide/matching.html#内生性への対処-3",
    "href": "slide/matching.html#内生性への対処-3",
    "title": "社会科学における因果推論",
    "section": "内生性への対処",
    "text": "内生性への対処\n\n\n\n\nやる気のない学生のみ（\\(Z_i = 0\\)）\n\n\n\n履修（\\(T\\)）\n平均年収（\\(Y\\)）\n\n\n\n\n1\n402.5000\n\n\n0\n193.5000\n\n\n\n\n\n\nやる気のある学生のみ（\\(Z_i = 1\\)）\n\n\n\n履修（\\(T\\)）\n平均年収（\\(Y\\)）\n\n\n\n\n1\n570.5455\n\n\n0\n394.2000\n\n\n\n\n\n\n\n\nやる気のある（ない）被験者を一人の被験者として考える場合、差分はITEと解釈可能。\n\nITEの加重平均 \\(\\rightarrow\\) 講義履修の因果効果 \\(\\rightarrow\\) 約191.6万円\n（言い換えれば、）\\(Z = 0\\)の学生のみのATEと\\(Z = 1\\)の学生のみのATEの加重平均\n\n\n\n\n\n\n\n\n\n\\(i\\)\n\\(N\\)\n\\(Z_i\\)\n\\(Y_i(T_i = 1)\\)\n\\(Y_i(T_i = 0)\\)\n\\(\\mbox{ITE}_i\\)\n\n\n\n\n1\n14\n0\n402.5000\n193.5000\n209.0000\n\n\n2\n16\n1\n570.5455\n394.2000\n176.3455\n\n\n\n\n\n\n加重平均\n191.5843"
  },
  {
    "objectID": "slide/matching.html#マッチングの考え方-1",
    "href": "slide/matching.html#マッチングの考え方-1",
    "title": "社会科学における因果推論",
    "section": "マッチングの考え方",
    "text": "マッチングの考え方\n割当メカニズムを想定し、交絡要因が同じユニット同士を比較\n\n交絡要因: 処置変数と結果変数、両方と関係のある変数\n以下の条件が満たされる場合、マッチングで因果効果の推定が可能\n条件付き独立の仮定 (Conditional Independece Assumption; CIA)\n\n\\(\\{Y_i(T_i = 1),Y_i(T_i = 0)\\} \\perp T_i∣X_i\\)\n\\(T_i\\) : 学生 \\(i\\) の履修有無、 \\(X_i\\) : 学生 \\(i\\) のやる気\nやる気(=交絡要因)が同じ場合、学生 \\(i\\) がソンさんの講義を履修するか否か(=処置変数)は彼(女)の将来収入(=結果変数)と関係なく決まる\n\\(\\rightarrow\\) 処置変数を外生変数として扱うことが可能に\n\nCIAが満たされるためには、割当メカニズム上のすべての交絡要因が必要"
  },
  {
    "objectID": "slide/matching.html#条件付き独立の仮定とはmatching_data3.csv",
    "href": "slide/matching.html#条件付き独立の仮定とはmatching_data3.csv",
    "title": "社会科学における因果推論",
    "section": "条件付き独立の仮定とは（matching_data3.csv）",
    "text": "条件付き独立の仮定とは（matching_data3.csv）\n\n\n\n\n\n\n\\(i\\)\n\\(Z_i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mathbb{E}[Y(T = 0)]\\)\n\\(\\mathbb{E}[Y(T = 1)]\\)\n\n\n\n\n統制群（\\(T = 0\\)）\n(A) 0.429\n(B) 0.429\n\n\n処置群（\\(T = 1\\)）\n(C) 0.538\n(D) 0.538\n\n\n\n\n観察可能なデータから計算した処置効果は0.538 − 0.429 = 0.109\n\n真の処置効果は0\n(B)と(C)は反実仮想（counterfactual）\n\nもし、統制群と処置群が同質なら…\n\nA = C、そしてB = Dのはず\n処置群がもし統制群になっても、今の統制群と同じ\n\\(\\Rightarrow\\) 交換可能性が成立せず"
  },
  {
    "objectID": "slide/matching.html#条件付き独立の仮定とは",
    "href": "slide/matching.html#条件付き独立の仮定とは",
    "title": "社会科学における因果推論",
    "section": "条件付き独立の仮定とは",
    "text": "条件付き独立の仮定とは\n\n\n\n\n\n\n\\(i\\)\n\\(Z_i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\\(Z\\) で条件づけた場合 ( \\(Z = 0\\) )\n\n\n\n\n\\(\\mathbb{E}[Y(T = 0)]\\)\n\\(\\mathbb{E}[Y(T = 1)]\\)\n\n\n\n\n統制群（\\(T = 0\\)）\n(A) 0.250\n(B) 0.250\n\n\n処置群（\\(T = 1\\)）\n(C) 0.250\n(D) 0.250\n\n\n\n\n処置効果は0.250 − 0.250 = 0.000\nもし、統制群と処置群が同質なら\nA = C、そしてB = Dが成立\n\\(\\Rightarrow\\) 交換可能性が成立"
  },
  {
    "objectID": "slide/matching.html#条件付き独立の仮定とは-1",
    "href": "slide/matching.html#条件付き独立の仮定とは-1",
    "title": "社会科学における因果推論",
    "section": "条件付き独立の仮定とは",
    "text": "条件付き独立の仮定とは\n\n\n\n\n\n\n\\(i\\)\n\\(Z_i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\\(Z\\) で条件づけた場合 ( \\(Z = 1\\) )\n\n\n\n\n\\(\\mathbb{E}[Y(T = 0)]\\)\n\\(\\mathbb{E}[Y(T = 1)]\\)\n\n\n\n\n統制群（\\(T = 0\\)）\n(A) 0.667\n(B) 0.667\n\n\n処置群（\\(T = 1\\)）\n(C) 0.667\n(D) 0.667\n\n\n\n\n処置効果は0.667 − 0.667 = 0.000\nもし、統制群と処置群が同質なら\nA = C、そしてB = Dが成立\n\\(\\Rightarrow\\) 交換可能性が成立"
  },
  {
    "objectID": "slide/matching.html#条件付き独立の仮定とは-2",
    "href": "slide/matching.html#条件付き独立の仮定とは-2",
    "title": "社会科学における因果推論",
    "section": "条件付き独立の仮定とは",
    "text": "条件付き独立の仮定とは\n\n\n\n\n\n\n\\(i\\)\n\\(Z_i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n条件付き独立が成立するということは…\n\n処置群を統制群に、統制群を処置群にしても同じ結果が得られること\n\n\\(\\Rightarrow\\) 統制群と処置群は交換可能"
  },
  {
    "objectID": "slide/matching.html#重回帰分析との比較",
    "href": "slide/matching.html#重回帰分析との比較",
    "title": "社会科学における因果推論",
    "section": "重回帰分析との比較",
    "text": "重回帰分析との比較\n重回帰分析における回帰係数の解釈\n\n他の変数すべてが同じ場合、ある変数が1単位変化する時の応答変数の変化量\nマッチングと同じ?\n\n重回帰分析とマッチングの結果が近似することも \\(\\bigcirc\\)\n\n手計算マッチング: 191.5843\n\n\n\n\n\n# df1 は matching_data1.csv\n# 単回帰分析\nFit1 <- lm(Income ~ Rishu, data = df1)\n# 重回帰分析\nFit2 <- lm(Income ~ Rishu + Yaruki, data = df1)\n\n\n\n\n\n\n \n  \n      \n    単回帰分析 \n    重回帰分析 \n  \n \n\n  \n    (Intercept) \n    260.400 (36.459) \n    198.595 (32.737) \n  \n  \n    Rishu \n    265.333 (51.561) \n    191.167 (44.915) \n  \n  \n    Yaruki \n     \n    185.415 (45.015) \n  \n  \n    Num.Obs. \n    30 \n    30 \n  \n  \n    R2 \n    0.486 \n    0.684"
  },
  {
    "objectID": "slide/matching.html#重回帰分析との比較-1",
    "href": "slide/matching.html#重回帰分析との比較-1",
    "title": "社会科学における因果推論",
    "section": "重回帰分析との比較",
    "text": "重回帰分析との比較\n実質的にマッチングと回帰分析は同じという見解も (Angrist and Pischke 2009)\n\n具体的に言えば、回帰分析はマッチングの特殊な形態\n\n強い仮定を置いたマッチング\n回帰分析は \\(Y = \\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k\\) の関数型を仮定 (parametric)\n\n回帰分析において誤差項の平均値は必ず0を仮定 ( \\(\\mathbb{E}[\\varepsilon|T, X] = 0\\) )\n\nマッチングの場合、( \\(\\mathbb{E}[\\varepsilon|T = 0, X] = \\mathbb{E}[\\varepsilon|T = 1, X]\\) )\n\n回帰分析はオーバーラップ条件を無視する\n\nマッチングされないケースでも、線形関数によって予測されてしまう\nマッチングはオーバーラップされないケースを分析から除外する\n\n結論: 回帰分析より柔軟、拡張性がある"
  },
  {
    "objectID": "slide/matching.html#ate-att-atc",
    "href": "slide/matching.html#ate-att-atc",
    "title": "社会科学における因果推論",
    "section": "ATE, ATT, ATC",
    "text": "ATE, ATT, ATC\n3種類の因果効果\n\nATE (Average Treatment Effect): 平均処置効果\nATT (ATE for the Treated): 処置群における平均処置効果\n\n潜在結果: 処置群が処置を受けなかった場合の応答変数\n\nATC (ATE for the Control): 統制群における平均処置効果\n\n潜在結果: 統制群が処置を受けた場合の応答変数\n\n\n\n\n因果効果は一般的に母集団ではなく、サンプルから推定されるため、「SATE/SATT/SATC」と呼ばれる場合も\n他にもRIE (Retrospective Intervention Effect) なども (Samii et al. 2016)\nRCTでは主にATEが推定対象（マッチングでは区分するケースが多い）\n統計ソフトウェアによってはATTを因果効果の推定値として表示する場合もある。"
  },
  {
    "objectID": "slide/matching.html#att-処置群における平均処置効果",
    "href": "slide/matching.html#att-処置群における平均処置効果",
    "title": "社会科学における因果推論",
    "section": "ATT: 処置群における平均処置効果",
    "text": "ATT: 処置群における平均処置効果\n\n処置群の潜在的結果を統制群から割り当てる。\n処置群は \\(Y_i(T_i = 1)\\) が観察済みであり、潜在的結果は \\(Y_i(T_i = 0)\\)\nやる気のない学生の \\(Y_i(T_i = 0)\\) は193.5、ある学生は394.2\n\n\n\n\n\n\n\n  \n  \n    \n      ID (i)\n      Yarukii\n      Yi(Ti = 1)\n      Yi(Ti = 0)\n      ITEi\n    \n  \n  \n    1\n0\n659\n193.5\n465.5\n    2\n1\n587\n394.2\n192.8\n    3\n1\n628\n394.2\n233.8\n    4\n1\n563\n394.2\n168.8\n    5\n1\n531\n394.2\n136.8\n    7\n0\n356\n193.5\n162.5\n    ...\n...\n...\n...\n...\n    20\n1\n648\n394.2\n253.8\n    22\n1\n768\n394.2\n373.8\n    26\n1\n408\n394.2\n13.8\n    28\n1\n516\n394.2\n121.8\n    平均 (ATT)\n\n\n\n185.1"
  },
  {
    "objectID": "slide/matching.html#atc-統制群における平均処置効果",
    "href": "slide/matching.html#atc-統制群における平均処置効果",
    "title": "社会科学における因果推論",
    "section": "ATC: 統制群における平均処置効果",
    "text": "ATC: 統制群における平均処置効果\n\n統制群の潜在的結果を処置群から割り当てる。\n統制群は \\(Y_i(T_i = 0)\\) が観察済みであり、潜在的結果は \\(Y_i(T_i = 1)\\)\nやる気のない学生の \\(Y_i(T_i = 1)\\) は402.5、ある学生は570.5\n\n\n\n\n\n\n\n  \n  \n    \n      ID (i)\n      Yarukii\n      Yi(Ti = 1)\n      Yi(Ti = 0)\n      ITEi\n    \n  \n  \n    6\n0\n402.5\n79\n323.5\n    8\n0\n402.5\n176\n226.5\n    9\n0\n402.5\n339\n63.5\n    11\n0\n402.5\n239\n163.5\n    12\n1\n570.5\n276\n294.5\n    14\n0\n402.5\n254\n148.5\n    ...\n...\n...\n...\n...\n    25\n0\n402.5\n304\n98.5\n    27\n0\n402.5\n259\n143.5\n    29\n1\n570.5\n476\n94.5\n    30\n0\n402.5\n110\n292.5\n    平均 (ATC)\n\n\n\n198.1"
  },
  {
    "objectID": "slide/matching.html#ate-平均処置効果",
    "href": "slide/matching.html#ate-平均処置効果",
    "title": "社会科学における因果推論",
    "section": "ATE: 平均処置効果",
    "text": "ATE: 平均処置効果\n\nATTとATCの加重平均\n今回は処置群と統制群が15:15 \\(\\rightarrow\\) 単純平均でOK\n\n\\(\\frac{1}{2}(185.1 + 198.1) = 191.6\\)\n手計算マッチングとと同じ結果\n\n\n\\[\\text{ATE} = \\frac{N_{\\text{treated}}}{N_{\\text{all}}} \\text{ATT} + \\frac{N_{\\text{controlled}}}{N_{\\text{all}}} \\text{ATC}.\\]"
  },
  {
    "objectID": "slide/matching.html#マッチングいろいろ",
    "href": "slide/matching.html#マッチングいろいろ",
    "title": "社会科学における因果推論",
    "section": "マッチングいろいろ",
    "text": "マッチングいろいろ\n\nExact Matching\nNearest-neighbor Matching\n\nk-nearest Neighbor Matching\nCaliper Matching (Radius Matching)\n\nCoarsened Exact Matching\nPropensity Score Matching\n\nInverse Probability Weighting\nEnsemble Matching"
  },
  {
    "objectID": "slide/matching.html#exact-matching",
    "href": "slide/matching.html#exact-matching",
    "title": "社会科学における因果推論",
    "section": "Exact Matching",
    "text": "Exact Matching\n\n「正確マッチング」、「厳格なマッチング」などで訳される\nこれまで見てきた方法が Exact Matching\n\nデータ内の共変量 (交絡要因) が完全に一致するケース同士の比較\n\n共変量が少数、かつ、名目or順序変数の場合、使用可\n共変量が多数、または連続変数の場合は実質的に無理\n\n次元の呪い or 次元爆発"
  },
  {
    "objectID": "slide/matching.html#nearest-neighbor-matching",
    "href": "slide/matching.html#nearest-neighbor-matching",
    "title": "社会科学における因果推論",
    "section": "Nearest-neighbor Matching",
    "text": "Nearest-neighbor Matching\nNearest-neighbor Matching\n\n「最近傍マッチング」と訳される。\n共変量が連続変数、多次元の場合、「完全に一致」ケースはない場合がほとんど\n\n\\(\\rightarrow\\) 「一致」ではなく、「最も似ている」ケース同士と比較\n共変量を座標（超）平面に位置づけた場合、最も近いケースをマッチング\n\n\n\n「近さ」の基準\n\nManhattan Distance\nStandardized Euclidean Distance\nMahalanobis Distance (\\(\\leftarrow\\) 最もよく使われる基準)"
  },
  {
    "objectID": "slide/matching.html#マンハッタン距離manhattan-distance-city-block-distance",
    "href": "slide/matching.html#マンハッタン距離manhattan-distance-city-block-distance",
    "title": "社会科学における因果推論",
    "section": "マンハッタン距離（Manhattan Distance; City-block Distance）",
    "text": "マンハッタン距離（Manhattan Distance; City-block Distance）\n\\[d(i, j) = |X_i - X_j| + |Y_i - Y_j| \\text{ where } i \\neq j.\\]"
  },
  {
    "objectID": "slide/matching.html#標準化ユークリッド距離standardized-euclidean-distance",
    "href": "slide/matching.html#標準化ユークリッド距離standardized-euclidean-distance",
    "title": "社会科学における因果推論",
    "section": "標準化ユークリッド距離（Standardized Euclidean Distance）",
    "text": "標準化ユークリッド距離（Standardized Euclidean Distance）\n\\[d(i, j) = \\sqrt{\\Bigg(\\frac{X_i - X_j}{\\sigma_X}\\Bigg)^2 + \\Bigg(\\frac{Y_i - Y_j}{\\sigma_Y}\\Bigg)^2} \\text{ where } i \\neq j.\\]"
  },
  {
    "objectID": "slide/matching.html#マハラノビス距離mahalanobis-distance",
    "href": "slide/matching.html#マハラノビス距離mahalanobis-distance",
    "title": "社会科学における因果推論",
    "section": "マハラノビス距離（Mahalanobis Distance）",
    "text": "マハラノビス距離（Mahalanobis Distance）\n\n共変量間の相関が0（\\(\\rho = 0\\)）の場合、Standardized Euclidean Distanceと同じ\n\n\\[d(i, j) = \\sqrt{\\frac{1}{1 - \\rho^2_{X, Y}} \\Bigg[\\Bigg(\\frac{X_i - X_j}{\\sigma_X}\\Bigg)^2 + \\Bigg(\\frac{Y_i - Y_j}{\\sigma_Y}\\Bigg)^2 - 2\\rho_{X,Y}\\Bigg(\\frac{X_i - X_j}{\\sigma_X}\\Bigg) \\Bigg(\\frac{Y_i - Y_j}{\\sigma_Y}\\Bigg)\\Bigg]} \\text{ where } i \\neq j.\\]"
  },
  {
    "objectID": "slide/matching.html#マッチング方法",
    "href": "slide/matching.html#マッチング方法",
    "title": "社会科学における因果推論",
    "section": "マッチング方法",
    "text": "マッチング方法\nATTの場合、処置群のケースに統制群の中で最も近いケース1個を割当\n\n近さの測定はマハラノビス距離が一般的\n処置群内の1ケースに複数の統制群ケースを割り当てる場合も\n\nk-nearest Neighbor Matching\nCaliper Matching\n\n復元マッチングと非復元マッチング"
  },
  {
    "objectID": "slide/matching.html#k-nearest-neighbor-matching",
    "href": "slide/matching.html#k-nearest-neighbor-matching",
    "title": "社会科学における因果推論",
    "section": "k-nearest Neighbor Matching",
    "text": "k-nearest Neighbor Matching\n\\(k\\)-最近傍マッチング\n\n最も近い1個ケースを潜在的結果として使うのではなく、最も近い \\(k\\) 個のケースの平均値を潜在的結果として用いる。\n\n\\(j(m)\\) : \\(i\\) から \\(m\\) 番目に近いケース \\(j\\)\n\n\n\\[Y_i(T_i = 0) = \\begin{cases}Y_i & \\text{ if } T_i = 0\\\\ \\frac{1}{K} \\sum_{m = 1}^K Y_{j(m)} & \\text{ if } T_i = 1\\end{cases}\\]\n\n最適 \\(k\\) を決める理論的基準は無し\n\n\\(k\\) を大きくすると、モデルの分散が小さくなる\nただし、モデルの分散が小さい = バイアスが拡大\n\nBias–variance trade-off\n\n\\(k\\) を変化させることによって結果がどのように変わるか観察"
  },
  {
    "objectID": "slide/matching.html#caliper-matching",
    "href": "slide/matching.html#caliper-matching",
    "title": "社会科学における因果推論",
    "section": "Caliper Matching",
    "text": "Caliper Matching\n「カリパーマッチング」と訳される（訳されてない…?）\n\n半径 \\(h\\) の中にある全てのケースの平均値を潜在的結果として使用\n\n\n\n\n\\[Y_i(T_i = 0) = \\begin{cases}Y_i & \\text{ if } T_i = 0\\\\ \\frac{\\sum_{j=1}^N I(T_j = 0, d(i, j) < h)\\cdot Y_i}{\\sum_{j=1}^N I(T_j = 0, d(i, j) < h)} & \\text{ if } T_i = 1\\end{cases}\\]"
  },
  {
    "objectID": "slide/matching.html#復元マッチングと非復元マッチング",
    "href": "slide/matching.html#復元マッチングと非復元マッチング",
    "title": "社会科学における因果推論",
    "section": "復元マッチングと非復元マッチング",
    "text": "復元マッチングと非復元マッチング\n\n1:1マッチングの場合に生じる問題: マッチング済みの統制群（処置群）をどう扱うか\n\n他にも近い処置群のケースがあればマッチング \\(\\rightarrow\\) 復元マッチング\n他にも近い処置群のケースがあっても使わない \\(\\rightarrow\\) 非復元マッチング\n\n復元マッチングの場合、統制群の各ケースに重みが付与される。\n\n加重平均 or 重み付け回帰分析が必要\n\n多くのパッケージは非復元がデフォルトとなっているが、推定ごとに結果が変化することも（図BとC）\n\n復元マッチングはバランスが改善されやすいが、サンプルサイズが小さくなる。\n\n正しい方法はなく、分析者の判断が必要。\n\n\n\n\n\n\n\nA) 復元マッチング\n\n\n\n\n\n\n\nB) 非復元マッチング (1)\n\n\n\n\n\n\n\nC) 非復元マッチング (2)"
  },
  {
    "objectID": "slide/matching.html#coarsened-exact-matching",
    "href": "slide/matching.html#coarsened-exact-matching",
    "title": "社会科学における因果推論",
    "section": "Coarsened Exact Matching",
    "text": "Coarsened Exact Matching\nCoarsened Exact Matching (Iacus, King, and Porro 2011)\n\n定訳はなく、「CEM」で呼ばれる(粗い正確マッチング?)\nアルゴリズムは簡単\n\n共変量をいくつかの層 (strata) へ分割する。\n各層にそれぞれ該当する処置・統制ユニットを入れる。\n最低一つ以上の処置・統制ユニットがない層は捨てる。\n各層の処置・統制ユニットの結果変数の差分を計算し、すべての層に対して加重平均\n\n層を細かくするほどExact Matchingへ近づく\n\nただし、マッチングされないケースが多くなり、分析に使えるケースが減少\nバイアス\\(\\downarrow\\); 分散\\(\\uparrow\\)"
  },
  {
    "objectID": "slide/matching.html#cemの例",
    "href": "slide/matching.html#cemの例",
    "title": "社会科学における因果推論",
    "section": "CEMの例",
    "text": "CEMの例\nmatching_data2.csvの例\n\n年齢は10歳刻み、学歴は大卒以上・未満に層化\n\n\n\n\n\n\n\n  \n  \n    \n      ID\n      年齢\n      教育\n      処置\n      結果\n      　\n      ID\n      年齢\n      教育\n      処置\n      結果\n    \n  \n  \n    1\n29\n院\n0\n6\n\n13\n57\n高\n0\n4\n    2\n41\n大\n0\n3\n\n14\n25\n院\n1\n5\n    3\n31\n院\n1\n7\n\n15\n55\n中\n1\n9\n    4\n39\n院\n0\n5\n\n16\n48\n院\n0\n2\n    5\n53\n大\n0\n6\n\n17\n23\n専\n0\n2\n    6\n59\n大\n0\n1\n\n18\n34\n大\n1\n4\n    7\n37\n高\n1\n8\n\n19\n42\n大\n1\n9\n    8\n44\n中\n0\n4\n\n20\n23\n高\n0\n4\n    9\n51\n中\n0\n2\n\n21\n22\n高\n1\n8\n    10\n59\n小\n1\n8\n\n22\n49\n大\n0\n9\n    11\n21\n大\n1\n4\n\n23\n45\n高\n1\n6\n    12\n24\n中\n1\n6\n\n24\n33\n大\n0\n8"
  },
  {
    "objectID": "slide/matching.html#cemの例-1",
    "href": "slide/matching.html#cemの例-1",
    "title": "社会科学における因果推論",
    "section": "CEMの例",
    "text": "CEMの例\n年齢は10歳刻み、学歴は大卒以上・未満に層化\n\nカテゴリが少なくなり、マッチングしやすくなる\n\n\n\n\n\n\n\n  \n  \n    \n      ID\n      年齢\n      教育\n      処置\n      結果\n      　\n      ID\n      年齢\n      教育\n      処置\n      結果\n    \n  \n  \n    1\n20代\nH\n0\n6\n\n13\n50代\nL\n0\n4\n    2\n40代\nH\n0\n3\n\n14\n20代\nH\n1\n5\n    3\n30代\nH\n1\n7\n\n15\n50代\nL\n1\n9\n    4\n30代\nH\n0\n5\n\n16\n40代\nH\n0\n2\n    5\n50代\nH\n0\n6\n\n17\n20代\nL\n0\n2\n    6\n50代\nH\n0\n1\n\n18\n30代\nH\n1\n4\n    7\n30代\nL\n1\n8\n\n19\n40代\nH\n1\n9\n    8\n40代\nL\n0\n4\n\n20\n20代\nL\n0\n4\n    9\n50代\nL\n0\n2\n\n21\n20代\nL\n1\n8\n    10\n50代\nL\n1\n8\n\n22\n40代\nH\n0\n9\n    11\n20代\nH\n1\n4\n\n23\n40代\nL\n1\n6\n    12\n20代\nL\n1\n6\n\n24\n30代\nH\n0\n8"
  },
  {
    "objectID": "slide/matching.html#cemの例-2",
    "href": "slide/matching.html#cemの例-2",
    "title": "社会科学における因果推論",
    "section": "CEMの例",
    "text": "CEMの例\n\n\n層ごとにケースをマッチング\n\nペアが組めない層が存在\n\n30代 & L\n50代 & H\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      年齢\n      教育\n      \n        処置群\n      \n      \n        統制群\n      \n    \n    \n      ID\n      処置\n      結果\n      ID\n      処置\n      結果\n    \n  \n  \n    20代\nH\n11\n1\n5\n1\n0\n6\n    20代\nH\n14\n1\n5\n\n\n\n    20代\nL\n12\n1\n6\n17\n0\n2\n    20代\nL\n21\n1\n8\n20\n0\n4\n    30代\nH\n3\n1\n7\n4\n0\n5\n    30代\nH\n18\n1\n4\n24\n0\n8\n    30代\nL\n7\n1\n8\n\n\n\n    40代\nH\n19\n1\n9\n2\n0\n3\n    40代\nH\n\n\n\n16\n0\n2\n    40代\nH\n\n\n\n22\n0\n9\n    40代\nL\n23\n1\n6\n8\n0\n4\n    50代\nH\n\n\n\n5\n0\n6\n    50代\nH\n\n\n\n6\n0\n1\n    50代\nL\n10\n1\n8\n9\n0\n2\n    50代\nL\n15\n1\n9\n13\n0\n4"
  },
  {
    "objectID": "slide/matching.html#cemの例-3",
    "href": "slide/matching.html#cemの例-3",
    "title": "社会科学における因果推論",
    "section": "CEMの例",
    "text": "CEMの例\nペアが組めない層を除外（30代Lと50代H）\n\n\n\n\n\n\n  \n  \n    \n      年齢\n      教育\n      \n        処置群\n      \n      \n        統制群\n      \n    \n    \n      ID\n      処置\n      結果\n      ID\n      処置\n      結果\n    \n  \n  \n    20代\nH\n11\n1\n5\n1\n0\n6\n    20代\nH\n14\n1\n5\n\n\n\n    20代\nL\n12\n1\n6\n17\n0\n2\n    20代\nL\n21\n1\n8\n20\n0\n4\n    30代\nH\n3\n1\n7\n4\n0\n5\n    30代\nH\n18\n1\n4\n24\n0\n8\n    40代\nH\n19\n1\n9\n2\n0\n3\n    40代\nH\n\n\n\n16\n0\n2\n    40代\nH\n\n\n\n22\n0\n9\n    40代\nL\n23\n1\n6\n8\n0\n4\n    50代\nL\n10\n1\n8\n9\n0\n2\n    50代\nL\n15\n1\n9\n13\n0\n4"
  },
  {
    "objectID": "slide/matching.html#cemの例-4",
    "href": "slide/matching.html#cemの例-4",
    "title": "社会科学における因果推論",
    "section": "CEMの例",
    "text": "CEMの例\n各ユニットの重みを計算\n\n\n\\[w_i = \\begin{cases} 1 & \\text{ if } T_i = 1, \\\\ \\frac{m_C}{m_T} \\cdot \\frac{m^s_T}{m^s_C} & \\text{ if } T_i = 0.\\end{cases}\\]\n\n\\(m_{C,T}\\): 統制・処置ケースの数\n\nペアを組めなかったケースはカウントしない\n\n\\(m^s_{C,T}\\): 層 \\(s\\) 内の統制・処置ケースの数\n\n\n\n\n\n\n\n\n  \n  \n    \n      年齢\n      教育\n      \n        処置群\n      \n      \n        統制群\n      \n    \n    \n      ID\n      処置\n      結果\n      重み\n      ID\n      処置\n      結果\n      重み\n    \n  \n  \n    20代\nH\n11\n1\n5\n1\n1\n0\n6\n2.2\n    20代\nH\n14\n1\n5\n1\n\n\n\n\n    20代\nL\n12\n1\n6\n1\n17\n0\n2\n1.1\n    20代\nL\n21\n1\n8\n1\n20\n0\n4\n1.1\n    30代\nH\n3\n1\n7\n1\n4\n0\n5\n1.1\n    30代\nH\n18\n1\n4\n1\n24\n0\n8\n1.1\n    40代\nH\n19\n1\n9\n1\n2\n0\n3\n0.367\n    40代\nH\n\n\n\n\n16\n0\n2\n0.367\n    40代\nH\n\n\n\n\n22\n0\n9\n0.367\n    40代\nL\n23\n1\n6\n1\n8\n0\n4\n1.1\n    50代\nL\n10\n1\n8\n1\n9\n0\n2\n1.1\n    50代\nL\n15\n1\n9\n1\n13\n0\n4\n1.1"
  },
  {
    "objectID": "slide/matching.html#cemの例-5",
    "href": "slide/matching.html#cemの例-5",
    "title": "社会科学における因果推論",
    "section": "CEMの例",
    "text": "CEMの例\n重み付け回帰分析\n\n\\(W = \\{2.200, 0.367, 1.000, 1.100, 0.000, 0.000, ..., 1.100\\}^{\\top}\\)\n\nマッチングされないケースの重みは0にするか、分析から除外\n\\(\\beta = (X^{\\top}WX)^{-1}X^{\\top}WY\\)\n\nRの場合、lm(formula, data, weight = ...)で推定可能\n\n{cem} or {MatchIt}パッケージならもっと簡単\n\n\\(\\widehat{\\text{Outcome}} = 4.567 + 2.033 \\cdot \\text{Treat}\\)\n\n処置群における因果効果 (ATT) = 2.033"
  },
  {
    "objectID": "slide/matching.html#傾向スコアとは",
    "href": "slide/matching.html#傾向スコアとは",
    "title": "社会科学における因果推論",
    "section": "傾向スコアとは",
    "text": "傾向スコアとは\nPropensity Score\n\n簡単にいうと「あるユニット \\(i\\) が処置を受ける確率」\n\n\\(e_i = Pr(T_i = 1 | X_i)\\)\n\n\n\nなぜ傾向スコア?\n\nマッチングの限界\n\n次元の問題 (dimension problem)\n恣意性\nカテゴリ変数の扱い方\nスケールの問題"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの計算",
    "href": "slide/matching.html#傾向スコアの計算",
    "title": "社会科学における因果推論",
    "section": "傾向スコアの計算",
    "text": "傾向スコアの計算\n処置変数 ( \\(T_i\\) ) を応答変数とし、共変量 ( \\(X_i\\) ) を説明変数とする\n\n一般的に、ロジットやプロビット回帰分析で推定する。\n\n他にも色々ある\n\nSupport Vector Machine, Decision Tree, Neural Network, …\n\n色んな手法で算出した傾向スコアを重み付けして合成することも可能\n\nEnsemble Method (Samii, Paler, and Zukerman 2016)\n\n\n\n\n\n推定された予測確率 \\(\\rightarrow\\) 傾向スコア\n\nRではオブジェクト名$fitted.valueで抽出可\n傾向スコアは多くの共変量を一つの変数に集約したもの\n\\(\\rightarrow\\) 傾向スコアを統制した回帰分析で因果効果を推定\n\\(\\rightarrow\\) 傾向スコアを用いて最近傍マッチング"
  },
  {
    "objectID": "slide/matching.html#傾向スコアマッチングの手順",
    "href": "slide/matching.html#傾向スコアマッチングの手順",
    "title": "社会科学における因果推論",
    "section": "傾向スコア・マッチングの手順",
    "text": "傾向スコア・マッチングの手順\n割り当てメカニズムを仮定\n\n\n\\[Pr(\\text{処置}) \\propto \\beta_0 + \\beta_1 \\cdot \\text{年齢} + \\beta_2 \\cdot \\text{教育}\\]\n\n\n\n\n\n\n\n  \n  \n    \n      ID\n      年齢\n      教育\n      処置\n      結果\n      　\n      ID\n      年齢\n      教育\n      処置\n      結果\n    \n  \n  \n    1\n29\n院\n0\n6\n\n13\n57\n高\n0\n4\n    2\n41\n大\n0\n3\n\n14\n25\n院\n1\n5\n    3\n31\n院\n1\n7\n\n15\n55\n中\n1\n9\n    4\n39\n院\n0\n5\n\n16\n48\n院\n0\n2\n    5\n53\n大\n0\n6\n\n17\n23\n専\n0\n2\n    6\n59\n大\n0\n1\n\n18\n34\n大\n1\n4\n    7\n37\n高\n1\n8\n\n19\n42\n大\n1\n9\n    8\n44\n中\n0\n4\n\n20\n23\n高\n0\n4\n    9\n51\n中\n0\n2\n\n21\n22\n高\n1\n8\n    10\n59\n小\n1\n8\n\n22\n49\n大\n0\n9\n    11\n21\n大\n1\n4\n\n23\n45\n高\n1\n6\n    12\n24\n中\n1\n6\n\n24\n33\n大\n0\n8"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出",
    "href": "slide/matching.html#傾向スコアの算出",
    "title": "社会科学における因果推論",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\n傾向スコアの算出\n\nPS_Fit <- glm(処置 ~ 年齢 + 学歴, data = データ, family = binomial(\"logit\"))\nsummary(PS_Fit)\n\n\n\n\n\n \n  \n      \n    Model 1 \n  \n \n\n  \n    (Intercept) \n    3.839 (2.364) \n  \n  \n    Age \n    −0.059 (0.039) \n  \n  \n    Edu \n    −0.420 (0.304) \n  \n  \n    Num.Obs. \n    24 \n  \n  \n    AIC \n    35.5 \n  \n  \n    F \n    1.486"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出-1",
    "href": "slide/matching.html#傾向スコアの算出-1",
    "title": "社会科学における因果推論",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\n傾向スコアの抽出\n\nデータ$PS <- PS_Fit$fitted.value\n\n\n\n\n\n\n\n  \n  \n    \n      ID\n      年齢\n      教育\n      処置\n      結果\n      PS\n      　\n      ID\n      年齢\n      教育\n      処置\n      結果\n      PS\n    \n  \n  \n    1\n29\n院\n0\n6\n0.406\n\n13\n57\n高\n0\n4\n0.317\n    2\n41\n大\n0\n3\n0.339\n\n14\n25\n院\n1\n5\n0.463\n    3\n31\n院\n1\n7\n0.378\n\n15\n55\n中\n1\n9\n0.443\n    4\n39\n院\n0\n5\n0.275\n\n16\n48\n院\n0\n2\n0.183\n    5\n53\n大\n0\n6\n0.203\n\n17\n23\n専\n0\n2\n0.692\n    6\n59\n大\n0\n1\n0.152\n\n18\n34\n大\n1\n4\n0.437\n    7\n37\n高\n1\n8\n0.601\n\n19\n42\n大\n1\n9\n0.326\n    8\n44\n中\n0\n4\n0.603\n\n20\n23\n高\n0\n4\n0.774\n    9\n51\n中\n0\n2\n0.502\n\n21\n22\n高\n1\n8\n0.784\n    10\n59\n小\n1\n8\n0.489\n\n22\n49\n大\n0\n9\n0.243\n    11\n21\n大\n1\n4\n0.624\n\n23\n45\n高\n1\n6\n0.485\n    12\n24\n中\n1\n6\n0.831\n\n24\n33\n大\n0\n8\n0.451"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出-2",
    "href": "slide/matching.html#傾向スコアの算出-2",
    "title": "社会科学における因果推論",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\n\n\nATT: 傾向スコアが最も近い統制群を割り当てる\n\n一回マッチングされたケースを除外する vs. しない\n傾向スコアが同じケースが複数ある場合の対処\n\n\n\n\n\n\n\n\n  \n  \n    \n      \n        処置群\n      \n      　\n      \n        統制群\n      \n      差分\n    \n    \n      ID\n      結果\n      PS\n      ID\n      結果\n      PS\n    \n  \n  \n    3\n7\n0.378\n\n1\n6\n0.406\n1\n    7\n8\n0.601\n\n8\n4\n0.603\n4\n    10\n8\n0.489\n\n9\n2\n0.502\n6\n    11\n4\n0.624\n\n8\n4\n0.603\n0\n    12\n6\n0.831\n\n20\n4\n0.774\n2\n    14\n5\n0.463\n\n24\n8\n0.451\n-3\n    15\n9\n0.443\n\n24\n8\n0.451\n1\n    18\n4\n0.437\n\n24\n8\n0.451\n-4\n    19\n9\n0.326\n\n13\n4\n0.317\n5\n    21\n8\n0.784\n\n20\n4\n0.774\n4\n    23\n6\n0.485\n\n9\n2\n0.502\n4\n  \n  \n  \n    \n       差分の平均値 (ATT): 1.818"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出-3",
    "href": "slide/matching.html#傾向スコアの算出-3",
    "title": "社会科学における因果推論",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\n\n\nATC: 傾向スコアが最も近い処置群を割り当てる\n\n\n\n\n\n\n\n  \n  \n    \n      \n        処置群\n      \n      　\n      \n        統制群\n      \n      差分\n    \n    \n      ID\n      結果\n      PS\n      ID\n      結果\n      PS\n    \n  \n  \n    3\n7\n0.378\n\n1\n6\n0.406\n1\n    19\n9\n0.326\n\n2\n3\n0.339\n6\n    19\n9\n0.326\n\n4\n5\n0.275\n4\n    19\n9\n0.326\n\n5\n6\n0.203\n3\n    19\n9\n0.326\n\n6\n1\n0.152\n8\n    7\n8\n0.601\n\n8\n4\n0.603\n4\n    10\n8\n0.489\n\n9\n2\n0.502\n6\n    19\n9\n0.326\n\n13\n4\n0.317\n5\n    19\n9\n0.326\n\n16\n2\n0.183\n7\n    11\n4\n0.624\n\n17\n2\n0.692\n2\n    21\n8\n0.784\n\n20\n4\n0.774\n4\n    19\n9\n0.326\n\n22\n9\n0.243\n0\n    15\n9\n0.443\n\n24\n8\n0.451\n1\n  \n  \n  \n    \n       差分の平均値 (ATC): 3.923"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出-4",
    "href": "slide/matching.html#傾向スコアの算出-4",
    "title": "社会科学における因果推論",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\nATE: ATTとATCの加重平均\n\\[\\begin{align}\\text{ATE} & = \\frac{N_\\text{Treat}}{N_\\text{All}}\\text{ATT} + \\frac{N_\\text{Control}}{N_\\text{All}}\\text{ATC} \\\\ & = \\frac{11}{24} 1.818 + \\frac{13}{24} 3.923 = 2.958\\end{align}\\]\n\n# 第1引数は平均値を求める値のベクトル、第2引数は重みのベクトル\n# 重みは合計1になるように c(0.4583333, 0.5416667) でもOK\nweighted.mean(c(1.818, 3.923), c(11, 13))\n\n[1] 2.958208"
  },
  {
    "objectID": "slide/matching.html#処置を受ける確率の計算",
    "href": "slide/matching.html#処置を受ける確率の計算",
    "title": "社会科学における因果推論",
    "section": "処置を受ける確率の計算",
    "text": "処置を受ける確率の計算\n処置を受ける確率 = 傾向スコア\n\n一般的にはロジスティック/プロビット回帰分析が使われる\nただし、確率が予測できるなら他の手法でも良い\n\nCovariate Balancing Propensity Score\nEntropy Balancing\nNeural Network\nSupport Vector Machine（SVM）\nRandom Forest（RF）など\n\n\n\n\n複数の手法を組み合わせる(= ensemble)することも可能\n\n\\(\\rightarrow\\) Super Learner Algorithm"
  },
  {
    "objectID": "slide/matching.html#傾向スコアのもう一つの使い方",
    "href": "slide/matching.html#傾向スコアのもう一つの使い方",
    "title": "社会科学における因果推論",
    "section": "傾向スコアのもう一つの使い方",
    "text": "傾向スコアのもう一つの使い方\nIPW: Inverse Probability Weighting (Rubin 1985)\n\n「逆確率重み付け」と訳される\n実際に処置を受けた( \\(T_i = 1\\) )にもかかわらず、処置を受ける傾向が 小さい場合は分析において大きい重み\n\n傾向スコアを重み変数として用いる。\n\\(e_i\\) が1または0に近い場合、一部のケースに非常に大きい重みを付け ることになるため、注意が必要\n\n\n\\[w_i = \\begin{cases}\\frac{1}{e_i} & \\text{ if } T_i = 1, \\\\ \\frac{1}{1 - e_i} & \\text{ if } T_i = 0.\\end{cases}\\]\n\n\\(e_i\\) : \\(i\\) の傾向スコア\n\\(T_i\\) : \\(i\\) の処置有無 ( \\(T_i \\in \\{0, 1\\}\\) )"
  },
  {
    "objectID": "slide/matching.html#傾向スコアのもう一つの使い方-1",
    "href": "slide/matching.html#傾向スコアのもう一つの使い方-1",
    "title": "社会科学における因果推論",
    "section": "傾向スコアのもう一つの使い方",
    "text": "傾向スコアのもう一つの使い方\nIPW: Inverse Probability Weighting (Rubin 1985)\n\n「逆確率重み付け」と訳される\n実際に処置を受けた( \\(T_i = 1\\) )にもかかわらず、処置を受ける傾向が 小さい場合は分析において大きい重み\n\n傾向スコアを重み変数として用いる。\n\\(e_i\\) が1または0に近い場合、一部のケースに非常に大きい重みを付け ることになるため、注意が必要\n\n\n\\[w_i = T_i \\frac{1}{e_i} + (1 - T_i) \\frac{1}{1 - e_i}.\\]\n\n\\(e_i\\) : \\(i\\) の傾向スコア\n\\(T_i\\) : \\(i\\) の処置有無 ( \\(T_i \\in \\{0, 1\\}\\) )"
  },
  {
    "objectID": "slide/matching.html#ipw-の考え方",
    "href": "slide/matching.html#ipw-の考え方",
    "title": "社会科学における因果推論",
    "section": "IPW の考え方",
    "text": "IPW の考え方\n\n\n\n\n\n\n\\(i\\)\n\\(Z_i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n条件付き独立の例のデータ（matching_data3.csv）\n\n\\(Pr(Z = 0) = 0.4\\) 、 \\(Pr(Z = 1) = 0.6\\)\n\\(Z = 0\\) の場合\n\n\\(Pr(T = 0) = 0.5\\) 、 \\(Pr(T = 1) = 0.5\\)\n\n\\(Z = 1\\) の場合\n\n\\(Pr(T = 0) = 0.25\\) 、 \\(Pr(T = 1) = 0.75\\)\n\n観察されたデータからは約0.1の処置効果が推定されるが、本当の処置効果は0"
  },
  {
    "objectID": "slide/matching.html#ipwの考え方",
    "href": "slide/matching.html#ipwの考え方",
    "title": "社会科学における因果推論",
    "section": "IPWの考え方",
    "text": "IPWの考え方"
  },
  {
    "objectID": "slide/matching.html#他の考え方",
    "href": "slide/matching.html#他の考え方",
    "title": "社会科学における因果推論",
    "section": "他の考え方",
    "text": "他の考え方\n\n\n\n\n\n\n\\(i\\)\n\\(Z_i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(e_i\\)\n\\(W_i\\)\n\n\n\n\n1\n0\n0\n0\n?\n0.50\n2.00\n\n\n2\n0\n0\n1\n?\n0.50\n2.00\n\n\n3\n0\n0\n0\n?\n0.50\n2.00\n\n\n4\n0\n0\n0\n?\n0.50\n2.00\n\n\n5\n0\n1\n?\n0\n0.50\n\n\n\n6\n0\n1\n?\n0\n0.50\n\n\n\n7\n0\n1\n?\n0\n0.50\n\n\n\n8\n0\n1\n?\n1\n0.50\n\n\n\n9\n1\n0\n1\n?\n0.75\n4.00\n\n\n10\n1\n0\n1\n?\n0.75\n4.00\n\n\n11\n1\n0\n0\n?\n0.75\n4.00\n\n\n12\n1\n1\n?\n1\n0.75\n\n\n\n13\n1\n1\n?\n1\n0.75\n\n\n\n14\n1\n1\n?\n1\n0.75\n\n\n\n15\n1\n1\n?\n1\n0.75\n\n\n\n16\n1\n1\n?\n1\n0.75\n\n\n\n17\n1\n1\n?\n1\n0.75\n\n\n\n18\n1\n1\n?\n0\n0.75\n\n\n\n19\n1\n1\n?\n0\n0.75\n\n\n\n20\n1\n1\n?\n0\n0.75\n\n\n\n\n\n\nもし、全ケースが統制群なら?\n\n\\(Z = 0\\) の統制群は4ケース（ID = 1, 2, 3, 4）\n\\(Z = 0\\) は全部で8ケース（2倍）\n\\(\\rightarrow\\) ケース1〜4の重みを2倍に（\\(W = 2\\)）\n\n\n\n\\(Z = 1\\) の統制群は3ケース（ID = 9, 10, 11）\n\\(Z = 1\\) は全部で12ケース（4倍）\n\\(\\rightarrow\\) ケース9〜11の重みを4倍に（\\(W = 4\\)）"
  },
  {
    "objectID": "slide/matching.html#他の考え方-1",
    "href": "slide/matching.html#他の考え方-1",
    "title": "社会科学における因果推論",
    "section": "他の考え方",
    "text": "他の考え方\n\n\n\n\n\n\n\\(i\\)\n\\(Z_i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(e_i\\)\n\\(W_i\\)\n\n\n\n\n1\n0\n0\n0\n?\n0.50\n\n\n\n2\n0\n0\n1\n?\n0.50\n\n\n\n3\n0\n0\n0\n?\n0.50\n\n\n\n4\n0\n0\n0\n?\n0.50\n\n\n\n5\n0\n1\n?\n0\n0.50\n2.00\n\n\n6\n0\n1\n?\n0\n0.50\n2.00\n\n\n7\n0\n1\n?\n0\n0.50\n2.00\n\n\n8\n0\n1\n?\n1\n0.50\n2.00\n\n\n9\n1\n0\n1\n?\n0.75\n\n\n\n10\n1\n0\n1\n?\n0.75\n\n\n\n11\n1\n0\n0\n?\n0.75\n\n\n\n12\n1\n1\n?\n1\n0.75\n1.33\n\n\n13\n1\n1\n?\n1\n0.75\n1.33\n\n\n14\n1\n1\n?\n1\n0.75\n1.33\n\n\n15\n1\n1\n?\n1\n0.75\n1.33\n\n\n16\n1\n1\n?\n1\n0.75\n1.33\n\n\n17\n1\n1\n?\n1\n0.75\n1.33\n\n\n18\n1\n1\n?\n0\n0.75\n1.33\n\n\n19\n1\n1\n?\n0\n0.75\n1.33\n\n\n20\n1\n1\n?\n0\n0.75\n1.33\n\n\n\n\n\nもし、全ケースが処置群なら?\n\n\\(Z = 0\\) の処置群は4ケース（ID = 5, 6, 7, 8）\n\\(Z = 0\\) は全部で8ケース（2倍）\n\\(\\rightarrow\\) ケース5〜8の重みを2倍に（\\(W = 2\\)）\n\n\n\n\\(Z = 1\\) の処置群は9ケース（ID = 12, 13, 14, … 20）\n\\(Z = 1\\) は全部で12ケース（1.333倍）\n\\(\\rightarrow\\) ケース12〜20の重みを1.333倍に（\\(W = 1.333\\)）"
  },
  {
    "objectID": "slide/matching.html#他の考え方-2",
    "href": "slide/matching.html#他の考え方-2",
    "title": "社会科学における因果推論",
    "section": "他の考え方",
    "text": "他の考え方\n\n\n\n\n\n\n\\(i\\)\n\\(Z_i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(e_i\\)\n\\(W_i\\)\n\n\n\n\n1\n0\n0\n0\n?\n0.50\n2.00\n\n\n2\n0\n0\n1\n?\n0.50\n2.00\n\n\n3\n0\n0\n0\n?\n0.50\n2.00\n\n\n4\n0\n0\n0\n?\n0.50\n2.00\n\n\n5\n0\n1\n?\n0\n0.50\n2.00\n\n\n6\n0\n1\n?\n0\n0.50\n2.00\n\n\n7\n0\n1\n?\n0\n0.50\n2.00\n\n\n8\n0\n1\n?\n1\n0.50\n2.00\n\n\n9\n1\n0\n1\n?\n0.75\n4.00\n\n\n10\n1\n0\n1\n?\n0.75\n4.00\n\n\n11\n1\n0\n0\n?\n0.75\n4.00\n\n\n12\n1\n1\n?\n1\n0.75\n1.33\n\n\n13\n1\n1\n?\n1\n0.75\n1.33\n\n\n14\n1\n1\n?\n1\n0.75\n1.33\n\n\n15\n1\n1\n?\n1\n0.75\n1.33\n\n\n16\n1\n1\n?\n1\n0.75\n1.33\n\n\n17\n1\n1\n?\n1\n0.75\n1.33\n\n\n18\n1\n1\n?\n0\n0.75\n1.33\n\n\n19\n1\n1\n?\n0\n0.75\n1.33\n\n\n20\n1\n1\n?\n0\n0.75\n1.33\n\n\n\n\n\n\n統制群におけるWの和: 20\n処置群におけるWの和: 20\n\\(\\rightarrow\\) 各群におけるWの和はサンプルサイズと一致する\n\\(\\rightarrow\\) 全サンプルが統制/処置群の場合の結果変数の期待値を計算（加重平均）"
  },
  {
    "objectID": "slide/matching.html#他の考え方-3",
    "href": "slide/matching.html#他の考え方-3",
    "title": "社会科学における因果推論",
    "section": "他の考え方",
    "text": "他の考え方\n\n\n\n\n\n\n\\(i\\)\n\\(Z_i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(e_i\\)\n\\(W_i\\)\n\n\n\n\n1\n0\n0\n0\n?\n0.50\n2.00\n\n\n2\n0\n0\n1\n?\n0.50\n2.00\n\n\n3\n0\n0\n0\n?\n0.50\n2.00\n\n\n4\n0\n0\n0\n?\n0.50\n2.00\n\n\n5\n0\n1\n?\n0\n0.50\n2.00\n\n\n6\n0\n1\n?\n0\n0.50\n2.00\n\n\n7\n0\n1\n?\n0\n0.50\n2.00\n\n\n8\n0\n1\n?\n1\n0.50\n2.00\n\n\n9\n1\n0\n1\n?\n0.75\n4.00\n\n\n10\n1\n0\n1\n?\n0.75\n4.00\n\n\n11\n1\n0\n0\n?\n0.75\n4.00\n\n\n12\n1\n1\n?\n1\n0.75\n1.33\n\n\n13\n1\n1\n?\n1\n0.75\n1.33\n\n\n14\n1\n1\n?\n1\n0.75\n1.33\n\n\n15\n1\n1\n?\n1\n0.75\n1.33\n\n\n16\n1\n1\n?\n1\n0.75\n1.33\n\n\n17\n1\n1\n?\n1\n0.75\n1.33\n\n\n18\n1\n1\n?\n0\n0.75\n1.33\n\n\n19\n1\n1\n?\n0\n0.75\n1.33\n\n\n20\n1\n1\n?\n0\n0.75\n1.33\n\n\n\n\n\n\n統制群の加重平均\n\n\\(0 \\cdot 2 + 1 \\cdot 2 + 0 \\cdot 2 + 0 \\cdot 2 + \\dots + 0 \\cdot 4\\)\n\\(\\mathbb{E}^w[Y_0] = 10\\)\n\n処置群の加重平均\n\n\\(0 \\cdot 2 + 0 \\cdot 2 + 0 \\cdot 2 + 1 \\cdot 2 + \\dots + 0 \\cdot 1.33\\)\n\\(\\mathbb{E}^w[Y_1] = 10\\)\n\n\n\n\\[\\mathbb{E}^w[Y_1] - \\mathbb{E}^w[Y_0] = 0\\]"
  },
  {
    "objectID": "slide/matching.html#共変量の選択-1",
    "href": "slide/matching.html#共変量の選択-1",
    "title": "社会科学における因果推論",
    "section": "共変量の選択",
    "text": "共変量の選択\n共変量選択の基準は (星野 2009; Imbens and Rubin 2015など)\n\n処置変数と結果変数、両方と連関があること\n\nOVBと関係\n\n処置前変数と処置後変数の区別\n\n処置変数に時間的に先行しているか否か\n\n処置前変数 (pre-treatment variable) は必ず投入する\n処置後変数 (post-treatment variable) は目的による\n\nというものの、基本的に投入しない\n応答変数よりも時間的に後なら絶対に投入しない"
  },
  {
    "objectID": "slide/matching.html#共変量の選択-2",
    "href": "slide/matching.html#共変量の選択-2",
    "title": "社会科学における因果推論",
    "section": "共変量の選択",
    "text": "共変量の選択\nVanderWeele (2019) のmodified disjunctive cause criterion\n\n処置変数と応答変数どちらかの原因となる変数\n処置変数と応答変数両方の原因となる変数\n操作変数は共変量として投入しない\n上記の基準を満たさない場合でも、観察されていない共変量の代理変数は統制しても良い\n\nしかし、慎重に選択しないとバイアスが拡大\n2.の該当する変数の代理変数が望ましい\n\n\n\n\n詳細はhttps://www.slideshare.net/tintstyle/ss-141543274を参照"
  },
  {
    "objectID": "slide/matching.html#ダイアグラムを使った例",
    "href": "slide/matching.html#ダイアグラムを使った例",
    "title": "社会科学における因果推論",
    "section": "ダイアグラムを使った例",
    "text": "ダイアグラムを使った例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(T \\rightarrow Y\\)の効果は11\n\\(Z\\): \\(T\\)と\\(Y\\)の原因 \\(\\leftarrow\\) 投入\n\\(A\\): 操作変数 \\(\\leftarrow\\) 除外\n\\(X\\): \\(Y\\)の原因 \\(\\leftarrow\\) 投入\n\\(V\\): \\(T\\)の結果 \\(\\leftarrow\\) 除外\n\\(W\\)は…?"
  },
  {
    "objectID": "slide/matching.html#ダイアグラムを使った例-1",
    "href": "slide/matching.html#ダイアグラムを使った例-1",
    "title": "社会科学における因果推論",
    "section": "ダイアグラムを使った例",
    "text": "ダイアグラムを使った例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(T \\rightarrow Y\\): 直接効果\n\\(T \\rightarrow W \\rightarrow Y\\): 間接効果\n\n\\(W\\)は中間変数（mediate variable）\n\n因果推論では主に全効果 (total effect) に関心があるため\\(W\\)は投入しない\n\n全効果: 直接効果 + 間接効果\n\\(T\\)が変動したら\\(W\\)も必ず変わるため、\\(T\\)のみの効果はあまり意味なし\n直接効果のみ推定する場合、\\(W\\)も統制\n\n例) 就職市場における人種差別の例\n\n\n結論: \\(Z\\)と\\(X\\)のみ統制\n\n実は\\(X\\)は入れなくてもOK"
  },
  {
    "objectID": "slide/matching.html#ダイアグラムのツール",
    "href": "slide/matching.html#ダイアグラムのツール",
    "title": "社会科学における因果推論",
    "section": "ダイアグラムのツール",
    "text": "ダイアグラムのツール\nDAGitty — draw and analyze causal diagrams\n\nウェーブページ or Rパッケージ{dagitty}（http://www.dagitty.net/）\n\n\n\n\n\npacman::p_load(ggdag)\nDAG1 <- dagitty(\n  \"dag {\n  T -> Y\n  T -> W -> Y\n  T <- Z -> Y\n  A -> T\n  X -> Y\n  T -> V\n  }\"\n)\n\n\n\n\n\n# Total Effect推定のための共変量\nadjustmentSets(DAG1, \n               exposure = \"T\", outcome = \"Y\",\n               effect = \"total\")\n\n{ Z }\n\n# Direct Effect推定のための共変量\nadjustmentSets(DAG1, \n               exposure = \"T\", outcome = \"Y\",\n               effect = \"direct\")\n\n{ W, Z }"
  },
  {
    "objectID": "slide/matching.html#ダイアグラムのツール-1",
    "href": "slide/matching.html#ダイアグラムのツール-1",
    "title": "社会科学における因果推論",
    "section": "ダイアグラムのツール",
    "text": "ダイアグラムのツール\n{ggdag}を用いた可視化\n\n詳細は『私たちのR』第20章を参照\n\n\n\n\n\ncoordinates(DAG1) <- list(\n  x = c(T = 1, Y = 5, Z = 3, W = 3, \n        A = 2, V = 2, X = 4),\n  y = c(T = 2, Y = 2, Z = 3, W = 4, \n        A = 1, V = 4, X = 1)\n)\nggdag(DAG1, stylized = TRUE) +\n  theme_dag_blank()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttps://www.jaysong.net/kandai-ci"
  },
  {
    "objectID": "intro/filesystem.html",
    "href": "intro/filesystem.html",
    "title": "本講義のためのファイル管理術",
    "section": "",
    "text": "PC内に存在するほとんどのファイルは「名前.拡張子」と名付けられている1。名前の拡張子は.で区切られており、名前は英数字と_のみで構成することを推奨する（ファイル名に.が推奨されない理由の一つが名前と拡張子を区分する文字として使われるからだ）。ここで注目したいのはファイルの名前でなく、拡張子のことだ。拡張子とはファイルの特徴を示すものである。たとえば、拡張子が.htmlであれば、ウェブページ形式を意味し、.pngなら図、.pdfなら図・文書、.exeなら実行ファイル、.dmgならディスクイメージを意味する。ファイル名がFigure01.pngならFigure01という名の画像ファイルであることを意味する2。この拡張子によって、パソコンは当該ファイルをどのアプリケーションで開くかを判定する。.exeファイルをダブルクリックするとアプリケーションが立ち上がるし、.pdfファイルをダブルクリックするとPDFビュアーソフトが起動され、中身が表示される。\n　これは拡張子を変えると問題が生じ得ることを意味する。画像ファイルであるFigure01.pngのファイル名を動画ファイル拡張子であるMovie01.mp4に修正しても、そのファイルは動画ファイルにはならない。また、拡張子が.mp4になると、そのファイルを開く際、動画プレイヤーが起動されるが、ファイルの中身は画像ファイルのままなのでエラーが出る。したがって、拡張子は勝手に変えてはならない。たまに課題の結果物としてファイルを提出する際、自分の名前を入れたくてファイル名をXXXX.htmlからXXXX.html_Songへ変更して提出する場合がある。しかし、これは大きな間違いだ。もやはこのファイルはHTMLファイル（.html）でなく、未知のファイル形式（.html_Song）として認識され、ダブルクリックしてもPCはどのアプリケーションで開けば良いかが分からなくなる。ファイル名を修正するならXXXX_Song.htmlのように修正しよう3。\n　Rを用いたデータ分析の場面において頻繁に登場する拡張子は以下の通りである。ファイルの名前は大文字と小文字を区別するが、拡張子の場合、区別されないケースが多い。\n\n\n\n\n\n\n\n\n拡張子\n説明\n備考\n\n\n\n\n.R\nRスクリプトファイル\n\n\n\n.Rproj\nRプロジェクトファイル\n\n\n\n.Rmd\nR Markdownファイル\n\n\n\n.qmd\nQuartoファイル\nRMarkdownに似たようなもの\n\n\n.csv\n表形式ファイル\n業界標準のフォーマット\n\n\n.xlsx or .xls\n表形式ファイル\nExcelで使うフォーマット\n\n\n.dta\n表形式ファイル\nStataで使うフォーマット\n\n\n.sav\n表形式ファイル\nSPSSで使うフォーマット\n\n\n.html\nウェブページファイル\nR Markdown/QuartoをKnitした場合に得られる\n\n\n.png\n画像ファイル\n\n\n\n.pdf\n画像/文書ファイル\n画像にも文書にもなるファイル"
  },
  {
    "objectID": "intro/filesystem.html#ファイルシステム",
    "href": "intro/filesystem.html#ファイルシステム",
    "title": "本講義のためのファイル管理術",
    "section": "2 ファイルシステム",
    "text": "2 ファイルシステム\n　R上でファイルを入出力を行うためにはファイルシステム（file system）を理解する必要がある。\n\n2.1 ファイルの入出力\n　そもそも、ファイルの「入出力」とは何だろうか。これはコンピューターの構造に関わる話なので極めて難しい内容であるが、我々のような消費者（end user）側から見れば、ファイルの入力（input）とは、いわゆるファイルの読み込みを意味し、多くの場合、表形式のデータ（.csv、.xlsxなど）をR上に読み込む作業を意味する。また、ファイルの出力（output）とは、いわゆるファイルの保存。たとえば、作成したスクリプトを.R形式で保存したり、クリーニングしたデータを.csv形式で保存したり、作成した図を.png、.pdf形式で保存したらい、作成した文書を.pdf、.html形式で保存したらいすることがファイルの出力だ。\n\n\n2.2 パスとは\n　ファイルを読み込む場合はファイル名を指定する必要がある。また、ファイルを書き出す場合もファイルに名付ける必要がある。そしてファイル名は名前.拡張子である。ただし、これらのファイルは全て一箇所に集まっているわけではない。もし、全てのファイルが一箇所に集まっていると、必要なファイルを探すのは非常に難しい。通常、PC内には数万のファイルがある。これらのファイルから必要なファイルを探すのは至難の業だろう。したがって、これらのファイルをいくつかの部屋に分けて保管し、この部屋のことをフォルダー（folder）、またはディレクトリ（directory）と呼ぶ（ここでは「フォルダー」と呼ぶとする）。\n　これは我々が住んでいる居住地の「住所」と同じ概念だ。もし、日本に「都道府県」も「市区町村」も「〜丁目、〜番、〜号」という概念がないとしよう。ここでAmazonで魚を購入し、受取先を指定する場合はどうすれば良いだろうか。日本に人が数十人しか住んでいないのであれば、「XXXさんの家」と書くだけで十分かも知れない。しかし、日本には1億人以上の人がある。「ソンさんの家」と書いても届かない。届いたとしても数年、あるいは数十年後に魚の化石の状態で届くかも知れない。そもそも日本に「ソンさん」はこの授業の担当教員以外にもいくらでもいる（ちなみに송（Song; 宋・松）さんも、손（Sohn; 孫）さんも、성（Seong/Sung; 成・星）さんも、선（Sun/Seon; 宣）さんも韓国語では発音が全く別だが、日本ではソンさんになってしまう。）。それぞれの家を何かの区域内に位置づけないとモノが届くまで数年かかってしまう。そこで必要なのが住所だ。「東京都千代田区永田町1丁目7番1号の田中さん」は「東京都」、「千代田区」、「永田町」、「1丁目」、「7番」、「1号」、「田中さん」で構成される。これをファイルシステムに例えると、東京都というフォルダーの中に千代田区というフォルダーがあり、その中には永田町というフォルダー、その中に1丁目といるファルダー、…が存在する。むろん、一つのフォルダーには複数のフォルダーが存在する可能性もある。東京都のフォルダーには千代田区以外にも大田区、中野区、文京区、葛飾区といった複数のフォルダーがあり、千代田区の中にも複数のフォルダーがある。最後の「田中さん」は受け取る人、コンピューターでいるファイル名である。\n　この住所のことをコンピューターではパス（path）と呼ぶ。それぞれのフォルダーは/で区切られる（macOS/Linuxでは/、Windowsでは\\または￥; NIIオンライン分析システムはLinuxベースである）。先ほどの住所の例だと、東京都/千代田区/永田町/1丁目/7番/1号/田中さんとなる（macOS/Linuxの場合）。左に行くほど上位のフォルダーとなり、最後のものはファイル名である。ただし、コンピュターではパスの最初に/を付ける。Windowsなら主にC:\\でスタートし、C:\\東京都\\千代田区\\永田町\\1丁目\\7番\\1号\\田中さんとなる。\n　たとえば、以下のような構造でファイルが保存されているとしよう。拡張子が付いているものはファイル、それ以外はフォルダー、1行目の.は最上位フォルダーである。\n\n\n                      levelName\n1  .                           \n2   ¦--Day01                   \n3   ¦   ¦--Day01.Rproj         \n4   ¦   ¦--Script01.R          \n5   ¦   ¦--Script02.R          \n6   ¦   ¦--Data                \n7   ¦   ¦   ¦--raw_data.csv    \n8   ¦   ¦   °--cleaned_data.csv\n9   ¦   °--Figs                \n10  ¦       ¦--Figure01.png    \n11  ¦       °--Figure02.png    \n12  °--Day02                   \n13      ¦--Day02.Rproj         \n14      ¦--Script01.R          \n15      ¦--Document01.Rmd      \n16      ¦--Document01.html     \n17      ¦--Data                \n18      ¦   °--my_data.csv     \n19      °--Figs                \n20          ¦--Old             \n21          ¦   ¦--Figure01.pdf\n22          ¦   ¦--Figure02.pdf\n23          ¦   °--Figure03.pdf\n24          °--New             \n25              °--Figure01.png\n\n\n　ここでread_csv()関数を使ってDay01フォルダー内のDataフォルダー内のraw_data.csvを読み込む場合はread_csv(\"/Day01/Data/raw_data.csv\")となる。また、ggsave()を用いて、Day02内のFigs内のNew内にFigure02.pngという名で図を保存する場合は、ggsave(filename = \"/Day02/Figs/New/Figure02.png\", ...)と入力する必要がある。しかし、通常、パスを指定する際に、/（WindownならC:\\）から始めることは滅多にない。それは「作業フォルダーはパスで省略可能」だからだ。"
  },
  {
    "objectID": "intro/filesystem.html#rstudioのプロジェクト機能",
    "href": "intro/filesystem.html#rstudioのプロジェクト機能",
    "title": "本講義のためのファイル管理術",
    "section": "3 RStudioのプロジェクト機能",
    "text": "3 RStudioのプロジェクト機能\n　Rでファイルを入出力する時に頭に入れておくべき概念として「作業フォルダー（working folder/working directory）」がある。通常、Rの作業フォルダーはmacOSだと/Users/ユーザー名/、NIIオンライン分析システムだと/home/joyvan/が作業フォルダーだ。そして、パスを指定する場合、作業フォルダーは省略することができる。つまり、現在の作業フォルダーが/home/joyvan/なら\"/home/joyvan/Day01/Data/raw_data.csv\"は\"Day01/Data/raw_data.csv\"に、\"/home/joyvan/Day02/Figs/New/Figure02.png\"は\"Day02/Figs/New/Figure02.png\"に省略される。我々が郵便局で手紙を送る際、住所にわざわざ「日本国」と書かないものと同じである。作業フォルダーはRコンソール上でgetwd()と入力すれば出力される。macOSなら/Users/ユーザー名、NIIオンライン分析システムなら/home/joyvanと出力される。\n\n\n\n\n\n\n最上位フォルダーの話\n\n\n\n　macOSとLinuxに限定した話であるが、最上位フォルダーは/であり、これはシステム上の最上位フォルダーである。個人レベルの最上位フォルダーはmacOSだと/Users/ユーザー名、NIIオンライン分析システムだと/home/joyvanである。そして、この個人レベルの最上位フォルダーは~/と表記することができる。Rコンソールでgetwd()を入力し、以上のように出力されれば個人レベルの最上位フォルダー（~/）が作業フォルダーになっている理解しても良い。ちなみに、WindowsはC:\\がシステム上の最上位フォルダーである。\n\n\n　もし、自分がこれから全ての作業をDay03という名のフォルダー内で完結するとする。つまり、保存するスクリプト（たとえば、Script.R）もDay03に保存し、図（たとえば、FigureA.png）はDay03のFigsフォルダーに、読み込む表形式データ（たとえば、Day03_Data.csv）もDay03の中のDataフォルダーに入れるとする。この場合、それぞれのファイルのパスはDay03/Script.R、Day03/Figs/FigureA.png、Day03/Data/Day03_Data.csvとなる（作業フォルダーが~/であるため、~/は省略可能）。全ての作業が同じフォルダー（とその下位フォルダー）内で行うとしたら、パス名にDay03も不要な気がする。そこで必要なのがRStudioのプロジェクト機能である。\n　RStudioでDay03というプロジェクトを作成すると、Day03フォルダーが自動的に生成され、Day03.Rprojというファイルも生成される。プロジェクトを最上位フォルダーに作成したのであれば、~/Day03/Day03.Rprojファイルが生成されるのである。ここでRStudioのFile > Open ProjectでこのDay03.Rprojファイルを開くとRStudio画面の右上にプロジェクト名が表示され、作業フォルダーがDay03.Rprojが保存されているフォルダー、つまり~/Day03へ変更される（プロジェクトが開かれていな場合は「Project: (None)」と表示される）。実際、NIIオンライン分析システムでXXXという名前のプロジェクトを生成し、そのプロジェクトを開けば作業フォルダーは/home/joyvan/XXX/（=~/XXX/）になる（getwd()で確認可能）。これは大変便利な機能である。なぜなら作業フォルダーまでのパスは全て省略可能だからだ。これまでDay03/Script.R、Day03/Figs/FigureA.png、Day03/Data/Day03_Data.csvだったパスが、それぞれScript.R、Figs/FigureA.png、Data/Day03_Data.csvになる。\n　また、何らかの理由でDay03フォルダーの名前をDay05に変更したとしよう。もし、プロジェクト機能を使っていないのであれば、パスのDay03を全てDay05に変更する必要がある。しかし、プロジェクト機能を使っているのであれば、.Rprojファイルが存在するフォルダーが作業フォルダーになるため、そもそもパスにDay03は存在しない。つまり、修正不要ということだ。ちなみに、プロジェクトを一旦作成したら、そのプロジェクトのフォルダー名や.Rprojファイルの名前は自由に修正しても良いし、フォルダー名と.Rprojファイルの名前が一致しなくても良い。\n　以上の内容をまた住所と郵便の話で例えるとしよう。社内でも郵便物の行き来は頻繁に行われる。とりわけ面積が広く、キャンパスも複数ある大学なら尚更だ。たとえば、「大阪府吹田市山手町3-3-35 関西大学 ラーメン学部」の宋が「大阪府吹田市山手町3-3-35 関西大学 ラーメン研究支援課」の金に郵便を送る場合、同じ大学であるにも関わらず、住所を全て書くのは面倒なことであろう。ここで関西大学専用の郵便局を作れば問題は解決される（「学内便」と呼ばれる）。そうすれば差出人は「ラーメン学部　宋」、受取人は「ラーメン研究支援課　金」と書くだけで郵便物は届く。つまり、「大阪府吹田市山手町3-3-35 関西大学」は省略できる（同じ市区町村内の引っ越した際、転入・転出届けの住所欄に市区町村名までは省略できるのと同じ）。また、関西大学がなぜかキャンパスを沖縄に移転した場合を考えてみよう。学内便がなければ、郵便物の住所を全て「沖縄県〜」に変えなければならない。しかし、学内便が存在すればこれまで使ってきた「ラーメン学部　宋」という表記は有効であろう。\n　このようにRStudioのプロジェクト機能は必須といっても過言ではない。簡単な計算目的として使う場合は問題ないが、何かの分析をする時、授業の実習時、課題時には必ずRStudioの右上が「Project: (None)」になっていないことを確認しよう。\n\n\n\n\n\n\n絶対パスと相対パス\n\n\n\n　これまで紹介したパスの書き方で/（WindowsならC:\\）から始まるパスは、絶対パス（absolute path）またはフルパス（full path）と呼ばれる。これはファイル名を最上位フォルダーを起点に書く方法である。一方、/（WindowsならC:\\）で始まらないパスは相対パス（relative path）呼ばれ、ファイル名を作業フォルダーを起点に書く方法である。"
  },
  {
    "objectID": "intro/filesystem.html#本講義でおすすめするフォルダー構造",
    "href": "intro/filesystem.html#本講義でおすすめするフォルダー構造",
    "title": "本講義のためのファイル管理術",
    "section": "4 本講義でおすすめするフォルダー構造",
    "text": "4 本講義でおすすめするフォルダー構造\n　プロジェクトを作成すれば、プロジェクトフォルダー内に以下のようなフォルダーを作成しよう。\n\n表形式のデータを読み込んだり、保存したりするのであればDataフォルダーをプロジェクトフォルダー内に作成する。\n\n.csv、.xlsx、.sav、.dtaのような表形式ファイルはDataフォルダーに入れる。\nデータを加工し、保存する場合はData/ファイル名.csvなどと指定する。\n\n図を作成し、保存する予定があれば、Figsフォルダーをプロジェクトフォルダー内に作成する。\n\n図を保存する場合、ファイルのパスをFigs/ファイル名.pngやFigs/ファイル名.pdfとする。\n\n\n　よく分からない場合はとりあえずプロジェクトフォルダー内にDataとFigsというフォルダーを作っておこう。ただし、.R、.Rmdなどコードファイルはプロジェクトフォルダーの下位フォルダーに入れず、プロジェクトフォルダーの直に入れよう4。この場合、R Markdown / Quartoで作成された文書（.html、.pdfなど）は.Rmdや.qmdファイルと同じフォルダーに保存される（別途の設定をすれば別フォルダーに保存することも可能だが、そこまではしなくても良い）。"
  },
  {
    "objectID": "intro/filesystem.html#参考",
    "href": "intro/filesystem.html#参考",
    "title": "本講義のためのファイル管理術",
    "section": "5 参考",
    "text": "5 参考\n　以下の内容も合わせて読むことを強く推奨する。\n\n宋財泫・矢内勇生.『私たちのR』の第6.1章: コンピュータの基礎知識"
  },
  {
    "objectID": "intro/file.html",
    "href": "intro/file.html",
    "title": "ファイル管理",
    "section": "",
    "text": "フォルダー/ファイルの管理はJupyterHub内でも、RStudio内でもできるが、ここではRStudio側で管理する方法を紹介する。RStudioを起動し、作業するプロジェクトを開き、Filesペインを確認しよう。RStudioを経由したフォルダー/ファイルの管理は全てFilesペイン上で行われる。"
  },
  {
    "objectID": "intro/file.html#フォルダーの管理",
    "href": "intro/file.html#フォルダーの管理",
    "title": "ファイル管理",
    "section": "1 フォルダーの管理",
    "text": "1 フォルダーの管理\n　講義、または課題ごとのプロジェクトを作ったら、JupyterHubにプロジェクトのフォルダーが生成される。各プロジェクトごとにRスクリプト、Markdownファイル、出力物（図、文書など）が管理できるが、プロジェクト内のファイルが多くなる可能性もある。この場合、プロジェクト・フォルダー内に更に下位フォルダーを作成し、ファイルを管理した方が望ましい。\n\n1.1 フォルダーの作成\n手順1: 現在、Filesペインで表示されているフォルダーがプロジェクトの最上位フォルダーであることを確認する。「Home > プロジェクト名」と表示されていれば問題ない。\n\n\n\n\n\n\n\n\n\n手順2: New Folderをクリックする。\n\n\n\n\n\n\n\n\n\n手順3: 作成するフォルダーの名前を入力する。ここではデータなどを集めておくDataという名のフォルダーを作成する。\n\n\n\n\n\n\n\n\n\n手順4: 正しくフォルダーが作成されているかを確認する。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nフォルダー名の付け方\n\n\n\nフォルダー名にはローマ字、数字のみを使おう。スペースもなるべく使わず、空白を入れたい場合はスペースの代わりにアンダースコア（_）を使おう。\n\n\n\n\n\n\n\n\nフォルダー in フォルダー\n\n\n\nフォルダー内に更にフォルダーを作成することもできる。一つのフォルダー内にファイルが多すぎる場合、更にフォルダー分けして管理した方が効率的だろう。\n\n\n\n\n1.2 フォルダーの削除\n\n\n\n\n\n\nフォルダーの削除は慎重に!\n\n\n\nフォルダーを削除するとフォルダー内のファイルも全て削除される。削除する前には慎重にフォルダー内のファイルを確認しておくこと。\n\n\n手順1: 削除するフォルダーの左にチェックを付け、Deleteをクリックする。\n\n\n\n\n\n\n\n\n\n手順2: Yesをクリックする。"
  },
  {
    "objectID": "intro/file.html#ファイルの管理",
    "href": "intro/file.html#ファイルの管理",
    "title": "ファイル管理",
    "section": "2 ファイルの管理",
    "text": "2 ファイルの管理\n　分析に使用するデータセットを自分のPCにダウンロードしてもそのままNIIオンライン分析システムで使うことはできない。NIIオンライン分析システムで使用するためには、ファイルをアップロードする必要がある。これはデータだけでなく、本講義の課題用ファイルについても同様である。\n\n2.1 ファイルのアップロード\n手順1: ファイルをアップロードしたいフォルダーへ移動する。\n\n下位フォルダーへの移動: フォルダー名をクリックする。\n上位フォルダーへの移動: 「..」をクリックするか、パスが表示されているバーで移動先をクリックする。\n\n手順2: ファイルのアップロード先が正しいかを確認し、Uploadをクリックする。\n\n以下の例はHomework_01プロジェクト・フォルダー内のDataフォルダーがアップロード先である。\n\n\n\n\n\n\n\n\n\n\n手順3: File to upload:でアップロードしたいファイルを選択する。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n複数のファイルをアップロードしたい場合\n\n\n\nRStudio上でファイルは一度の一つしかアップロードできない。複数のファイルを同時にアップロードしたい場合は、この作業を繰り返すか、JupyterHubのホーム画面でアップロードする必要がある。\n\n\n手順4: アップロードするファイルをダブルクリックする。\n\n以下ではPrev_Vote.csvというファイルをアップロードする例である。\n\n\n\n\n\n\n\n\n\n\n手順5: OKをクリックする。\n\n\n\n\n\n\n\n\n\n手順6: 正しくファイルがアップロードされているかを確認する。\n\n\n\n\n\n\n\n\n\n\n\n2.2 ファイルのダウンロード\n　作成した図表をLaTex/Microsoft Word/Powerpoint/Pages/Keynoteなどで使うためには、その図表を自分のPCにダウンロードする必要がある。同様に、課題の出力物をLMSに提出するためにも、出力物を一旦自分のPCにダウンロードしてから提出する必要がある。\n\n\n\n\n\n\n複数ファイルのダウンロード\n\n\n\nアップロードは一度ごとに一つのファイルしかアップロードできないが、ダウンロードは複数のファイルを同時にダウンロードできる。ただし、個別のファイルがダウンロードされるのではなく、一つのファイルととして圧縮（zip形式）されてからダウンロードされる。ダウンロード後はファイルを解凍すること。\n\n\n手順1: ダウンロードするファイル名の左にチェックを付ける。\n\n以下ではMicro_HW01.htmlというファイルをダウンロードする例である。\n\n\n\n\n\n\n\n\n\n\n手順2: More > Export…をクリックする。\n\n\n\n\n\n\n\n\n\n手順3: Downloadをクリックする。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n課題の出力物は提出する前に必ず確認を!!\n\n\n\nLMSで課題を提出するためには出力物を提出する必要があるが、提出する前にダウンロードしたファイルを必ず確認しよう。間違ったファイルを提出した場合でも提出期限内なら差し替え可能だが、期限が過ぎた場合、理由を問わず差し替えは認めない。また、間違ったファイルが提出されたことを宋が個別に知らせることもないため注意しよう。\n\n\n\n\n2.3 ファイルの削除\nフォルダーの削除と同じ手順で削除できる。"
  },
  {
    "objectID": "intro/file.html#参考-本講義で推奨するファイルフォルダー構造",
    "href": "intro/file.html#参考-本講義で推奨するファイルフォルダー構造",
    "title": "ファイル管理",
    "section": "3 参考) 本講義で推奨するファイル/フォルダー構造",
    "text": "3 参考) 本講義で推奨するファイル/フォルダー構造\n\nプロジェクト機能は必ず使用し、RStudioの右上が「Project: (None)」になっている場合、プロジェクトを作成するか、既存のプロジェクトを開く。右上のにプロジェクト名が表示されていればOK\nコードが含まれたファイル（.R、.Rmd、.qmdなど）はプロジェクトフォルダーの直に入れる。R Markdownの出力物の基本的にここに保存される。\nDataフォルダーを作成し、データファイル（.csv、.xlsxなど）はDataフォルダーに入れる。\nグラフを作成し、保存する場合はプロジェクト・フォルダーにFigsフォルダーを作成し、そこに保存する。\n\n\n\n\n\n\n\nファイルの場所が分からない\n\n\n\nFileペインではファイルの一覧が確認できる。しかし、これらのファイルがどのフォルダーに入っているかが分からない場合もあろう。この場合、Fileペインの上段バーを確認すること。そこに現在表示されているファイルのパスが表示されている。「Home>プロジェクト名」と表示されている場合、Fileペインに見えるファイルはプロジェクト・フォルダ―直に入っていることを意味する（右上のプロジェクト名とFileペインのプロジェクト名が一致しているか確認すること）。これらのファイルのパスは\"ファイル名\"のみで良い。上段バーのパスが「Home>プロジェクト名>Data」になっている場合、表示されているファイルはプロジェクト・フォルダー内のDataフォルダーに入っていることを意味する。これらのファイルのパスは\"Data/ファイル名\"となる。"
  },
  {
    "objectID": "intro/homework.html",
    "href": "intro/homework.html",
    "title": "課題の取り組み方",
    "section": "",
    "text": "課題の取り組み方が分からない?\n\n\n\n必ず宋と相談すること。"
  },
  {
    "objectID": "intro/homework.html#step1-課題ファイル一式の入手",
    "href": "intro/homework.html#step1-課題ファイル一式の入手",
    "title": "課題の取り組み方",
    "section": "Step1: 課題ファイル一式の入手",
    "text": "Step1: 課題ファイル一式の入手\n手順1: LMSの授業ページから「第XX回 課題資料」を選択する。\n\n以下の画面は2021年度のページである。\nタイトルは「第XX回 課題資料」でなく「第XX回 課題用ファイル」など変更される可能性もある。\n\n\n\n\n\n\n\n\n\n\n手順2: 通常、課題ファイルは2つであるが、1つのみ、または3つ以上の場合もある。それぞれの資料の「添付資料」クリックする。\n\n\n\n\n\n\n\n\n\n手順3: 新しいウィンドウが表示される。ここでファイル名をクリックするとファイルがダウンロードされる。この作業を全ファイルに対して行うこと。"
  },
  {
    "objectID": "intro/homework.html#step2-課題ファイルのアップロード",
    "href": "intro/homework.html#step2-課題ファイルのアップロード",
    "title": "課題の取り組み方",
    "section": "Step2: 課題ファイルのアップロード",
    "text": "Step2: 課題ファイルのアップロード\n手順1: NIIオンライン分析システムへアクセスし、RStudioを起動する。\n手順2: 課題用のプロジェクトを作成する。プロジェクト名は任意だが、Homework_XXやHW_XXなど、分かりやすい名前を付けよう。\n手順3: ダウンロードしたファイルにデータ（.csvなど）がある場合、プロジェクト・フォルダー内にDataというフォルダーを作成する。\n手順4: ダウンロードしたファイルをアップロードする。課題用ファイル（.Rmdファイル）はプロジェクト・フォルダー直に、課題用データ（.csv、.xlsxなど）は手順3で作成したDataにアップロードする。\n\n\n\n\n\n\nプロジェクト、フォルダー、ファイルの管理\n\n\n\n以下のページを参照すること。\n\nプロジェクト管理\nファイル管理"
  },
  {
    "objectID": "intro/homework.html#step3-頑張る",
    "href": "intro/homework.html#step3-頑張る",
    "title": "課題の取り組み方",
    "section": "Step3: 頑張る",
    "text": "Step3: 頑張る\n一部の課題を除き、本講義の課題は本サポートページの「課題」メニューに掲載されている画面と同じ結果が得られるようにコードを書くことである。\n\n\n\n\n\n\n学籍番号と名前を忘れずに!\n\n\n\n課題用ファイル（.Rmd）の2行目には「情20-0012 関大太郎」と名前が記入されている。課題に取り組む前にまず学籍番号と名前を修正しよう。毎年、関大太郎と関大花子さんから提出された課題が散見されるが、この場合、課題未提出とみなす。むろん、自分の名前が関大太郎/関大花子なら学籍番号のみ修正しても良い。\n\n\n一部の課題を除き、履修者がやることは「学籍番号と氏名の修正」と「チャンク（chunk）内にコードを入力すること」、そして最後に「Knit」することだけである。チャンク内には# ここにコードと既に何かが書いてあるが、この# ここにコードの行は消してからコードを書くこと。あっても減点にはならない（印象は悪くなるかも知れない）。"
  },
  {
    "objectID": "intro/homework.html#step4-出力物のダウンロード",
    "href": "intro/homework.html#step4-出力物のダウンロード",
    "title": "課題の取り組み方",
    "section": "Step4: 出力物のダウンロード",
    "text": "Step4: 出力物のダウンロード\n本講義の課題は一部を除き、成果として.htmlファイルを提出する。Knit後のHTMLファイルは元のRmdファイル名.htmlである。こちらのファイルをダウンロードしよう。.Rmdも一緒にダウンロードして良いが、指定された形式のファイルを提出すること。.htmlファイルを提出しなければならないのに、.Rmdファイルを提出した場合は未提出とみなす。\n\n\n\n\n\n\n右クリックしてダウンロードは厳禁!!!\n\n\n\n出力物のダウンロード方法はファイル管理を参考すること。JupyterHubのホーム画面でファイルを右クリックして保存することは絶対にしないこと。開いてみれば分かるが、なんの情報もない（ほぼ）空っぽのファイルがダウンロードされる。提出期限が過ぎてから「知りませんでした！ごめんなさい！てへっ」と言われても、宋は「そうか、残念！てへっ」としか言わないので、ダウンロードしたファイルは必ず一回自分で開いてみよう。"
  },
  {
    "objectID": "intro/homework.html#step5-提出",
    "href": "intro/homework.html#step5-提出",
    "title": "課題の取り組み方",
    "section": "Step5: 提出",
    "text": "Step5: 提出\n手順1: LMSの授業ページから「第XX回 課題提出窓口」をクリックする。\n\n\n\n\n\n\n\n\n\n手順2: 指定された形式のファイルを添付し、「レポート提出」クリックする。\n\n提出されたら「202X-XX-XX XX:XX:XX にファイル xxxxxxxx が提出済みです。」と表示される。ここまでできたら終了ボタンをクリックする。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n課題がちゃんと提出されているか不安です…\n\n\n\n自分が提出した課題はLMSの「マイレポート」から確認できる。\n\n\n\n\n\n\n\n\n\n以下のように自分が提出した課題のリストが表示される。提出物のダウンロードもできるため、ファイルが問題なくアップロードされているかも確認できる。"
  },
  {
    "objectID": "intro/install.html",
    "href": "intro/install.html",
    "title": "Rの導入",
    "section": "",
    "text": "本講義の実習はNIIオンライン分析システムの使用を推奨する。自分のPCにインストールしたR + RStudio、RStuio.cloud、大学PCにインストールされているR + RStudioなどの使用を妨げないが1、本ページの資料と同じ結果が得られることは保証しない。また、実習・分析中に起きた不具合についても授業中には対応しない（オフィスアワーなどでは対応可能）。\n　以下ではNIIオンライン分析システムを用いたRおよびRStudioの導入方法について解説する。\n\n\n\n\n\n\n注意!!!\n\n\n\n初期設定は国立情報学研究所（以下、NII）のサーバーに自分の作業用スペースを借りる作業である。つまり、初期設定を繰り返すことはNIIのサーバー（のスペース）をいくつも借りることとなり、サーバーを圧迫してしまう可能性がある。したがって、初期設定は授業全体を通じて1回のみ実行すること。\n\n\n手順1: 以下のアドレスにアクセスする。\n\nhttps://binder.cs.rcos.nii.ac.jp/v2/gh/JaehyunSong/Binder_R/HEAD\n\n手順2: 所属機関に「関西大学」、または「Kansai University」を入力・選択し、「選択」をクリックする。このような画面が表示されない場合は手順2から5は飛ばしても良い。\n\n\n\n\n\n\n\n\n\n手順3: 自分の関西大学のIDをパスワードを入力する。こちらのIDとパスワードは関西大学インフォメーション・システムおよびLMSのID/パスワードと同じである。\n\n\n\n\n\n\n\n\n\n手順4: このまま「同意します」をクリックする。\n\n\n\n\n\n\n\n\n\n手順5: 以下のような画面が表示されたらしばらく待つ。\n\n\n\n\n\n\n\n\n\n手順6: 以下のような画面が表示されたら初期設定は完了\n\n\n\n\n\n\n\n\n\n手順7: 初期設定が終わったら、すぐRおよびRStudioが利用可能だが、ここでは一旦右上の「Logout」をクリックし、タブ (or ウィンドウ) を閉じる。"
  },
  {
    "objectID": "intro/install.html#niiオンライン分析システムの起動",
    "href": "intro/install.html#niiオンライン分析システムの起動",
    "title": "Rの導入",
    "section": "2 NIIオンライン分析システムの起動",
    "text": "2 NIIオンライン分析システムの起動\n初期設定が終わったら、今後、以下の手順でNIIオンライン分析システムを起動する。\n手順1: 以下のアドレスにアクセスするか、本ページの右上にある右上の  ボタンをクリックする（右クリックし、新しいタブ or ウィンドウで開くことを推奨する）。\n\nhttps://jupyter.cs.rcos.nii.ac.jp/\n\n手順2: 必要に応じて認証を行う（初期設定の手順2, 3, 4と同じ）。\n手順3: サーバーリストが表示される。URL列のアドレスをクリックする。\n\n参考) 初期設定を1回のみ行ったら1行のみ表示されるため混同することはないが、個人利用などを目的に初期設定を複数回行った場合は2行以上が表示されるだろう。本講義に使うサーバーのURLをクリックすること。\n\n\n\n\n\n\n\n\n\n\n手順4: 以下のような画面が表示されたらNIIオンライン分析システムの起動完了である。この画面を今後、「JupyterHub（ジュピターハブ）のホーム画面」と呼ぶ。"
  },
  {
    "objectID": "intro/install.html#rstudioの起動",
    "href": "intro/install.html#rstudioの起動",
    "title": "Rの導入",
    "section": "3 RStudioの起動",
    "text": "3 RStudioの起動\n手順1: JupyterHubのホーム画面の右上の「New」をクリックし、「RStudio」をクリックする。\n\n\n\n\n\n\n\n\n\n手順2: 以下の画面が表示されたら、RStudioの起動完了である（RStudioの見栄は初期状態の場合、白ベースである）。"
  },
  {
    "objectID": "intro/install.html#rstudioの終了",
    "href": "intro/install.html#rstudioの終了",
    "title": "Rの導入",
    "section": "4 RStudioの終了",
    "text": "4 RStudioの終了\n手順1: RStudio画面右上のオレンジ色のボタンをクリックする。\n\n\n\n\n\n\n\n\n\n手順2: 以下のダイアログが表示されたらタブ、またはウィンドウを閉じる。"
  },
  {
    "objectID": "intro/packages.html",
    "href": "intro/packages.html",
    "title": "パッケージ",
    "section": "",
    "text": "Rには数万以上のパッケージが存在し、Rをインストールするだけでも数十のパッケージが自動的にインストールされる。しかし、データ分析/ハンドリング/可視化の手法は日々発展しており、R内蔵パッケージだけでは対応が難しい (できないわけではない)。したがって、必要に応じて新しいパッケージを導入する必要があるが、パッケージのインストールするにはConsoleペインに以下のように入力する。\ninstall.packages(\"インストールするパッケージ名\")\n　前期の「ミクロ政治データ分析実習」では{tidyverse}パッケージのみ使用する予定である。ただし、本講義ようにセッティングされた環境を導入する場合、{tidyverse}は既に導入済みであるため、以下のコードは実行しなくても良い。"
  },
  {
    "objectID": "intro/packages.html#アップデート",
    "href": "intro/packages.html#アップデート",
    "title": "パッケージ",
    "section": "2 アップデート",
    "text": "2 アップデート\n　特定のパッケージをアップデートする方法はインストールと同じだが、一つ一つのパッケージが全て最新バージョンかどうかを確認するのは大変である。また、久々のアップデートで数十個のパッケージをアップデートする必要があるケースもあろう。この場合、RStudioの内蔵機能を使えば一瞬で更新可能なパッケージのリスト化、インストールができる。\n手順1: PackagesペインのUpdateをクリックする。\n\n\n\n\n\n\n\n\n\n手順2: アップデートしたいパッケージの左にチェックを付けるか、左下のSelect Allをクリックし、右下のInstall Updatesをクリックする。\n\n\n\n\n\n\n\n\n\n　インストール、またはアップデートの際、以下のようなメッセージが出力される場合がある。\n  There are binary versions available but the source versions\n  are later:\n      binary source needs_compilation\nterra 1.5-17 1.5-21              TRUE\nyaml   2.2.2  2.3.4              TRUE\n\nDo you want to install from sources the packages which need compilation? (Yes/no/cancel)\n　この場合、Consoleペイン上でYes、no、cancelのいずれかを入力してReturnキー (Enterキー)を押す必要がある。大文字と小文字は区別すること。どうしても最新のパッケージが欲しい場合はYesを入力すれば良いが、インストールに時間がかかる場合がある。一方、noを入力した場合は、若干古いバージョンがインストールされるが、インストールに必要な時間が短いため、基本的にはnoでも問題ないだろう。cancelを入力した場合はアップデートが全てキャンセルされる。"
  },
  {
    "objectID": "intro/packages.html#教科書",
    "href": "intro/packages.html#教科書",
    "title": "パッケージ",
    "section": "3 教科書",
    "text": "3 教科書\n『私たちのR』の第5章「Rパッケージ」: https://www.jaysong.net/RBook/packages.html"
  },
  {
    "objectID": "intro/project.html",
    "href": "intro/project.html",
    "title": "プロジェクト管理",
    "section": "",
    "text": "手順1: File > New Project…をクリックする。\n\n\n\n\n\n\n\n\n\n手順2: New Directoryをクリックする。\n\n\n\n\n\n\n\n\n\n手順3: New Projectをクリックする。\n\n\n\n\n\n\n\n\n\n手順4: Directory name:にプロジェクト名を入力し、Create Projectをクリックする。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n注意: プロジェクト名の付け方\n\n\n\n　プロジェクト名にはローマ字、数字のみを使おう。つまり、日本語、中国語、韓国語、全角文字、スペースはなるべく使わないこと。空白を入れたい場合はスペースの代わりにアンダースコア（_）を使おう。"
  },
  {
    "objectID": "intro/project.html#プロジェクトの開き方",
    "href": "intro/project.html#プロジェクトの開き方",
    "title": "プロジェクト管理",
    "section": "2 プロジェクトの開き方",
    "text": "2 プロジェクトの開き方\n　プロジェクトを作成すれば、自動的に出来たてのプロジェクトが開かれる。しかし、NIIオンライン分析システムから一旦ログアウトし、改めてRStudioを起動する場合、プロジェクトをロードする必要がある。\n手順1: File > Open Project…をクリックする。\n\n\n\n\n\n\n\n\n\n手順2: プロジェクト・フォルダー名をダブルクリックする。\n\n\n\n\n\n\n\n\n\n手順3: .Rprojで終わるファイルをダブルクリックする。\n\n\n\n\n\n\n\n\n\nプロジェクトが正しくロードされている場合、RStudioの右上にプロジェクト名が表示される。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n常にプロジェクト機能を使おう!\n\n\n\n　RStudionの右上のプロジェクト名表示が「Project: (None)」になっていることは、現在プロジェクトを開いていないことを意味する。簡単な計算機として使う目的以外（つまり、授業中の実習や課題）は必ずプロジェクト機能を使おう。"
  },
  {
    "objectID": "intro/rstudio.html",
    "href": "intro/rstudio.html",
    "title": "RStudioの設定",
    "section": "",
    "text": "RStudioはそのままでも使えるが、少しカスタマイズするとより使い勝手が良くなる。RStudioのカスタマイズ画面はTools > Global Optionsをクリックすることで表示される。\n以下の設定はNIIオンライン分析システムで使用可能なRStudio最新版 (RStudio Server 2021.09.1+372)の設定であり、宋の設定と同じである。"
  },
  {
    "objectID": "intro/rstudio.html#general",
    "href": "intro/rstudio.html#general",
    "title": "RStudioの設定",
    "section": "1 General",
    "text": "1 General\n\n\n\n\n\n\nRestore .RData into workspace at startupのチェックを消す。\nSave workspace to .RData on exit:をNeverに変更する。\nAlways save history (even when not saving .RData)のチェックを消す。"
  },
  {
    "objectID": "intro/rstudio.html#code",
    "href": "intro/rstudio.html#code",
    "title": "RStudioの設定",
    "section": "2 Code",
    "text": "2 Code\n\n2.1 Editingタブ\n\n\n\n\n\n\nInsert spaces for tabのチェックを付ける。\nTab widthは2、または4を指定する。\nAuto-detect code indentationのチェックを付ける。\nInsert matching parens/quotesのチェックを付ける。\nAuto-indent code after pasteのチェックを付ける。\nVertically align arguments in auto-indentのチェックを付ける。\nAlways save R scripts before sourcingのチェックを付ける。\nCtrl + Return executes:をMulti-line R statementに変更する。\n\n\n\n2.2 Displayタブ\n\n\n\n\n\n\nHighlight selected wordのチェックを付ける。\nHighlight selected lineのチェックを付ける。\nShow line numbersのチェックを付ける。\nShow syntax highlighting in console inputのチェックを付ける。\nHighlight R function callsのチェックを付ける。\nRainbow parenthesesのチェックを付ける。\n\n\n\n2.3 Savingタブ\n\n\n\n\n\n\nDefault text encoding:のChangeをクリックし、UTF-8を選択する。\n\n\n\n2.4 Completionタブ\n\n\n\n\n\n\nShow code completion:をAutomaticallyに変更する。\nAllow automatic completions in consoleのチェックを付ける。\nInsert parentheses after function completionsのチェックを付ける。\nShow help tooltip after function completionsのチェックを付ける。\nInsert spaces around equals for argument completionsのチェックを付ける。\nUse tab for autocompletionのチェックを付ける。"
  },
  {
    "objectID": "intro/rstudio.html#console",
    "href": "intro/rstudio.html#console",
    "title": "RStudioの設定",
    "section": "3 Console",
    "text": "3 Console\n\n\n\n\n\n\nShow syntax highlighting in console inputのチェックを付ける。"
  },
  {
    "objectID": "intro/rstudio.html#appearance",
    "href": "intro/rstudio.html#appearance",
    "title": "RStudioの設定",
    "section": "4 Appearance",
    "text": "4 Appearance\n\n\n\n\n\n\n自分の好みのものを選択する。ただし、小さすぎる文字サイズ (font size) は推奨しない。目に優しくないだけでなく、誤字脱字が見つけにくくなる。"
  },
  {
    "objectID": "intro/rstudio.html#pane-layout",
    "href": "intro/rstudio.html#pane-layout",
    "title": "RStudioの設定",
    "section": "5 Pane Layout",
    "text": "5 Pane Layout\n\n\n\n\n\n\n左上: Source\n右上: Console\n左下: 全てチェックを消す。\n左下: 全てチェックを付ける。"
  },
  {
    "objectID": "intro/rstudio.html#r-markdown",
    "href": "intro/rstudio.html#r-markdown",
    "title": "RStudioの設定",
    "section": "6 R Markdown",
    "text": "6 R Markdown\n\n\n\n\n\n\nShow output preview in:をViewer Paneに変更する。\nShow output inline for all R Markdown documentsのチェックを消す。\n\n設定が終わったら右下のOK、またはApplyをクリックする。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Causal Inference in Social Science@Kandai",
    "section": "",
    "text": "関西大学総合情報学研究科「社会科学における因果推論（2022年度）」のサポートページです。\n\n\n\n\n\n\nアイコン説明\n\n\n\n\n：NIIオンライン分析システムの起動\n\n右クリックし、新しいタブ（or ウィンドウ）で開いてください。\n初期設定が必要です。初期設定の方法はRの使い方 > Rの導入を参照してください。\n\n：Rの教科書（『私たちのR』）\n：本ウェブサイト内の検索\n\n\n\n\n\n\n\n\n\nページ情報\n\n\n\n\n最終更新日: 2022年12月07日\n開発環境\n\nmacOS 12.5.1 “Monterey”\nFirefox 104.0.2\nR version 4.2.2 (2022-10-31)\nRStudio 2022.07.1+554 “Elsbeth Geranium”\nQuarto 1.2.269\nR package {quarto} 1.2\n\n本サポートページのレポジトリ"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "本講義について",
    "section": "",
    "text": "科目名: 社会科学における因果推論\n講師: 宋財泫 (ソン ジェヒョン)\n所属: 関西大学総合情報学部\n\nE-mail: song [at] kansai-u.ac.jp\nHomepage: https://www.jaysong.net\n\n時間: 月曜日2限（10:40〜12:10）\n教室: TD106"
  },
  {
    "objectID": "syllabus.html#授業の内容",
    "href": "syllabus.html#授業の内容",
    "title": "本講義について",
    "section": "授業の内容",
    "text": "授業の内容\n　本講義は、近年社会科学において関心が高まっている「因果推論」を行うための諸手段を理解・習得することを目的とする。最初に、最良の因果推論とも称される RCT(ランダム化比較試験)を説明し、RCTが不可能な際の手法としてマッチング、回帰不連続デザイン、差分の差分法、操作変数法などを紹介する。"
  },
  {
    "objectID": "syllabus.html#評価",
    "href": "syllabus.html#評価",
    "title": "本講義について",
    "section": "評価",
    "text": "評価\n\n平常点: 70%\n\n授業への参加度、質問など\n\n期末課題: 30%\n\n第15回の研究構想の発表"
  },
  {
    "objectID": "syllabus.html#履修上の注意",
    "href": "syllabus.html#履修上の注意",
    "title": "本講義について",
    "section": "履修上の注意",
    "text": "履修上の注意\n　統計学に関する基礎知識が必要である。目安は母平均の差の検定、および線形回帰分析が理解でき、統計ソフトウェアで実行・解釈が可能なレベルである。\n　本講義における共通言語はRである。Rの使い方に関しては既にインターネット上に膨大な情報がある。宋と矢内(高知工科大学)が執筆中の以下の資料(無料で閲覧可能)を参照することも1つの選択肢である。\n\n宋財泫・矢内勇生. 『私たちの R: ベストプラクティスの探究』(web-book)\n\nRの導入方法は講義中、宋が解説する。\n\n\n　統計学および定量的分析、Rの使い方については以下の書籍を講義開始日までに読んで おくことを強く推奨する。\n\n浅野正彦・矢内勇生. 2019『Rによる計量政治学』オーム社.\n\n　R スクリプト作成の際、{tidyverse} というパッケージ群を積極的に活用する。この パッケージには {dplyr}、{ggplot2} などのパッケージが含まれている。各パッケージの 使い方を習得するには以下の教材を推奨する。\n\nWickham, Hadley and Grolemund, Garrett. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, O’Reilly. (邦訳あり/原著はインターネットから無料で閲覧可)\n松村優哉・湯谷啓明・紀ノ定保礼・前田和寛 . 2021. 『改訂2版 Rユーザのための RStudio[実践] 入門—tidyverseによるモダンな分析フローの世界—』技術評論社."
  },
  {
    "objectID": "syllabus.html#教科書参考書",
    "href": "syllabus.html#教科書参考書",
    "title": "本講義について",
    "section": "教科書・参考書",
    "text": "教科書・参考書\n以下は本書の内容を(一部)カバーする書籍の目録である。必ずしも購入する必要はないが、予習・復習において適宜参照することを推奨する。\n\n因果推論の理論と実例\n\nAngrist, Joahua D., and Jorn-steffen Pischke. 2008. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press.\n\n『「ほとんど無害」な計量経済学―応用経済学のための実証分析ガイド』 (翻訳はかなり有害)\n\nAngrist, Joahua D., and Jorn-steffen Pischke. 2014. Mastering ’Metrics: The Path from Cause to Effect. Princeton University Press.\n森田果. 2014.『実証分析入門—データから「因果関係」を読み解く作法』日本評論社.\n中室牧子・津川友介. 2017.『「原因と結果」の経済学—データから真実を見抜く思考法』ダイヤモンド社.\n伊藤公一郎. 2017.『データ分析の力—因果関係に迫る思考法』光文社新書.\n松林哲也. 2021.『政治学と因果推論』岩波書店.\n\n理論+R\n\n星野匡郎・田中久稔. 2016.『Rによる実証分析—回帰分析から因果分析へ—』オーム社.\n安井翔太. 2020. 『効果検証入門—正しい比較のための因果推論/計量経済学の基礎』技術評論社.\nCunningham, Scott. 2021. Causal Inference: The Mixtape. Yale University Press.\n高橋将宜. 2022. 『統計的因果推論の理論と実装』共立出版."
  },
  {
    "objectID": "syllabus.html#講義内容",
    "href": "syllabus.html#講義内容",
    "title": "本講義について",
    "section": "講義内容",
    "text": "講義内容\n以下の内容は履修者の理解度や進捗状況に応じて変更される可能性がある。\n\n\n\n回\n講義日\n内容\n\n\n\n\n1\n2022/09/26\nガイダンス\n\n\n2\n2022/10/03\n因果推論の考え方\n\n\n3\n2022/10/10\n無作為化比較試験\n\n\n4\n2022/10/17\nRの復習（1）\n\n\n5\n2022/10/24\nRの復習（2）\n\n\n6\n2022/10/24\nRの復習（3）\n\n\n7\n2022/11/07\n回帰分析とマッチング（理論）\n\n\n8\n2022/11/14\n回帰分析とマッチング（理論）\n\n\n9\n2022/11/21\n回帰分析とマッチング（実習）\n\n\n10\n2022/11/28\n回帰分析とマッチング（実習）\n\n\n11\n2022/12/05\n差分の差分法（理論）\n\n\n12\n2022/12/12\n差分の差分法（実習）\n\n\n13\n2022/12/19\n回帰不連続デザイン（理論）\n\n\n14\n2022/12/26\n回帰不連続デザイン（実習）\n\n\n15\n2023/01/16\n研究構想の発表"
  },
  {
    "objectID": "material/did.html",
    "href": "material/did.html",
    "title": "差分の差分法",
    "section": "",
    "text": "新しいタブで開く"
  },
  {
    "objectID": "material/did.html#セットアップ",
    "href": "material/did.html#セットアップ",
    "title": "差分の差分法",
    "section": "セットアップ",
    "text": "セットアップ\n　本日の実習に必要なパッケージとデータを読み込む。\n\npacman::p_load(tidyverse,     # Rの必須パッケージ\n               summarytools,  # 記述統計\n               modelsummary,  # 推定結果の要約\n               estimatr)      # ロバストな回帰分析\n\ndid_df <- read_csv(\"data/did_data3.csv\")\n\ndid_df\n\n# A tibble: 18,749 × 14\n   county state  year shooting fatal_s…¹ non_f…² turnout demvote popul…³ non_w…⁴\n    <dbl> <chr> <dbl>    <dbl>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1   1001 01     1996        0         0       0    56.1    32.5   40207   0.190\n 2   1001 01     2000        0         0       0    56.8    28.7   44021   0.189\n 3   1001 01     2004        0         0       0    60.2    23.7   48366   0.196\n 4   1001 01     2008        0         0       0    64.1    25.8   53277   0.205\n 5   1001 01     2012        0         0       0    61.0    26.5   55027   0.212\n 6   1001 01     2016        0         0       0    60.7    24.0   55416   0.228\n 7   1003 01     1996        0         0       0    51.8    27.1  125412   0.123\n 8   1003 01     2000        0         0       0    54.6    24.8  141342   0.122\n 9   1003 01     2004        0         0       0    59.8    22.5  156266   0.122\n10   1003 01     2008        0         0       0    62.4    23.8  175827   0.122\n# … with 18,739 more rows, 4 more variables: change_unem_rate <dbl>,\n#   county_f <dbl>, state_f <chr>, year_f <dbl>, and abbreviated variable names\n#   ¹​fatal_shooting, ²​non_fatal_shooting, ³​population, ⁴​non_white\n\n\n　データの詳細はスライドを参照すること。DID推定には時間（年）とカウンティー（郡）の固定効果を投入し、州レベルでクラスタリングした標準誤差を使う予定である。これらの変数を予めfactor化しておこう。factor化した変数は変数名の後ろに_fを付けて、新しい列として追加しておく。\n\ndid_df <- did_df |>\n  mutate(county_f = factor(county),\n         state_f  = factor(state),\n         year_f   = factor(year))\n\ndid_df\n\n# A tibble: 18,749 × 14\n   county state  year shooting fatal_s…¹ non_f…² turnout demvote popul…³ non_w…⁴\n    <dbl> <chr> <dbl>    <dbl>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1   1001 01     1996        0         0       0    56.1    32.5   40207   0.190\n 2   1001 01     2000        0         0       0    56.8    28.7   44021   0.189\n 3   1001 01     2004        0         0       0    60.2    23.7   48366   0.196\n 4   1001 01     2008        0         0       0    64.1    25.8   53277   0.205\n 5   1001 01     2012        0         0       0    61.0    26.5   55027   0.212\n 6   1001 01     2016        0         0       0    60.7    24.0   55416   0.228\n 7   1003 01     1996        0         0       0    51.8    27.1  125412   0.123\n 8   1003 01     2000        0         0       0    54.6    24.8  141342   0.122\n 9   1003 01     2004        0         0       0    59.8    22.5  156266   0.122\n10   1003 01     2008        0         0       0    62.4    23.8  175827   0.122\n# … with 18,739 more rows, 4 more variables: change_unem_rate <dbl>,\n#   county_f <fct>, state_f <fct>, year_f <fct>, and abbreviated variable names\n#   ¹​fatal_shooting, ²​non_fatal_shooting, ³​population, ⁴​non_white\n\n\n　連続変数（shootingからchange_unem_rateまで）の記述統計量を出力する。ここで一つ注意が必要だ。それはselect()関数の使い方である。具体的に言えば、使い方そのものは変わらない。\n\ndid_df |>\n  select(shooting:change_unem_rate) |>\n  descr(stats = c(\"mean\", \"sd\", \"min\", \"max\", \"n.valid\"),\n        transpose = TRUE, order = \"p\")\n\nDescriptive Statistics  \n\n                               Mean     Std.Dev      Min           Max    N.Valid\n------------------------ ---------- ----------- -------- ------------- ----------\n                shooting       0.00        0.07     0.00          1.00   18749.00\n          fatal_shooting       0.00        0.05     0.00          1.00   18749.00\n      non_fatal_shooting       0.00        0.04     0.00          1.00   18749.00\n                 turnout      57.94       10.32     1.08        300.00   18627.00\n                 demvote      39.01       13.79     3.14         92.85   18627.00\n              population   95121.69   306688.63    55.00   10137915.00   18749.00\n               non_white       0.13        0.16     0.00          0.96   18749.00\n        change_unem_rate      -0.39        2.34   -19.60         15.30   18749.00"
  },
  {
    "objectID": "material/did.html#diff-in-diff",
    "href": "material/did.html#diff-in-diff",
    "title": "差分の差分法",
    "section": "Diff-in-Diff",
    "text": "Diff-in-Diff\n　それでは差分の差分法の実装について紹介する。推定式は以下の通りである。\n\\[\n\\mbox{Outcome}_{i, t} = \\beta_0 + \\beta_1 \\mbox{Shooting}_{i, t} + \\sum_k \\delta_{k, i, t} \\mbox{Controls}_{k, i, t} + \\lambda_{t} + \\omega_{i} + \\varepsilon_{i, t}\n\\]\n\n\\(\\mbox{Otucome}\\): 応答変数\n\nturnout: 投票率（大統領選挙）\ndemvote: 民主党候補者の得票率\n\n\\(\\mbox{Shooting}\\): 処置変数\n\nshooting: 銃撃事件の発生有無\nfatal_shooting: 死者を伴う銃撃事件の発生有無\nnon_fatal_shooting: 死者を伴わない銃撃事件の発生有無\n\n\\(\\mbox{Controls}\\): 統制変数\n\npopulation: カウンティーの人口\nnon_white: 非白人の割合\nchange_unem_rate: 失業率の変化\n統制変数あり/なしのモデルを個別に推定\n\n\\(\\lambda\\): 年固定効果\n\\(\\omega\\): カウンティー固定効果\n\n応答変数が2種類、処置変数が3種類、共変量の有無でモデルを分けるので、推定するモデルは計12個である。\n\n\n\nモデル\nオブジェクト名\n応答変数\n処置変数\n統制変数\n\n\n\n\nモデル1\ndid_fit1\nturnout\nshooting\nなし\n\n\nモデル2\ndid_fit2\nturnout\nshooting\nあり\n\n\nモデル3\ndid_fit3\nturnout\nfatal_shooting\nなし\n\n\nモデル4\ndid_fit4\nturnout\nfatal_shooting\nあり\n\n\nモデル5\ndid_fit5\nturnout\nnon_fatal_shooting\nなし\n\n\nモデル6\ndid_fit6\nturnout\nnon_fatal_shooting\nあり\n\n\nモデル7\ndid_fit7\ndemvote\nshooting\nなし\n\n\nモデル8\ndid_fit8\ndemvote\nshooting\nあり\n\n\nモデル9\ndid_fit9\ndemvote\nfatal_shooting\nなし\n\n\nモデル10\ndid_fit10\ndemvote\nfatal_shooting\nあり\n\n\nモデル11\ndid_fit11\ndemvote\nnon_fatal_shooting\nなし\n\n\nモデル12\ndid_fit12\ndemvote\nnon_fatal_shooting\nあり\n\n\n\n　まずはモデル1を推定し、did_fit1という名のオブジェクトとして格納する。基本的には線形回帰分析であるため、lm()でも推定はできる。しかし、差分の差分法の場合、通常、クラスター化した頑健な標準誤差（cluster robust standard error）を使う。lm()単体ではこれが計算できないため、今回は{estimatr}パッケージが提供するlm_robust()関数を使用する。使い方はlm()同様、まず回帰式と使用するデータ名を指定する。続いて、固定効果をfixed_effects引数で指定する1。書き方は~固定効果変数1 + 固定効果変数2 + ...である。回帰式と違って、~の左側には変数がないことに注意すること。続いて、clusters引数でクラスタリングする変数を指定する。今回は州レベルでクラスタリングするので、state_fで良い。最後に標準誤差のタイプを指定するが、デフォルトは\"CR2\"となっている。今回のデータはそれなりの大きさのデータであり、\"CR2\"だと推定時間が非常に長くなる。ここでは推定時間が比較的早い\"stata\"とする。\n\ndid_fit1 <- lm_robust(turnout ~ shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\nsummary(did_fit1)\n\n\nCall:\nlm_robust(formula = turnout ~ shooting, data = did_df, clusters = state_f, \n    fixed_effects = ~year_f + county_f, se_type = \"stata\")\n\nStandard error type:  stata \n\nCoefficients:\n         Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF\nshooting  -0.5211     0.6457  -0.807   0.4235   -1.819   0.7764 49\n\nMultiple R-squared:  0.8575 ,   Adjusted R-squared:  0.8288\nMultiple R-squared (proj. model):  6.907e-05 ,  Adjusted R-squared (proj. model):  -0.2008 \nF-statistic (proj. model): 0.6513 on 1 and 49 DF,  p-value: 0.4235\n\n\n　処置効果の推定値は-0.521である。これは学校内銃撃事件が発生したカウンティーの場合、大統領選挙において投票率が約-0.521%p低下することを意味する。しかし、標準誤差がかなり大きく、統計的有意な結果ではない。つまり、「学校内銃撃事件が投票率を上げる（or 下げる）とは言えない」と解釈できる。決して「学校内銃撃事件が投票率を上げない（or 下げない）」と解釈しないこと。\n　共変量を投入してみたらどうだろうか。たとえば、人口は自治体の都市化程度を表すこともあるので、都市化程度と投票率には関係があると考えられる。また、人口が多いと自然に事件が発生する確率もあがるので、交絡要因として考えられる。人種や失業率も同様であろう。ここではカウンティーの人口（population）、非白人の割合（non_white）、失業率の変化（change_unem_rate）を統制変数として投入し、did_fit2という名で格納する。\n\ndid_fit2 <- lm_robust(turnout ~ shooting + \n                        population + non_white + change_unem_rate, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\nsummary(did_fit2)\n\n\nCall:\nlm_robust(formula = turnout ~ shooting + population + non_white + \n    change_unem_rate, data = did_df, clusters = state_f, fixed_effects = ~year_f + \n    county_f, se_type = \"stata\")\n\nStandard error type:  stata \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)   CI Lower   CI Upper\nshooting         -7.098e-01  6.237e-01  -1.138  0.26066 -1.963e+00  5.436e-01\npopulation        8.029e-06  5.688e-06   1.411  0.16443 -3.402e-06  1.946e-05\nnon_white        -3.483e+01  1.558e+01  -2.236  0.02990 -6.613e+01 -3.534e+00\nchange_unem_rate  1.592e-01  6.584e-02   2.418  0.01938  2.688e-02  2.915e-01\n                 DF\nshooting         49\npopulation       49\nnon_white        49\nchange_unem_rate 49\n\nMultiple R-squared:  0.8598 ,   Adjusted R-squared:  0.8316\nMultiple R-squared (proj. model):  0.01669 ,    Adjusted R-squared (proj. model):  -0.1811 \nF-statistic (proj. model): 5.047 on 4 and 49 DF,  p-value: 0.001739\n\n\n　処置効果の推定値は-0.710である。これは他の条件が同じ場合、学校内銃撃事件が発生したカウンティーは大統領選挙において投票率が約-0.710%p低下することを意味する。ちなみに、e-01は\\(\\times 10^{-1}\\)を、e-06は\\(\\times 10^{-6}\\)を、e+01は\\(\\times 10^{1}\\)意味する。今回も統計的に非有意な結果が得られている。\n　これまでの処置変数は死者の有無と関係なく、学校内銃撃事件が発生したか否かだった。もしかしたら、死者を伴う銃撃事件が発生した場合、その効果が大きいかも知れない。したがって、これからは処置変数を死者を伴う学校内銃撃事件の発生有無（fatal_shooting）、死者を伴わない学校内銃撃事件の発生有無（non_fatal_shooting）に変えてもう一度推定してみよう。\n\ndid_fit3 <- lm_robust(turnout ~ fatal_shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit4 <- lm_robust(turnout ~ fatal_shooting + \n                        population + non_white + change_unem_rate, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit5 <- lm_robust(turnout ~ non_fatal_shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit6 <- lm_robust(turnout ~ non_fatal_shooting + \n                        population + non_white + change_unem_rate, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\n　これまで推定してきた6つのモデルを比較してみよう。\n\nmodelsummary(list(did_fit1, did_fit2, did_fit3, \n                  did_fit4, did_fit5, did_fit6))\n\n\n\n \n  \n      \n    Model 1 \n    Model 2 \n    Model 3 \n    Model 4 \n    Model 5 \n    Model 6 \n  \n \n\n  \n    shooting \n    −0.521 \n    −0.710 \n     \n     \n     \n     \n  \n  \n     \n    (0.646) \n    (0.624) \n     \n     \n     \n     \n  \n  \n    population \n     \n    0.000008 \n     \n    0.000008 \n     \n    0.000008 \n  \n  \n     \n     \n    (0.000006) \n     \n    (0.000006) \n     \n    (0.000006) \n  \n  \n    non_white \n     \n    −34.834 \n     \n    −34.844 \n     \n    −34.814 \n  \n  \n     \n     \n    (15.575) \n     \n    (15.618) \n     \n    (15.614) \n  \n  \n    change_unem_rate \n     \n    0.159 \n     \n    0.159 \n     \n    0.160 \n  \n  \n     \n     \n    (0.066) \n     \n    (0.066) \n     \n    (0.066) \n  \n  \n    fatal_shooting \n     \n     \n    −0.678 \n    −0.918 \n     \n     \n  \n  \n     \n     \n     \n    (0.619) \n    (0.658) \n     \n     \n  \n  \n    non_fatal_shooting \n     \n     \n     \n     \n    −0.239 \n    −0.327 \n  \n  \n     \n     \n     \n     \n     \n    (1.094) \n    (1.145) \n  \n  \n    Num.Obs. \n    18627 \n    18627 \n    18627 \n    18627 \n    18627 \n    18627 \n  \n  \n    R2 \n    0.857 \n    0.860 \n    0.857 \n    0.860 \n    0.857 \n    0.860 \n  \n  \n    R2 Adj. \n    0.829 \n    0.832 \n    0.829 \n    0.832 \n    0.829 \n    0.832 \n  \n  \n    AIC \n    103543.4 \n    103237.2 \n    103543.3 \n    103237.1 \n    103544.6 \n    103239.4 \n  \n  \n    BIC \n    103559.0 \n    103276.4 \n    103559.0 \n    103276.3 \n    103560.2 \n    103278.6 \n  \n  \n    RMSE \n    3.90 \n    3.87 \n    3.90 \n    3.87 \n    3.90 \n    3.87 \n  \n  \n    Std.Errors \n    by: state_f \n    by: state_f \n    by: state_f \n    by: state_f \n    by: state_f \n    by: state_f \n  \n\n\n\n\n\n　いずれのモデルも統計的に有意な処置効果は確認されていない。これらの結果を表として報告するには紙がもったいない気もする。これらの結果はOnline Appendixに回し、本文中には処置効果の点推定値と95%信頼区間を示せば良いだろう。\n　{broom}のtidy()関数で推定結果のみを抽出し、それぞれオブジェクトとして格納しておこう。\n\ntidy_fit1 <- tidy(did_fit1, conf.int = TRUE)\ntidy_fit2 <- tidy(did_fit2, conf.int = TRUE)\ntidy_fit3 <- tidy(did_fit3, conf.int = TRUE)\ntidy_fit4 <- tidy(did_fit4, conf.int = TRUE)\ntidy_fit5 <- tidy(did_fit5, conf.int = TRUE)\ntidy_fit6 <- tidy(did_fit6, conf.int = TRUE)\n\n　全て確認する必要はないので、tidy_fit1のみを確認してみる。\n\ntidy_fit1\n\n      term   estimate std.error  statistic   p.value conf.low conf.high df\n1 shooting -0.5210841 0.6456718 -0.8070417 0.4235426 -1.81861  0.776442 49\n  outcome\n1 turnout\n\n\n　以上の6つの表形式オブジェクトを一つの表としてまとめる。それぞれのオブジェクトには共変量の有無_処置変数の種類の名前を付けよう。共変量なしのモデルはM1、ありのモデルはM2とする。処置変数はshootingの場合はTr1、fatal_shootingはTr2、non_fatal_shootingはTr3とする。\n\ndid_est1 <- bind_rows(list(\"M1_Tr1\" = tidy_fit1,\n                           \"M2_Tr1\" = tidy_fit2,\n                           \"M1_Tr2\" = tidy_fit3,\n                           \"M2_Tr2\" = tidy_fit4,\n                           \"M1_Tr3\" = tidy_fit5,\n                           \"M2_Tr3\" = tidy_fit6),\n                      .id = \"Model\")\n\ndid_est1\n\n    Model               term      estimate    std.error  statistic    p.value\n1  M1_Tr1           shooting -5.210841e-01 6.456718e-01 -0.8070417 0.42354260\n2  M2_Tr1           shooting -7.097922e-01 6.237320e-01 -1.1379763 0.26066411\n3  M2_Tr1         population  8.028568e-06 5.688141e-06  1.4114574 0.16442833\n4  M2_Tr1          non_white -3.483443e+01 1.557543e+01 -2.2364985 0.02990378\n5  M2_Tr1   change_unem_rate  1.592020e-01 6.584450e-02  2.4178480 0.01937671\n6  M1_Tr2     fatal_shooting -6.779229e-01 6.191749e-01 -1.0948810 0.27892152\n7  M2_Tr2     fatal_shooting -9.179995e-01 6.576559e-01 -1.3958659 0.16904785\n8  M2_Tr2         population  8.026778e-06 5.747531e-06  1.3965611 0.16883977\n9  M2_Tr2          non_white -3.484436e+01 1.561829e+01 -2.2309975 0.03029042\n10 M2_Tr2   change_unem_rate  1.591126e-01 6.591001e-02  2.4140886 0.01955574\n11 M1_Tr3 non_fatal_shooting -2.387205e-01 1.093832e+00 -0.2182423 0.82814672\n12 M2_Tr3 non_fatal_shooting -3.269742e-01 1.145303e+00 -0.2854915 0.77647098\n13 M2_Tr3         population  7.821482e-06 5.712400e-06  1.3692110 0.17717684\n14 M2_Tr3          non_white -3.481384e+01 1.561438e+01 -2.2296020 0.03038921\n15 M2_Tr3   change_unem_rate  1.595359e-01 6.590170e-02  2.4208169 0.01923637\n        conf.low     conf.high df outcome\n1  -1.818610e+00  7.764420e-01 49 turnout\n2  -1.963229e+00  5.436442e-01 49 turnout\n3  -3.402178e-06  1.945932e-05 49 turnout\n4  -6.613442e+01 -3.534428e+00 49 turnout\n5   2.688251e-02  2.915215e-01 49 turnout\n6  -1.922202e+00  5.663557e-01 49 turnout\n7  -2.239609e+00  4.036096e-01 49 turnout\n8  -3.523318e-06  1.957687e-05 49 turnout\n9  -6.623047e+01 -3.458237e+00 49 turnout\n10  2.666148e-02  2.915637e-01 49 turnout\n11 -2.436859e+00  1.959418e+00 49 turnout\n12 -2.628546e+00  1.974598e+00 49 turnout\n13 -3.658017e-06  1.930098e-05 49 turnout\n14 -6.619211e+01 -3.435580e+00 49 turnout\n15  2.710152e-02  2.919704e-01 49 turnout\n\n\n　続いて、処置効果のみを抽出する。処置効果はterm列の値が\"shooting\"、\"fatal_shooting\"、\"non_fatal_shooting\"のいずれかと一致する行であるため、filter()関数を使用する。\n\ndid_est1 <- did_est1 |>\n  filter(term %in% c(\"shooting\", \"fatal_shooting\", \"non_fatal_shooting\"))\n\ndid_est1\n\n   Model               term   estimate std.error  statistic   p.value  conf.low\n1 M1_Tr1           shooting -0.5210841 0.6456718 -0.8070417 0.4235426 -1.818610\n2 M2_Tr1           shooting -0.7097922 0.6237320 -1.1379763 0.2606641 -1.963229\n3 M1_Tr2     fatal_shooting -0.6779229 0.6191749 -1.0948810 0.2789215 -1.922202\n4 M2_Tr2     fatal_shooting -0.9179995 0.6576559 -1.3958659 0.1690478 -2.239609\n5 M1_Tr3 non_fatal_shooting -0.2387205 1.0938325 -0.2182423 0.8281467 -2.436859\n6 M2_Tr3 non_fatal_shooting -0.3269742 1.1453027 -0.2854915 0.7764710 -2.628546\n  conf.high df outcome\n1 0.7764420 49 turnout\n2 0.5436442 49 turnout\n3 0.5663557 49 turnout\n4 0.4036096 49 turnout\n5 1.9594182 49 turnout\n6 1.9745977 49 turnout\n\n\n　ちなみにgrepl()関数を使うと、\"shooting\"が含まれる行を抽出することもできる。以下のコードは上記のコードと同じ機能をする。\n\ndid_est1 <- did_est1 |>\n  filter(grepl(\"shooting\", term))\n\n　つづいて、Model列をModelとTreat列へ分割する。\n\ndid_est1 <- did_est1 |>\n  separate(col  = Model,\n           into = c(\"Model\", \"Treat\"),\n           sep  = \"_\")\n\ndid_est1\n\n  Model Treat               term   estimate std.error  statistic   p.value\n1    M1   Tr1           shooting -0.5210841 0.6456718 -0.8070417 0.4235426\n2    M2   Tr1           shooting -0.7097922 0.6237320 -1.1379763 0.2606641\n3    M1   Tr2     fatal_shooting -0.6779229 0.6191749 -1.0948810 0.2789215\n4    M2   Tr2     fatal_shooting -0.9179995 0.6576559 -1.3958659 0.1690478\n5    M1   Tr3 non_fatal_shooting -0.2387205 1.0938325 -0.2182423 0.8281467\n6    M2   Tr3 non_fatal_shooting -0.3269742 1.1453027 -0.2854915 0.7764710\n   conf.low conf.high df outcome\n1 -1.818610 0.7764420 49 turnout\n2 -1.963229 0.5436442 49 turnout\n3 -1.922202 0.5663557 49 turnout\n4 -2.239609 0.4036096 49 turnout\n5 -2.436859 1.9594182 49 turnout\n6 -2.628546 1.9745977 49 turnout\n\n\n　可視化に入る前にModel列とTreat列の値を修正する。Model列の値が\"M1\"なら\"County-Year FE\"に、それ以外なら\"County-Year FE + Covariates\"とリコーディングする。戻り値が2種類だからif_else()を使う。Treat列の場合、戻り値が3つなので、recode()かcase_when()を使う。ここではrecode()を使ってリコーディングする。最後にModelとTreatを表示順番でfactor化し（fct_inorder()）、更に順番を逆転する（fct_rev()）。\n\ndid_est1 <- did_est1 |>\n  mutate(Model = if_else(Model == \"M1\",\n                           \"County-Year FE\", \n                           \"County-Year FE + Covariates\"),\n         Treat = recode(Treat,\n                        \"Tr1\" = \"Any Shooting (t-1)\",\n                        \"Tr2\" = \"Fatal Shooting (t-1)\",\n                        \"Tr3\" = \"Nonfatal Shooting (t-1)\"),\n         Model = fct_rev(fct_inorder(Model)),\n         Treat = fct_rev(fct_inorder(Treat)))\n\ndid_est1\n\n                        Model                   Treat               term\n1              County-Year FE      Any Shooting (t-1)           shooting\n2 County-Year FE + Covariates      Any Shooting (t-1)           shooting\n3              County-Year FE    Fatal Shooting (t-1)     fatal_shooting\n4 County-Year FE + Covariates    Fatal Shooting (t-1)     fatal_shooting\n5              County-Year FE Nonfatal Shooting (t-1) non_fatal_shooting\n6 County-Year FE + Covariates Nonfatal Shooting (t-1) non_fatal_shooting\n    estimate std.error  statistic   p.value  conf.low conf.high df outcome\n1 -0.5210841 0.6456718 -0.8070417 0.4235426 -1.818610 0.7764420 49 turnout\n2 -0.7097922 0.6237320 -1.1379763 0.2606641 -1.963229 0.5436442 49 turnout\n3 -0.6779229 0.6191749 -1.0948810 0.2789215 -1.922202 0.5663557 49 turnout\n4 -0.9179995 0.6576559 -1.3958659 0.1690478 -2.239609 0.4036096 49 turnout\n5 -0.2387205 1.0938325 -0.2182423 0.8281467 -2.436859 1.9594182 49 turnout\n6 -0.3269742 1.1453027 -0.2854915 0.7764710 -2.628546 1.9745977 49 turnout\n\n\n　それでは{ggplot2}を使ってpoint-rangeプロットを作成してみよう。\n\ndid_est1 |>\n  ggplot() +\n  # x = 0の箇所に垂直線を引く。垂直線は破線（linetype = 2）とする。\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Treat, color = Model),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"Change in Turnout (%p)\", y = \"\", color = \"\") +\n  # 色を指定する。\n  # Modelの値が County-Year FE なら黒、\n  # County-Year FE + Covariates ならグレー、\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  # 横軸の下限と上限を-10〜10とする。\n  coord_cartesian(xlim = c(-10, 10)) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　元の論文を見ると、点の上に点推定値が書かれているが、私たちもこれを真似してみよう。文字列をプロットするレイヤーはgeom_text()とgeom_label()、annotate()があるが、ここではgeom_text()を使用する。文字列が表示される横軸上の位置（x）と縦軸上の位置（y）、そして出力する文字列（label）をマッピングする。点推定値は3桁まで出力したいので、sprintf()を使って、3桁に丸める。ただし、これだけだと点と文字が重なってしまう。vjustを-0.75にすることで、出力する文字列を点の位置を上の方向へ若干ずらすことができる。\n\ndid_est1 |>\n  ggplot() +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Treat, color = Model),\n                  position = position_dodge2(1/2)) +\n  geom_text(aes(x = estimate, y = Treat, color = Model, \n                label = sprintf(\"%.3f\", estimate)),\n            position = position_dodge2(1/2),\n            vjust = -0.75) +\n  labs(x = \"Change in Turnout (%p)\", y = \"\", color = \"\") +\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  coord_cartesian(xlim = c(-10, 10)) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　ちなみにこのコードを見ると、geom_pointrange()とgeom_text()はx、y、colorを共有しているので、ggplot()内でマッピングすることもできる。\n\ndid_est1 |>\n  ggplot(aes(x = estimate, y = Treat, color = Model)) +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high),\n                  position = position_dodge2(1/2)) +\n  geom_text(aes(label = sprintf(\"%.3f\", estimate)),\n            position = position_dodge2(1/2),\n            vjust = -0.75) +\n  labs(x = \"Change in Turnout (%p)\", y = \"\", color = \"\") +\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  coord_cartesian(xlim = c(-10, 10)) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n　続いて、民主党候補者の得票率（demvote）を応答変数として6つのモデルを推定し、同じ作業を繰り返す。\n\ndid_fit7 <- lm_robust(demvote ~ shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit8 <- lm_robust(demvote ~ shooting + \n                        population + non_white + change_unem_rate, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit9 <- lm_robust(demvote ~ fatal_shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit10 <- lm_robust(demvote ~ fatal_shooting + \n                         population + non_white + change_unem_rate, \n                       data          = did_df, \n                       fixed_effects = ~year_f + county_f,\n                       clusters      = state_f,\n                       se_type       = \"stata\")\n\ndid_fit11 <- lm_robust(demvote ~ non_fatal_shooting, \n                       data          = did_df, \n                       fixed_effects = ~year_f + county_f,\n                       clusters      = state_f,\n                       se_type       = \"stata\")\n\ndid_fit12 <- lm_robust(demvote ~ non_fatal_shooting + \n                         population + non_white + change_unem_rate, \n                       data          = did_df, \n                       fixed_effects = ~year_f + county_f,\n                       clusters      = state_f,\n                       se_type       = \"stata\")\n\nmodelsummary(list(\"Model 7\"  = did_fit7,  \"Model 8\"  = did_fit8, \n                  \"Model 9\"  = did_fit9,  \"Model 10\" = did_fit10, \n                  \"Model 11\" = did_fit11, \"Model 12\" = did_fit12))\n\n\n\n \n  \n      \n    Model 7 \n    Model 8 \n    Model 9 \n    Model 10 \n    Model 11 \n    Model 12 \n  \n \n\n  \n    shooting \n    4.513 \n    2.364 \n     \n     \n     \n     \n  \n  \n     \n    (0.875) \n    (0.737) \n     \n     \n     \n     \n  \n  \n    population \n     \n    0.00003 \n     \n    0.00003 \n     \n    0.00003 \n  \n  \n     \n     \n    (0.000007) \n     \n    (0.000007) \n     \n    (0.000007) \n  \n  \n    non_white \n     \n    86.873 \n     \n    86.866 \n     \n    86.796 \n  \n  \n     \n     \n    (17.863) \n     \n    (17.855) \n     \n    (17.855) \n  \n  \n    change_unem_rate \n     \n    −0.139 \n     \n    −0.139 \n     \n    −0.140 \n  \n  \n     \n     \n    (0.127) \n     \n    (0.128) \n     \n    (0.127) \n  \n  \n    fatal_shooting \n     \n     \n    4.404 \n    1.782 \n     \n     \n  \n  \n     \n     \n     \n    (1.092) \n    (0.836) \n     \n     \n  \n  \n    non_fatal_shooting \n     \n     \n     \n     \n    4.217 \n    2.930 \n  \n  \n     \n     \n     \n     \n     \n    (1.298) \n    (1.037) \n  \n  \n    Num.Obs. \n    18627 \n    18627 \n    18627 \n    18627 \n    18627 \n    18627 \n  \n  \n    R2 \n    0.882 \n    0.894 \n    0.882 \n    0.894 \n    0.882 \n    0.894 \n  \n  \n    R2 Adj. \n    0.859 \n    0.873 \n    0.859 \n    0.873 \n    0.859 \n    0.873 \n  \n  \n    AIC \n    110745.2 \n    108755.4 \n    110772.0 \n    108768.2 \n    110786.5 \n    108762.1 \n  \n  \n    BIC \n    110760.8 \n    108794.6 \n    110787.7 \n    108807.3 \n    110802.2 \n    108801.3 \n  \n  \n    RMSE \n    4.73 \n    4.48 \n    4.73 \n    4.48 \n    4.73 \n    4.48 \n  \n  \n    Std.Errors \n    by: state_f \n    by: state_f \n    by: state_f \n    by: state_f \n    by: state_f \n    by: state_f \n  \n\n\n\n\n\n　今回はいずれも統計的に有意な結果が得られている。例えば、モデル7（did_fit7）の場合、処置効果の推定値は4.513である。これは学校内銃撃事件が発生したカウンティーの場合、大統領選挙において民主党候補者の得票率が約4.513%p増加することを意味する。\n　以上の結果を図としてまとめてみよう。\n\ntidy_fit7  <- tidy(did_fit7)\ntidy_fit8  <- tidy(did_fit8)\ntidy_fit9  <- tidy(did_fit9)\ntidy_fit10 <- tidy(did_fit10)\ntidy_fit11 <- tidy(did_fit11)\ntidy_fit12 <- tidy(did_fit12)\n\ndid_est2 <- bind_rows(list(\"M1_Tr1\" = tidy_fit7,\n                           \"M2_Tr1\" = tidy_fit8,\n                           \"M1_Tr2\" = tidy_fit9,\n                           \"M2_Tr2\" = tidy_fit10,\n                           \"M1_Tr3\" = tidy_fit11,\n                           \"M2_Tr3\" = tidy_fit12),\n                      .id = \"Model\")\n\ndid_est2\n\n    Model               term      estimate    std.error statistic      p.value\n1  M1_Tr1           shooting  4.513237e+00 8.752702e-01  5.156393 4.514820e-06\n2  M2_Tr1           shooting  2.363839e+00 7.367346e-01  3.208536 2.353748e-03\n3  M2_Tr1         population  3.174252e-05 6.778757e-06  4.682646 2.275534e-05\n4  M2_Tr1          non_white  8.687344e+01 1.786287e+01  4.863352 1.234074e-05\n5  M2_Tr1   change_unem_rate -1.389392e-01 1.274198e-01 -1.090405 2.808682e-01\n6  M1_Tr2     fatal_shooting  4.404109e+00 1.091944e+00  4.033274 1.920110e-04\n7  M2_Tr2     fatal_shooting  1.782393e+00 8.363792e-01  2.131083 3.812471e-02\n8  M2_Tr2         population  3.206812e-05 6.801197e-06  4.715070 2.039958e-05\n9  M2_Tr2          non_white  8.686629e+01 1.785535e+01  4.865000 1.227169e-05\n10 M2_Tr2   change_unem_rate -1.392341e-01 1.275138e-01 -1.091914 2.802109e-01\n11 M1_Tr3 non_fatal_shooting  4.216683e+00 1.298056e+00  3.248460 2.098382e-03\n12 M2_Tr3 non_fatal_shooting  2.929866e+00 1.037217e+00  2.824737 6.825655e-03\n13 M2_Tr3         population  3.229215e-05 6.717999e-06  4.806810 1.495567e-05\n14 M2_Tr3          non_white  8.679618e+01 1.785514e+01  4.861131 1.243440e-05\n15 M2_Tr3   change_unem_rate -1.400321e-01 1.274994e-01 -1.098296 2.774427e-01\n        conf.low    conf.high df outcome\n1   2.754316e+00 6.272159e+00 49 demvote\n2   8.833157e-01 3.844363e+00 49 demvote\n3   1.812010e-05 4.536494e-05 49 demvote\n4   5.097665e+01 1.227702e+02 49 demvote\n5  -3.949989e-01 1.171206e-01 49 demvote\n6   2.209766e+00 6.598453e+00 49 demvote\n7   1.016261e-01 3.463160e+00 49 demvote\n8   1.840061e-05 4.573564e-05 49 demvote\n9   5.098461e+01 1.227480e+02 49 demvote\n10 -3.954828e-01 1.170146e-01 49 demvote\n11  1.608142e+00 6.825225e+00 49 demvote\n12  8.454996e-01 5.014232e+00 49 demvote\n13  1.879182e-05 4.579247e-05 49 demvote\n14  5.091493e+01 1.226774e+02 49 demvote\n15 -3.962518e-01 1.161876e-01 49 demvote\n\n\n\ndid_est2 <- did_est2 |>\n  filter(grepl(\"shooting\", term))\n\ndid_est2\n\n   Model               term estimate std.error statistic      p.value  conf.low\n1 M1_Tr1           shooting 4.513237 0.8752702  5.156393 4.514820e-06 2.7543158\n2 M2_Tr1           shooting 2.363839 0.7367346  3.208536 2.353748e-03 0.8833157\n3 M1_Tr2     fatal_shooting 4.404109 1.0919440  4.033274 1.920110e-04 2.2097656\n4 M2_Tr2     fatal_shooting 1.782393 0.8363792  2.131083 3.812471e-02 0.1016261\n5 M1_Tr3 non_fatal_shooting 4.216683 1.2980560  3.248460 2.098382e-03 1.6081422\n6 M2_Tr3 non_fatal_shooting 2.929866 1.0372173  2.824737 6.825655e-03 0.8454996\n  conf.high df outcome\n1  6.272159 49 demvote\n2  3.844363 49 demvote\n3  6.598453 49 demvote\n4  3.463160 49 demvote\n5  6.825225 49 demvote\n6  5.014232 49 demvote\n\n\n\ndid_est2 <- did_est2 |>\n  separate(col  = Model,\n           into = c(\"Model\", \"Treat\"),\n           sep  = \"_\")\n\ndid_est2\n\n  Model Treat               term estimate std.error statistic      p.value\n1    M1   Tr1           shooting 4.513237 0.8752702  5.156393 4.514820e-06\n2    M2   Tr1           shooting 2.363839 0.7367346  3.208536 2.353748e-03\n3    M1   Tr2     fatal_shooting 4.404109 1.0919440  4.033274 1.920110e-04\n4    M2   Tr2     fatal_shooting 1.782393 0.8363792  2.131083 3.812471e-02\n5    M1   Tr3 non_fatal_shooting 4.216683 1.2980560  3.248460 2.098382e-03\n6    M2   Tr3 non_fatal_shooting 2.929866 1.0372173  2.824737 6.825655e-03\n   conf.low conf.high df outcome\n1 2.7543158  6.272159 49 demvote\n2 0.8833157  3.844363 49 demvote\n3 2.2097656  6.598453 49 demvote\n4 0.1016261  3.463160 49 demvote\n5 1.6081422  6.825225 49 demvote\n6 0.8454996  5.014232 49 demvote\n\n\n\ndid_est2 <- did_est2 |>\n  mutate(Model = if_else(Model == \"M1\",\n                           \"County-Year FE\", \n                           \"County-Year FE + Covariates\"),\n         Treat = recode(Treat,\n                        \"Tr1\" = \"Any Shooting (t-1)\",\n                        \"Tr2\" = \"Fatal Shooting (t-1)\",\n                        \"Tr3\" = \"Nonfatal Shooting (t-1)\"),\n         Model = fct_rev(fct_inorder(Model)),\n         Treat = fct_rev(fct_inorder(Treat)))\n\ndid_est2\n\n                        Model                   Treat               term\n1              County-Year FE      Any Shooting (t-1)           shooting\n2 County-Year FE + Covariates      Any Shooting (t-1)           shooting\n3              County-Year FE    Fatal Shooting (t-1)     fatal_shooting\n4 County-Year FE + Covariates    Fatal Shooting (t-1)     fatal_shooting\n5              County-Year FE Nonfatal Shooting (t-1) non_fatal_shooting\n6 County-Year FE + Covariates Nonfatal Shooting (t-1) non_fatal_shooting\n  estimate std.error statistic      p.value  conf.low conf.high df outcome\n1 4.513237 0.8752702  5.156393 4.514820e-06 2.7543158  6.272159 49 demvote\n2 2.363839 0.7367346  3.208536 2.353748e-03 0.8833157  3.844363 49 demvote\n3 4.404109 1.0919440  4.033274 1.920110e-04 2.2097656  6.598453 49 demvote\n4 1.782393 0.8363792  2.131083 3.812471e-02 0.1016261  3.463160 49 demvote\n5 4.216683 1.2980560  3.248460 2.098382e-03 1.6081422  6.825225 49 demvote\n6 2.929866 1.0372173  2.824737 6.825655e-03 0.8454996  5.014232 49 demvote\n\n\n\ndid_est2 |>\n  ggplot() +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Treat, color = Model),\n                  position = position_dodge2(1/2)) +\n  geom_text(aes(x = estimate, y = Treat, color = Model, \n                label = sprintf(\"%.3f\", estimate)),\n            position = position_dodge2(1/2),\n            vjust = -0.75) +\n  labs(x = \"Change in Democratic Vote Share (%p)\", y = \"\", color = \"\") +\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  coord_cartesian(xlim = c(-10, 10)) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　最後に、これまで作成した2つの図を一つにまとめてみよう。bind_rows()関数を使い、それぞれの表に識別子（Outcome）を与える。\n\ndid_est <- bind_rows(list(\"Out1\" = did_est1,\n                          \"Out2\" = did_est2),\n                     .id = \"Outcome\")\n\ndid_est\n\n   Outcome                       Model                   Treat\n1     Out1              County-Year FE      Any Shooting (t-1)\n2     Out1 County-Year FE + Covariates      Any Shooting (t-1)\n3     Out1              County-Year FE    Fatal Shooting (t-1)\n4     Out1 County-Year FE + Covariates    Fatal Shooting (t-1)\n5     Out1              County-Year FE Nonfatal Shooting (t-1)\n6     Out1 County-Year FE + Covariates Nonfatal Shooting (t-1)\n7     Out2              County-Year FE      Any Shooting (t-1)\n8     Out2 County-Year FE + Covariates      Any Shooting (t-1)\n9     Out2              County-Year FE    Fatal Shooting (t-1)\n10    Out2 County-Year FE + Covariates    Fatal Shooting (t-1)\n11    Out2              County-Year FE Nonfatal Shooting (t-1)\n12    Out2 County-Year FE + Covariates Nonfatal Shooting (t-1)\n                 term   estimate std.error  statistic      p.value   conf.low\n1            shooting -0.5210841 0.6456718 -0.8070417 4.235426e-01 -1.8186103\n2            shooting -0.7097922 0.6237320 -1.1379763 2.606641e-01 -1.9632286\n3      fatal_shooting -0.6779229 0.6191749 -1.0948810 2.789215e-01 -1.9222015\n4      fatal_shooting -0.9179995 0.6576559 -1.3958659 1.690478e-01 -2.2396086\n5  non_fatal_shooting -0.2387205 1.0938325 -0.2182423 8.281467e-01 -2.4368592\n6  non_fatal_shooting -0.3269742 1.1453027 -0.2854915 7.764710e-01 -2.6285461\n7            shooting  4.5132372 0.8752702  5.1563930 4.514820e-06  2.7543158\n8            shooting  2.3638394 0.7367346  3.2085357 2.353748e-03  0.8833157\n9      fatal_shooting  4.4041092 1.0919440  4.0332738 1.920110e-04  2.2097656\n10     fatal_shooting  1.7823931 0.8363792  2.1310825 3.812471e-02  0.1016261\n11 non_fatal_shooting  4.2166835 1.2980560  3.2484602 2.098382e-03  1.6081422\n12 non_fatal_shooting  2.9298657 1.0372173  2.8247368 6.825655e-03  0.8454996\n   conf.high df outcome\n1  0.7764420 49 turnout\n2  0.5436442 49 turnout\n3  0.5663557 49 turnout\n4  0.4036096 49 turnout\n5  1.9594182 49 turnout\n6  1.9745977 49 turnout\n7  6.2721585 49 demvote\n8  3.8443631 49 demvote\n9  6.5984529 49 demvote\n10 3.4631600 49 demvote\n11 6.8252248 49 demvote\n12 5.0142319 49 demvote\n\n\n　Outcome列のリコーディングし、factor化する。\n\ndid_est <- did_est |>\n  mutate(Outcome = if_else(Outcome == \"Out1\",\n                           \"Change in Turnout (%p)\",\n                           \"Change in Democratic Vote Share (%p)\"),\n         Outcome = fct_inorder(Outcome))\n\ndid_est\n\n                                Outcome                       Model\n1                Change in Turnout (%p)              County-Year FE\n2                Change in Turnout (%p) County-Year FE + Covariates\n3                Change in Turnout (%p)              County-Year FE\n4                Change in Turnout (%p) County-Year FE + Covariates\n5                Change in Turnout (%p)              County-Year FE\n6                Change in Turnout (%p) County-Year FE + Covariates\n7  Change in Democratic Vote Share (%p)              County-Year FE\n8  Change in Democratic Vote Share (%p) County-Year FE + Covariates\n9  Change in Democratic Vote Share (%p)              County-Year FE\n10 Change in Democratic Vote Share (%p) County-Year FE + Covariates\n11 Change in Democratic Vote Share (%p)              County-Year FE\n12 Change in Democratic Vote Share (%p) County-Year FE + Covariates\n                     Treat               term   estimate std.error  statistic\n1       Any Shooting (t-1)           shooting -0.5210841 0.6456718 -0.8070417\n2       Any Shooting (t-1)           shooting -0.7097922 0.6237320 -1.1379763\n3     Fatal Shooting (t-1)     fatal_shooting -0.6779229 0.6191749 -1.0948810\n4     Fatal Shooting (t-1)     fatal_shooting -0.9179995 0.6576559 -1.3958659\n5  Nonfatal Shooting (t-1) non_fatal_shooting -0.2387205 1.0938325 -0.2182423\n6  Nonfatal Shooting (t-1) non_fatal_shooting -0.3269742 1.1453027 -0.2854915\n7       Any Shooting (t-1)           shooting  4.5132372 0.8752702  5.1563930\n8       Any Shooting (t-1)           shooting  2.3638394 0.7367346  3.2085357\n9     Fatal Shooting (t-1)     fatal_shooting  4.4041092 1.0919440  4.0332738\n10    Fatal Shooting (t-1)     fatal_shooting  1.7823931 0.8363792  2.1310825\n11 Nonfatal Shooting (t-1) non_fatal_shooting  4.2166835 1.2980560  3.2484602\n12 Nonfatal Shooting (t-1) non_fatal_shooting  2.9298657 1.0372173  2.8247368\n        p.value   conf.low conf.high df outcome\n1  4.235426e-01 -1.8186103 0.7764420 49 turnout\n2  2.606641e-01 -1.9632286 0.5436442 49 turnout\n3  2.789215e-01 -1.9222015 0.5663557 49 turnout\n4  1.690478e-01 -2.2396086 0.4036096 49 turnout\n5  8.281467e-01 -2.4368592 1.9594182 49 turnout\n6  7.764710e-01 -2.6285461 1.9745977 49 turnout\n7  4.514820e-06  2.7543158 6.2721585 49 demvote\n8  2.353748e-03  0.8833157 3.8443631 49 demvote\n9  1.920110e-04  2.2097656 6.5984529 49 demvote\n10 3.812471e-02  0.1016261 3.4631600 49 demvote\n11 2.098382e-03  1.6081422 6.8252248 49 demvote\n12 6.825655e-03  0.8454996 5.0142319 49 demvote\n\n\n　図の作り方はこれまでと変わらないが、ファセット分割を行うため、facet_wrap()レイヤーを追加する。\n\ndid_est |>\n  ggplot() +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Treat, color = Model),\n                  position = position_dodge2(1/2)) +\n  geom_text(aes(x = estimate, y = Treat, color = Model, \n                label = sprintf(\"%.3f\", estimate)),\n            position = position_dodge2(1/2),\n            vjust = -0.75) +\n  labs(x = \"Treatment Effects\", y = \"\", color = \"\") +\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  coord_cartesian(xlim = c(-10, 10)) +\n  facet_wrap(~Outcome, ncol = 2) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　以上の結果から「学校内銃撃事件の発生は投票参加を促すとは言えないものの、民主党候補者の得票率を上げる」ということが言えよう。"
  },
  {
    "objectID": "material/intro.html",
    "href": "material/intro.html",
    "title": "ガイダンス",
    "section": "",
    "text": "新しいタブで開く"
  },
  {
    "objectID": "material/r.html",
    "href": "material/r.html",
    "title": "Rの復習",
    "section": "",
    "text": "通常、Rでのパッケージのインストールとアップーでとにはinstall.packages()関数、読み込みにはlibrary()、またはrequire()関数を使う。また、R公式レポジトリにないパッケージは{devtools}か{remote}パッケージを使う。これらの関数を使い分けることは面倒なので、本講義ではこれらの処理を統合した{pacman}パッケージを使用する。まずは、{pacman}パッケージをインストールする。\n\n# NIIオンライン分析システムを利用する場合、導入済み\ninstall.packages(\"pacman\")\n\n　パッケージを読み込む際、pacman::p_load(読み込むパッケージ名)を入力する。インストールされていない場合は、自動的にCRANからダウンロード&インストールした上で読み込んでくれるので便利だ1。以下では本講義で使用するパッケージとして{tidyverse}、{summarytools}、{fastDummies}、{modelsummary}を読み込む。\n\npacman::p_load(tidyverse, summarytools, fastDummies,\n               modelsummary, broom)\n\n　CRANでなく、GitHub上で公開されているパッケージを使う場合はpacman::p_load_gh()を使用する。()の中には\"ユーザー名/リポジトリ名\"を入力。たとえば、{BalanceR}の作成者のGitHubアカウント名はJaehyunSongであり、{BalanceR}のリポジトリ名はBalanceRだから、以下のように入力する。\n\npacman::p_load_gh(\"JaehyunSong/BalanceR\")"
  },
  {
    "objectID": "material/r.html#データの読み込みと確認",
    "href": "material/r.html#データの読み込みと確認",
    "title": "Rの復習",
    "section": "データの読み込みと確認",
    "text": "データの読み込みと確認\n　.csv形式のデータを読み込むにはread_csv()関数を使用する。()内には読み込むファイルのパスを\"で囲んで記入する。read_csv()関数はファイルの読み込みのみの機能しか持たない。現在の作業環境内に読み込んだデータを格納するためには代入演算子<-を使う。ここではdataフォルダー内のrct_data.csvを読み込み2、raw_dfという名のオブジェクトとしてく格納する。作業環境内のオブジェクトはRを再起動すると削除されるため、改めてパッケージ/データの読み込みが必要だ。\n\nraw_df <- read_csv(\"data/rct_data.csv\")\n\nRows: 5000 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): treatment, gender, voted2000, voted2002, voted2004, voted2006\ndbl (2): yob, hh_size\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n　オブジェクトの中身を出力するためにはオブジェクト名を入力する。\n\nraw_df\n\n# A tibble: 5,000 × 8\n   treatment  gender   yob hh_size voted2000 voted2002 voted2004 voted2006\n   <chr>      <chr>  <dbl>   <dbl> <chr>     <chr>     <chr>     <chr>    \n 1 Hawthorne  female  1955       1 no        yes       no        no       \n 2 Hawthorne  male    1969       2 no        yes       no        no       \n 3 Control    female  1944       2 no        no        no        no       \n 4 Control    male    1974       2 no        no        yes       no       \n 5 Neighbors  female  1969       2 no        no        yes       no       \n 6 Control    male    1942       1 no        yes       no        no       \n 7 Civic Duty male    1969       2 yes       no        no        no       \n 8 Hawthorne  male    1966       2 no        yes       no        yes      \n 9 Control    male    1949       2 no        yes       yes       no       \n10 Control    female  1958       2 no        yes       no        no       \n# … with 4,990 more rows\n\n\n　表形式データの大きさ（行の列の数）の確認にはdim()関数を使う。\n\ndim(raw_df)\n\n[1] 5000    8\n\n\n　表形式データの場合、各列には名前が付いており、それぞれが一つの変数に該当する。これら変数名のみの出力にはnames()関数を使う。今回のデータだと、列の数が少ないこともあり、一画面に全列が表示されるが、数百列のデータとなると画面に収まらないので、変数名を確認しておくことを推奨する。\n\nnames(raw_df)\n\n[1] \"treatment\" \"gender\"    \"yob\"       \"hh_size\"   \"voted2000\" \"voted2002\"\n[7] \"voted2004\" \"voted2006\""
  },
  {
    "objectID": "material/r.html#データハンドリングとパイプ演算子",
    "href": "material/r.html#データハンドリングとパイプ演算子",
    "title": "Rの復習",
    "section": "データハンドリングとパイプ演算子",
    "text": "データハンドリングとパイプ演算子\n　パイプ演算子には{magrittr}パッケージが提供する%>%とR 4.1から提供されるネイティブパイプ演算子の|>がある。現在の主流は古くから使われてきた%>%であるが、今後、|>が主流になると考えられるため、本講義では|>を使用する。しかし、多くの場合、|>の代わりに%>%を使っても同じ結果が得られる。\n　パイプ演算子はパイプ前のオブジェクトを、パイプ後の関数の第一引数として渡す単純な演算子だ。たとえば、列名を変更する関数はrename()であるが、使い方はrenames(データ名, 新しい列名 = 既存の列名, ...)である。raw_dfのgender列の名前をfemaleに変更する場合は以下のように書く。\n\nrename(raw_df, female = gender)\n\n# A tibble: 5,000 × 8\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   <chr>      <chr>  <dbl>   <dbl> <chr>     <chr>     <chr>     <chr>    \n 1 Hawthorne  female  1955       1 no        yes       no        no       \n 2 Hawthorne  male    1969       2 no        yes       no        no       \n 3 Control    female  1944       2 no        no        no        no       \n 4 Control    male    1974       2 no        no        yes       no       \n 5 Neighbors  female  1969       2 no        no        yes       no       \n 6 Control    male    1942       1 no        yes       no        no       \n 7 Civic Duty male    1969       2 yes       no        no        no       \n 8 Hawthorne  male    1966       2 no        yes       no        yes      \n 9 Control    male    1949       2 no        yes       yes       no       \n10 Control    female  1958       2 no        yes       no        no       \n# … with 4,990 more rows\n\n\n　ここで第1引数がraw_dfだが、パイプ演算子を使うと以下のようになり、人間にとって読みやすいコードになる。\n\nraw_df |>\n  rename(female = gender)\n\n# A tibble: 5,000 × 8\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   <chr>      <chr>  <dbl>   <dbl> <chr>     <chr>     <chr>     <chr>    \n 1 Hawthorne  female  1955       1 no        yes       no        no       \n 2 Hawthorne  male    1969       2 no        yes       no        no       \n 3 Control    female  1944       2 no        no        no        no       \n 4 Control    male    1974       2 no        no        yes       no       \n 5 Neighbors  female  1969       2 no        no        yes       no       \n 6 Control    male    1942       1 no        yes       no        no       \n 7 Civic Duty male    1969       2 yes       no        no        no       \n 8 Hawthorne  male    1966       2 no        yes       no        yes      \n 9 Control    male    1949       2 no        yes       yes       no       \n10 Control    female  1958       2 no        yes       no        no       \n# … with 4,990 more rows\n\n\n　要するに、X |> Yは「X（の結果）を使ってYを行う」ことを意味する。\n　続いて、変数のリコーディングをしてみよう。xの値が\"A\"なら1、それ以外は0のように、戻り値が2種類の場合のリコーディングにはif_else()を使用する。書き方は以下の通りだ。\n\nif_else(条件式, 条件が満たされる場合の戻り値, 条件が満たされない場合の戻り値)\n\n　たとえば、raw_dfのgender列の値が\"female\"なら1、それ以外なら0とし、その結果をfemale列として追加するコードは以下の通り。同値を意味する演算子が=でなく、==であることに注意すること（=は<-と同じ代入演算子であるが、Rでは代入演算子として=より<-の使用を推奨している）。\n\nmutate(raw_df, \n       female = if_else(gender == \"female\", 1, 0))\n\n# A tibble: 5,000 × 9\n   treatment  gender   yob hh_size voted2000 voted2002 voted2004 voted2…¹ female\n   <chr>      <chr>  <dbl>   <dbl> <chr>     <chr>     <chr>     <chr>     <dbl>\n 1 Hawthorne  female  1955       1 no        yes       no        no            1\n 2 Hawthorne  male    1969       2 no        yes       no        no            0\n 3 Control    female  1944       2 no        no        no        no            1\n 4 Control    male    1974       2 no        no        yes       no            0\n 5 Neighbors  female  1969       2 no        no        yes       no            1\n 6 Control    male    1942       1 no        yes       no        no            0\n 7 Civic Duty male    1969       2 yes       no        no        no            0\n 8 Hawthorne  male    1966       2 no        yes       no        yes           0\n 9 Control    male    1949       2 no        yes       yes       no            0\n10 Control    female  1958       2 no        yes       no        no            1\n# … with 4,990 more rows, and abbreviated variable name ¹​voted2006\n\n\n　mutate()は指定された列に対して何らかの処理を行い、その結果を新しい列として追加するか、上書きする関数である。このmutate()関数の第1引数もデータであるため、以下のようにパイプ演算子を使うこともできる。\n\nraw_df |>\n  mutate(female = if_else(gender == \"female\", 1, 0))\n\n# A tibble: 5,000 × 9\n   treatment  gender   yob hh_size voted2000 voted2002 voted2004 voted2…¹ female\n   <chr>      <chr>  <dbl>   <dbl> <chr>     <chr>     <chr>     <chr>     <dbl>\n 1 Hawthorne  female  1955       1 no        yes       no        no            1\n 2 Hawthorne  male    1969       2 no        yes       no        no            0\n 3 Control    female  1944       2 no        no        no        no            1\n 4 Control    male    1974       2 no        no        yes       no            0\n 5 Neighbors  female  1969       2 no        no        yes       no            1\n 6 Control    male    1942       1 no        yes       no        no            0\n 7 Civic Duty male    1969       2 yes       no        no        no            0\n 8 Hawthorne  male    1966       2 no        yes       no        yes           0\n 9 Control    male    1949       2 no        yes       yes       no            0\n10 Control    female  1958       2 no        yes       no        no            1\n# … with 4,990 more rows, and abbreviated variable name ¹​voted2006\n\n\n　また、mutate()内には複数のコードを書くこともできる。voted2000列からvoted2006列までそれぞれの値が\"yes\"であれば、1を、それ以外の場合は0にリコーディングしてみよう。\n\nraw_df |>\n  mutate(female    = if_else(gender    == \"female\", 1, 0),\n         voted2000 = if_else(voted2000 == \"yes\", 1, 0),\n         voted2002 = if_else(voted2002 == \"yes\", 1, 0),\n         voted2004 = if_else(voted2004 == \"yes\", 1, 0),\n         voted2006 = if_else(voted2006 == \"yes\", 1, 0))\n\n# A tibble: 5,000 × 9\n   treatment  gender   yob hh_size voted2000 voted2002 voted2004 voted2…¹ female\n   <chr>      <chr>  <dbl>   <dbl>     <dbl>     <dbl>     <dbl>    <dbl>  <dbl>\n 1 Hawthorne  female  1955       1         0         1         0        0      1\n 2 Hawthorne  male    1969       2         0         1         0        0      0\n 3 Control    female  1944       2         0         0         0        0      1\n 4 Control    male    1974       2         0         0         1        0      0\n 5 Neighbors  female  1969       2         0         0         1        0      1\n 6 Control    male    1942       1         0         1         0        0      0\n 7 Civic Duty male    1969       2         1         0         0        0      0\n 8 Hawthorne  male    1966       2         0         1         0        1      0\n 9 Control    male    1949       2         0         1         1        0      0\n10 Control    female  1958       2         0         1         0        0      1\n# … with 4,990 more rows, and abbreviated variable name ¹​voted2006\n\n\n　また、パイプ演算子は2つ以上使うこともできる。たとえば、rename()を使ってgender列をfemaleに変更し、mutate()でリコーディングを行う場合、以下のように書く。これはraw_dfを使ってrename()の処理を行い、その結果をmutate()関数のデータとして渡すことを意味する。\n\nraw_df |>\n  rename(female = gender) |>\n  mutate(female    = if_else(female    == \"female\", 1, 0),\n         voted2000 = if_else(voted2000 == \"yes\", 1, 0),\n         voted2002 = if_else(voted2002 == \"yes\", 1, 0),\n         voted2004 = if_else(voted2004 == \"yes\", 1, 0),\n         voted2006 = if_else(voted2006 == \"yes\", 1, 0))\n\n# A tibble: 5,000 × 8\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   <chr>       <dbl> <dbl>   <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n 1 Hawthorne       1  1955       1         0         1         0         0\n 2 Hawthorne       0  1969       2         0         1         0         0\n 3 Control         1  1944       2         0         0         0         0\n 4 Control         0  1974       2         0         0         1         0\n 5 Neighbors       1  1969       2         0         0         1         0\n 6 Control         0  1942       1         0         1         0         0\n 7 Civic Duty      0  1969       2         1         0         0         0\n 8 Hawthorne       0  1966       2         0         1         0         1\n 9 Control         0  1949       2         0         1         1         0\n10 Control         1  1958       2         0         1         0         0\n# … with 4,990 more rows\n\n\n　以上のコードはデータを加工し、その結果を出力するだけであって、その結果を保存しない。もう一度raw_dfを出力してみても、これまでのデータ加工内容は反映されていないことが分かる。\n\nraw_df\n\n# A tibble: 5,000 × 8\n   treatment  gender   yob hh_size voted2000 voted2002 voted2004 voted2006\n   <chr>      <chr>  <dbl>   <dbl> <chr>     <chr>     <chr>     <chr>    \n 1 Hawthorne  female  1955       1 no        yes       no        no       \n 2 Hawthorne  male    1969       2 no        yes       no        no       \n 3 Control    female  1944       2 no        no        no        no       \n 4 Control    male    1974       2 no        no        yes       no       \n 5 Neighbors  female  1969       2 no        no        yes       no       \n 6 Control    male    1942       1 no        yes       no        no       \n 7 Civic Duty male    1969       2 yes       no        no        no       \n 8 Hawthorne  male    1966       2 no        yes       no        yes      \n 9 Control    male    1949       2 no        yes       yes       no       \n10 Control    female  1958       2 no        yes       no        no       \n# … with 4,990 more rows\n\n\n　このように頑張ってデータを加工したもののその結果が全く反映されていない。加工したデータを引き続き使っていくためには、加工結果を作業環境内に保存する必要がある。作業環境内にオブジェクトを保存するためには代入演算子（<-）を使い、名前を付けて作業空間内に保存する（ファイルとして保存されるわけではない）必要がある。今回は加工の結果をdfという名で保存する。raw_dfに上書きしても問題はないが、生データはとりあえず作業空間内に残しておくことを推奨する（Rに慣れれば上書きしても良い）。\n\ndf <- raw_df |>\n  rename(female = gender) |>\n  mutate(female    = if_else(female    == \"female\", 1, 0),\n         voted2000 = if_else(voted2000 == \"yes\", 1, 0),\n         voted2002 = if_else(voted2002 == \"yes\", 1, 0),\n         voted2004 = if_else(voted2004 == \"yes\", 1, 0),\n         voted2006 = if_else(voted2006 == \"yes\", 1, 0))\n\ndf\n\n# A tibble: 5,000 × 8\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   <chr>       <dbl> <dbl>   <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n 1 Hawthorne       1  1955       1         0         1         0         0\n 2 Hawthorne       0  1969       2         0         1         0         0\n 3 Control         1  1944       2         0         0         0         0\n 4 Control         0  1974       2         0         0         1         0\n 5 Neighbors       1  1969       2         0         0         1         0\n 6 Control         0  1942       1         0         1         0         0\n 7 Civic Duty      0  1969       2         1         0         0         0\n 8 Hawthorne       0  1966       2         0         1         0         1\n 9 Control         0  1949       2         0         1         1         0\n10 Control         1  1958       2         0         1         0         0\n# … with 4,990 more rows\n\n\n　ちなみに、across()関数とラムダ式（無名関数）を組み合わせると以上のコードをより効率的に書くこともできる。across()は強力な関数だが、初心者にはやや難しいかも知れない。詳細は『私たちのR』の第13.1章を参照されたい。\n\ndf <- raw_df |>\n  rename(female = gender) |>\n  mutate(female = if_else(female == \"female\", 1, 0),\n         # 第1引数: votedで始まる変数を対象に処理を行う\n         # 第2引数: 当該変数の値が\"yes\"なら1、それ以外なら0を割り当てる無名関数\n         #          無名関数は「~」で始まり、変数が入る箇所は.xと表記する\n         #          引数が当該変数のみであれば、「~」を付けずに関数のみでもOK\n         across(starts_with(\"voted\"), ~if_else(.x == \"yes\", 1, 0)))"
  },
  {
    "objectID": "material/r.html#記述統計量",
    "href": "material/r.html#記述統計量",
    "title": "Rの復習",
    "section": "記述統計量",
    "text": "記述統計量\n　記述統計量の計算には{summarytools}のdescr()関数が便利だ。descr(データ名)を入力するだけで各変数の記述統計量が出力される。実際にやってみると分かるが、情報量がかなり多い。しかし、実際の論文では各変数の歪度や尖度まで報告することはあまりないだろう。ここではstats引数を追加して、論文などでよく使う平均値（\"mean\"）、標準偏差（\"sd\"）、最小値（\"min\"）、最大値（\"max\"）、有効ケース数（\"n.valid\"）のみ出力する。\n\n# descr()の第一引数は表形式データのオブジェクト名であるため、\n# オブジェクト名 |> descr() \n# のような書き方でもOK\ndf |>\n  descr(stats = c(\"mean\", \"sd\", \"min\", \"max\", \"n.valid\"))\n\nNon-numerical variable(s) ignored: treatment\n\n\nDescriptive Statistics  \ndf  \nN: 5000  \n\n                 female   hh_size   voted2000   voted2002   voted2004   voted2006       yob\n------------- --------- --------- ----------- ----------- ----------- ----------- ---------\n         Mean      0.50      2.18        0.26        0.39        0.41        0.33   1955.75\n      Std.Dev      0.50      0.79        0.44        0.49        0.49        0.47     14.41\n          Min      0.00      1.00        0.00        0.00        0.00        0.00   1910.00\n          Max      1.00      6.00        1.00        1.00        1.00        1.00   1986.00\n      N.Valid   5000.00   5000.00     5000.00     5000.00     5000.00     5000.00   5000.00\n\n\n　ただし、descr()を使うと数値型（numeric）変数の記述統計量のみ表示される。dfだと、treatment列は文字型（character）であるため、表示されない3。各グループがサンプルの何割かを計算するためには、treatment変数をダミー変数へ変換する必要がある。ダミー変数の作成は面倒な作業であるが、{fastDummies}パッケージのdummy_cols()を使えば簡単にできる。dummy_cols()の中にはselect_columns = \"ダミー化する列名\"を入れれば、当該変数をダミー変数へ変換し、新しい列として追加してくれる。それではtreatment列をダミー化&追加し、その結果をdfに上書きしてみよう。\n\ndf <- df |>\n  dummy_cols(select_columns = \"treatment\")\n\ndf\n\n# A tibble: 5,000 × 13\n   treatm…¹ female   yob hh_size voted…² voted…³ voted…⁴ voted…⁵ treat…⁶ treat…⁷\n   <chr>     <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <int>   <int>\n 1 Hawthor…      1  1955       1       0       1       0       0       0       0\n 2 Hawthor…      0  1969       2       0       1       0       0       0       0\n 3 Control       1  1944       2       0       0       0       0       0       1\n 4 Control       0  1974       2       0       0       1       0       0       1\n 5 Neighbo…      1  1969       2       0       0       1       0       0       0\n 6 Control       0  1942       1       0       1       0       0       0       1\n 7 Civic D…      0  1969       2       1       0       0       0       1       0\n 8 Hawthor…      0  1966       2       0       1       0       1       0       0\n 9 Control       0  1949       2       0       1       1       0       0       1\n10 Control       1  1958       2       0       1       0       0       0       1\n# … with 4,990 more rows, 3 more variables: treatment_Hawthorne <int>,\n#   treatment_Neighbors <int>, treatment_Self <int>, and abbreviated variable\n#   names ¹​treatment, ²​voted2000, ³​voted2002, ⁴​voted2004, ⁵​voted2006,\n#   ⁶​`treatment_Civic Duty`, ⁷​treatment_Control\n\n\n　画面には表示されないが、出力結果の下段を見るとtreatment_で始まるいくつかの変数が追加されたことが分かる。ここでは\"tretmant\"で始まる列のみを抽出つして確認してみよう。\n\ndf |>\n  select(starts_with(\"treatment\"))\n\n# A tibble: 5,000 × 6\n   treatment  `treatment_Civic Duty` treatment_Control treatme…¹ treat…² treat…³\n   <chr>                       <int>             <int>     <int>   <int>   <int>\n 1 Hawthorne                       0                 0         1       0       0\n 2 Hawthorne                       0                 0         1       0       0\n 3 Control                         0                 1         0       0       0\n 4 Control                         0                 1         0       0       0\n 5 Neighbors                       0                 0         0       1       0\n 6 Control                         0                 1         0       0       0\n 7 Civic Duty                      1                 0         0       0       0\n 8 Hawthorne                       0                 0         1       0       0\n 9 Control                         0                 1         0       0       0\n10 Control                         0                 1         0       0       0\n# … with 4,990 more rows, and abbreviated variable names ¹​treatment_Hawthorne,\n#   ²​treatment_Neighbors, ³​treatment_Self\n\n\n　select()関数内には抽出する列名を入力するだけで良い。たとえば、femaleとyob列を抽出するならselect(female, yob)である。また、femaleからvoted2006までの意味でfemale:voted2006のような書き方もできる。他にも上の例のようにstarts_with()やends_with()、contain()を使って特定の文字列で始まる（で終わる、を含む）列を指定することもできる。一部の列を除外する場合は変数名の前に!か-を付ける。\n　とにかく、問題なくダミー化されていることが分かる。もう一度記述統計量を出してみよう。descr()は仕様上、出力される変数の順番はアルファベット順になるが、ここでは元の順番を維持するためにorder = \"p\"を追加する。また、通常の記述統計表が、先ほど見たものとは違って、各行が変数を、列は記述統計量を表す場合が多い。このように行と列を交換するためにはtranspose = TRUEを追加する4。\ndf |>\n  descr(stats = c(\"mean\", \"sd\", \"min\", \"max\", \"n.valid\"),\n        order = \"p\", transpose = TRUE, headings = FALSE)\nNon-numerical variable(s) ignored: treatment\n\n\n\n\nMean\nStd.Dev\nMin\nMax\nN.Valid\n\n\n\n\nfemale\n0.50\n0.50\n0.00\n1.00\n5000.00\n\n\nyob\n1955.75\n14.41\n1910.00\n1986.00\n5000.00\n\n\nhh_size\n2.18\n0.79\n1.00\n6.00\n5000.00\n\n\nvoted2000\n0.26\n0.44\n0.00\n1.00\n5000.00\n\n\nvoted2002\n0.39\n0.49\n0.00\n1.00\n5000.00\n\n\nvoted2004\n0.41\n0.49\n0.00\n1.00\n5000.00\n\n\nvoted2006\n0.33\n0.47\n0.00\n1.00\n5000.00\n\n\ntreatment_Civic Duty\n0.12\n0.32\n0.00\n1.00\n5000.00\n\n\ntreatment_Control\n0.56\n0.50\n0.00\n1.00\n5000.00\n\n\ntreatment_Hawthorne\n0.11\n0.32\n0.00\n1.00\n5000.00\n\n\ntreatment_Neighbors\n0.11\n0.31\n0.00\n1.00\n5000.00\n\n\ntreatment_Self\n0.11\n0.31\n0.00\n1.00\n5000.00\n\n\n\n　他にも以下のようにdfSummary()関数を使えば、綺麗な表としてまとめてくれる。しかも文字型、factor型変数の場合も度数分布表を作成してくれるので非常に便利だ。これも{summarytools}パッケージに含まれた機能なので、別途、パッケージを読み込む必要はない。\n\ndf |>\n  select(-starts_with(\"treatment_\")) |>\n  dfSummary(headings = FALSE) |> \n  print(method = \"render\", round.digits = 3)\n\n\n\n\n  \n    \n      No\n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Valid\n      Missing\n    \n  \n  \n    \n      1\n      treatment\n[character]\n      1. Civic Duty2. Control3. Hawthorne4. Neighbors5. Self\n      578(11.6%)2777(55.5%)572(11.4%)535(10.7%)538(10.8%)\n      \n      5000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      2\n      female\n[numeric]\n      Min  : 0Mean : 0.5Max  : 1\n      0:2494(49.9%)1:2506(50.1%)\n      \n      5000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      3\n      yob\n[numeric]\n      Mean (sd) : 1955.8 (14.4)min ≤ med ≤ max:1910 ≤ 1956 ≤ 1986IQR (CV) : 18 (0)\n      76 distinct values\n      \n      5000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      4\n      hh_size\n[numeric]\n      Mean (sd) : 2.2 (0.8)min ≤ med ≤ max:1 ≤ 2 ≤ 6IQR (CV) : 0 (0.4)\n      1:699(14.0%)2:3112(62.2%)3:831(16.6%)4:308(6.2%)5:45(0.9%)6:5(0.1%)\n      \n      5000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      5\n      voted2000\n[numeric]\n      Min  : 0Mean : 0.3Max  : 1\n      0:3722(74.4%)1:1278(25.6%)\n      \n      5000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      6\n      voted2002\n[numeric]\n      Min  : 0Mean : 0.4Max  : 1\n      0:3058(61.2%)1:1942(38.8%)\n      \n      5000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      7\n      voted2004\n[numeric]\n      Min  : 0Mean : 0.4Max  : 1\n      0:2941(58.8%)1:2059(41.2%)\n      \n      5000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      8\n      voted2006\n[numeric]\n      Min  : 0Mean : 0.3Max  : 1\n      0:3373(67.5%)1:1627(32.5%)\n      \n      5000\n(100.0%)\n      0\n(0.0%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.2)2022-12-07"
  },
  {
    "objectID": "material/r.html#バランスチェック",
    "href": "material/r.html#バランスチェック",
    "title": "Rの復習",
    "section": "バランスチェック",
    "text": "バランスチェック\n　バランスチェックの簡単な方法はグループごとに処置前変数（pre-treatment variables）の平均値を比較することである。無作為割当が成功しているのであれば、処置前に測定された変数の平均値は近似するはずである。ここではグループ（treatment）ごとに性別、誕生年、世帯規模、2000〜2004年の投票参加の平均値を比較してみる。\n\ndf |>\n  group_by(treatment) |>\n  summarise(female    = mean(female, na.rm = TRUE),\n            yob       = mean(yob, na.rm = TRUE),\n            hh_size   = mean(hh_size, na.rm = TRUE),\n            voted2000 = mean(voted2000, na.rm = TRUE),\n            voted2002 = mean(voted2002, na.rm = TRUE),\n            voted2004 = mean(voted2004, na.rm = TRUE))\n\n# A tibble: 5 × 7\n  treatment  female   yob hh_size voted2000 voted2002 voted2004\n  <chr>       <dbl> <dbl>   <dbl>     <dbl>     <dbl>     <dbl>\n1 Civic Duty  0.517 1957.    2.22     0.239     0.374     0.394\n2 Control     0.491 1956.    2.17     0.261     0.390     0.411\n3 Hawthorne   0.507 1956.    2.23     0.257     0.385     0.416\n4 Neighbors   0.507 1955.    2.13     0.247     0.406     0.439\n5 Self        0.526 1956.    2.19     0.253     0.383     0.401\n\n\n　それぞれの変数の平均値は非常に似ているため、無作為割当が成功したと考えられる。しかし、変数の単位によって判断が難しいかも知れない。たとえば、2つのグループがあり、年齢の平均値の差は3、世帯規模のそれは2だとする。これを見ると年齢の方がよりバランスが取れていないようにも見えるが、年齢の幅は数十であるに対し、世帯規模はせいぜい5〜6程度であろう。したがって、各変数のばらつきまで考慮した比較が適切であり、その方法の一つが標準化バイアス（=標準化差分）である。\n　標準化差分を計算する便利パッケージ、{BalanceR}を使ってみよう。第1引数はデータだから、パイプで渡せば良い。BalanceR()内にはgroup引数にグループ識別変数を、covには処置前変数のベクトルを入れる。\n\nblc_chk <- df |>\n  BalanceR(group = treatment,\n           cov   = c(female, yob, hh_size, voted2000, voted2002, voted2004))\n\nblc_chk\n\n  Covariate Mean:Civic Duty SD:Civic Duty Mean:Control SD:Control\n1    female           0.517         0.500        0.491      0.500\n2       yob        1957.304        14.515     1955.555     14.453\n3   hh_size           2.225         0.810        2.169      0.777\n4 voted2000           0.239         0.427        0.261      0.439\n5 voted2002           0.374         0.484        0.390      0.488\n6 voted2004           0.394         0.489        0.411      0.492\n  Mean:Hawthorne SD:Hawthorne Mean:Neighbors SD:Neighbors Mean:Self SD:Self\n1          0.507        0.500          0.507        0.500     0.526   0.500\n2       1955.909       14.638       1954.976       14.510  1955.719  13.639\n3          2.231        0.809          2.129        0.786     2.193   0.772\n4          0.257        0.437          0.247        0.432     0.253   0.435\n5          0.385        0.487          0.406        0.491     0.383   0.487\n6          0.416        0.493          0.439        0.497     0.401   0.491\n  SB:Civic Duty-Control SB:Civic Duty-Hawthorne SB:Civic Duty-Neighbors\n1                 5.299                   2.062                   2.153\n2                12.082                   9.573                  16.047\n3                 7.102                  -0.723                  12.018\n4                -5.157                  -4.225                  -1.860\n5                -3.353                  -2.249                  -6.546\n6                -3.420                  -4.405                  -9.094\n  SB:Civic Duty-Self SB:Control-Hawthorne SB:Control-Neighbors SB:Control-Self\n1             -1.746               -3.236               -3.145          -7.046\n2             11.255               -2.437                3.997          -1.173\n3              3.994               -7.847                5.060          -3.199\n4             -3.260                0.931                3.296           1.896\n5             -1.897                1.103               -3.191           1.456\n6             -1.435               -0.985               -5.669           1.985\n  SB:Hawthorne-Neighbors SB:Hawthorne-Self SB:Neighbors-Self\n1                  0.090            -3.809            -3.899\n2                  6.404             1.341            -5.281\n3                 12.763             4.739            -8.258\n4                  2.365             0.965            -1.400\n5                 -4.295             0.353             4.648\n6                 -4.684             2.970             7.656\n\n\n　ちなみに、df内にfemaleからvoted2004は連続している（names(df)で確認してみよう）。この場合は以下のように（female:voted2004）書き換えることもできる。\n\nblc_chk <- df |>\n  BalanceR(group = treatment,\n           cov   = female:voted2004)\n\nblc_chk\n\n　標準化差分（標準化バイアス）を用いたバランスチェックはそれぞれのペアごとに計算を行うため、グループが多い場合は凡例が圧迫される場合が多い。しかし、重要なのは標準化差分の最大値だろう。ペア1、2、3でバランスが取れても、ペア4のバランスが取られていない場合は無意味だからだ。また、標準化差分の場合、符号の意味はなく、絶対値が重要だ。また、バランスチェックにおいてグループごとの平均値や標準偏差は不要である。ここでsummary()関数を使うと、絶対値が最も大きい標準化差分のみ出力される。\n\nsummary(blc_chk)\n\n  Covariate Abs_Maximum_SB\n1    female          7.046\n2       yob         16.047\n3   hh_size         12.763\n4 voted2000          5.157\n5 voted2002          6.546\n6 voted2004          9.094\n\n\n　plot()関数を使えば、これらの結果を可視化することもできる。\n\nplot(blc_chk)\n\n\n\n\n図 1: ?(caption)\n\n\n\n\n　先ほど述べたようにバランスチェックで重要なのは絶対値が最も大きい標準化差分である。plot()内にsimplify = TRUEを指定すれば最大値のみ表示され、更にabs = TRUEにすると絶対値へ変換される。また、垂直のガイドラインはvline引数で変更できる。\n\n# plot() の第1引数は blc_chk なのでパイプの使える\nblc_chk |>\n  plot(vline = c(5, 10), simplify = TRUE, abs = TRUE)\n\n\n\n\n図 2: ?(caption)"
  },
  {
    "objectID": "material/r.html#処置効果の確認",
    "href": "material/r.html#処置効果の確認",
    "title": "Rの復習",
    "section": "処置効果の確認",
    "text": "処置効果の確認\n\nグループごとの応答変数の平均値\n　処置効果を確認するためには各グループごとの応答変数（ここではvoted2006）の平均値を計算し、処置群の平均値から統制群の平均値を引く必要がある。まずは、特定の変数の平均値を計算する方法について紹介する。データ内にある特定の変数の平均値を計算するためにはsummarise()関数内に平均値を求めるmean()関数を入れる。たとえば、dfのvoted2006の平均値を計算するコードは以下の通りである。\n\ndf |>\n  summarise(mean(voted2006, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  `mean(voted2006, na.rm = TRUE)`\n                            <dbl>\n1                           0.325\n\n\n　na.rm = TRUEは「欠損値があれば、それを除外する」を意味し、指定されていない場合（=既定値）はFALSEになる。今回は欠損値がないものの、念の為に入れておく。\n　出力結果を見ると、平均値が表示される列の名前が`mean(voted2006, na.rm = TRUE)`となっており、非常に見にくい。この場合、以下のようにmean()の前に出力される列名を予め指定することもできる。\n\ndf |>\n  # voted2006の平均値が表示される列名を Outcome にする。\n  summarise(Outcome = mean(voted2006, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  Outcome\n    <dbl>\n1   0.325\n\n\n　我々が知りたいのはvoted2006の平均値でなく、グループごとの平均値だろう。被験者がどのグループに属しているかわ示す変数はtreatmentであるが、summarise()にデータを渡す前にgroup_by()変数を使うと、グループごとに計算を行い、その結果を返す。\n\ndf |>\n  group_by(treatment) |>\n  summarise(Outcome = mean(voted2006, na.rm = TRUE))\n\n# A tibble: 5 × 2\n  treatment  Outcome\n  <chr>        <dbl>\n1 Civic Duty   0.317\n2 Control      0.299\n3 Hawthorne    0.339\n4 Neighbors    0.421\n5 Self         0.364\n\n\n　group_by()内でも=演算子を使うと、グループ名が出力される列名を変更することができる。\n\ndf |>\n  # グループ名が表示される列名を Group にする。\n  group_by(Groups = treatment) |>\n  summarise(Outcome = mean(voted2006, na.rm = TRUE))\n\n# A tibble: 5 × 2\n  Groups     Outcome\n  <chr>        <dbl>\n1 Civic Duty   0.317\n2 Control      0.299\n3 Hawthorne    0.339\n4 Neighbors    0.421\n5 Self         0.364\n\n\n　ここで一つ注目したいのが、グループの表示順番である。変数のデータ型が文字型だと（Rコンソール上でclass(df$treatment)を入力するか、dfの出力画面でtreatmentの下に<chr>と表示されていることで確認できる）、今のようにアルファベット順で表示される。しかし、統制群は最初か最後に来るのが通例である。この順番をアルファベット順でなく、任意の順番にするためにはtreatment変数をfactor型変数へ変換する必要がある。Factor型は「順序付きの文字型変数」だと理解しても良い5。列の追加・上書き（今回はtreatment列の上書き）の処理が必要なのでmutate()関数を使う。変数をfactor型に変換する関数はfactor()関数で、第1引数としてはfactor型へ変換する変数名を指定する。第2引数はlevelsであり、出力したい順番の文字型ベクトルを指定する。スペルミスに注意すること。\n\ndf |>\n  mutate(treatment = factor(treatment,\n                            levels = c(\"Control\", \"Civic Duty\",\n                                       \"Self\", \"Neighbors\", \"Hawthorne\")))\n\n# A tibble: 5,000 × 13\n   treatm…¹ female   yob hh_size voted…² voted…³ voted…⁴ voted…⁵ treat…⁶ treat…⁷\n   <fct>     <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <int>   <int>\n 1 Hawthor…      1  1955       1       0       1       0       0       0       0\n 2 Hawthor…      0  1969       2       0       1       0       0       0       0\n 3 Control       1  1944       2       0       0       0       0       0       1\n 4 Control       0  1974       2       0       0       1       0       0       1\n 5 Neighbo…      1  1969       2       0       0       1       0       0       0\n 6 Control       0  1942       1       0       1       0       0       0       1\n 7 Civic D…      0  1969       2       1       0       0       0       1       0\n 8 Hawthor…      0  1966       2       0       1       0       1       0       0\n 9 Control       0  1949       2       0       1       1       0       0       1\n10 Control       1  1958       2       0       1       0       0       0       1\n# … with 4,990 more rows, 3 more variables: treatment_Hawthorne <int>,\n#   treatment_Neighbors <int>, treatment_Self <int>, and abbreviated variable\n#   names ¹​treatment, ²​voted2000, ³​voted2002, ⁴​voted2004, ⁵​voted2006,\n#   ⁶​`treatment_Civic Duty`, ⁷​treatment_Control\n\n\n　treatment列名の下が<fct>となっていることが分かる。これはtreatment列のデータ型がfactor型であることを意味する。問題なく動くことが確認できたので、dfを上書きしよう。\n\ndf <- df |>\n  mutate(treatment = factor(treatment,\n                            levels = c(\"Control\", \"Civic Duty\",\n                                       \"Self\", \"Neighbors\", \"Hawthorne\")))\n\n　それでは、改めてグループごとのvoted2006の平均値を計算してみよう。今回は計算結果をout_mean_dfという名のオブジェクトとして格納する。\n\nout_mean_df <- df |>\n  group_by(Groups = treatment) |>\n  summarise(Outcome = mean(voted2006, na.rm = TRUE))\n\nout_mean_df\n\n# A tibble: 5 × 2\n  Groups     Outcome\n  <fct>        <dbl>\n1 Control      0.299\n2 Civic Duty   0.317\n3 Self         0.364\n4 Neighbors    0.421\n5 Hawthorne    0.339\n\n\n　今回は統制群は最初に出力されていることが確認できる。\n　それではこの結果をグラフとして示してみよう。作図には{ggplot2}パッケージを使う。まずはout_mean_dfをggplot()関数に渡す。ggplot()関数以降は、+演算子を使ってレイヤーを足していくこととなる。棒グラフのレイヤーはgeom_bar()関数であり、その中にaes()関数を入れる。aes()の中には棒グラフの作図に必要な情報を入れる必要がある（これをマッピング（mapping）と呼ぶ）。棒グラフを作成するために必要な最低限の情報とは各棒の横軸上の位置（x）と棒の高さ（y）だ。今回は横軸がグループ名、縦軸が平均値となる棒グラフを作る。aes()外側にはstat = \"identity\"を忘れずに付けること。\n\nout_mean_df |>\n  ggplot() +\n  geom_bar(aes(x = Groups, y = Outcome), stat = \"identity\")\n\n\n\n\n図 3: ?(caption)\n\n\n\n\n　続いて、このグラフの見た目を調整してみよう。\n\nout_mean_df |>\n  ggplot() +\n  geom_bar(aes(x = Groups, y = Outcome), stat = \"identity\") +\n  # 縦軸（y軸）のラベルを変更する\n  labs(y = \"Mean(Outcome)\") +\n  # grayテーマ（デフォルトのテーマ）を使用し、フォントサイズは14\n  theme_gray(base_size = 14)\n\n\n\n\n図 4: ?(caption)\n\n\n\n\n　また、geom_label()レイヤーを足すと、棒の上にラベルを付けることもできる。ラベルに必要な情報は各ラベルの横軸上の位置（x）、縦軸上の位置（y）、ラベルの表示内容（label）だ。今回のラベルは平均値の具体的な数値を入れてみよう。\n\nout_mean_df |>\n  ggplot() +\n  geom_bar(aes(x = Groups, y = Outcome), stat = \"identity\") +\n  geom_label(aes(x = Groups, y = Outcome, label = Outcome)) +\n  labs(y = \"Mean(Outcome)\") +\n  theme_gray(base_size = 14)\n\n\n\n\n図 5: ?(caption)\n\n\n\n\n　小数点が長すぎるので3桁まで表示としよう。ここではsprintf()を使用する。使い方が簡単とは言えないが、覚える必要はなく、必要な時にググるか、本資料のコードをコピペすれば良い6。\n\nout_mean_df |>\n  ggplot() +\n  geom_bar(aes(x = Groups, y = Outcome), stat = \"identity\") +\n  # 2桁までなら %.3f を %.2f に変更\n  geom_label(aes(x = Groups, y = Outcome, label = sprintf(\"%.3f\", Outcome))) +\n  labs(y = \"Mean(Outcome)\") +\n  theme_gray(base_size = 14)\n\n\n\n\n図 6: ?(caption)\n\n\n\n\n　これで可視化ができた。ただし、以上のコードには改善の余地がある。geom_bar()とgeom_label()内のaes()関数に注目して欲しい。よく見るとxとyと同じだろう。geom_*()が共有するマッピングがあれば、ggplot()内で指定することでコードを効率化することもできる。\n\nout_mean_df |>\n  ggplot(aes(x = Groups, y = Outcome)) +\n  geom_bar(stat = \"identity\") +\n  geom_label(aes(label = sprintf(\"%.3f\", Outcome))) +\n  labs(y = \"Mean(Outcome)\") +\n  theme_gray(base_size = 14)\n\n\n\n\n図 7: ?(caption)\n\n\n\n\n\n\n統計的推定（単回帰分析）\n　これまでの作業はグループごとの応答変数の平均値であって、処置効果ではない。処置効果を計算するためには処置群の平均値から統制群の平均値を引く必要がある。たとえば、Civic Dutyはがき群の平均値は約0.317、統制群のそれは0.299であるため、Civic Dutyはがきの処置効果は約0.018である。しかし、これを各グループごとに計算することは面倒だし、何よりも得られた値が点推定値だという限界がある。得られた処置効果の不確実性は計算できない。\n　ここで有効なのが線形回帰分析である。回帰分析を行うことで処置効果の点推定値のみならず、不確実性の指標である標準誤差も計算され、区間推定や統計的仮説検定も可能となる。線形回帰分析の関数はlm()だ。第1引数としては回帰式であり、応答変数 ~ 説明変数と表記する。第2引数はdataであり、回帰式で指定した変数が入っているデータ名を指定する。回帰分析の結果は名前を付けてオブジェクトとして格納し、summary()関数を使うと、詳細が確認できる。\n\nfit1 <- lm(voted2006 ~ treatment, data = df)\n\nsummary(fit1)\n\n\nCall:\nlm(formula = voted2006 ~ treatment, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.4206 -0.3166 -0.2985  0.6357  0.7015 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         0.298524   0.008864  33.680  < 2e-16 ***\ntreatmentCivic Duty 0.018085   0.021355   0.847   0.3971    \ntreatmentSelf       0.065789   0.022002   2.990   0.0028 ** \ntreatmentNeighbors  0.122037   0.022053   5.534  3.3e-08 ***\ntreatmentHawthorne  0.040637   0.021447   1.895   0.0582 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4671 on 4995 degrees of freedom\nMultiple R-squared:  0.007123,  Adjusted R-squared:  0.006328 \nF-statistic: 8.959 on 4 and 4995 DF,  p-value: 3.312e-07\n\n\n　ちなみに、これもパイプ演算子を使うことができる。ただし、第1引数として渡すパイプ演算子の特徴上、そのまま使うことはできない。なぜならlm()関数の第1引数はデータでなく、回帰式（formula型）だから。この場合はプレースホルダー（place holder）を指定する必要がある。パイプ前のオブジェクトが入る位置を任意に指定することであり、_を使う。%>%演算子を使う場合は_でなく、.を使う。上記のコードと以下のコードは同じコードとなる。プレースホルダーは自分が使うパイプ演算子によって使い分けること。\n\nfit1 <- df |> # |> パイプを使う場合\n  lm(voted2006 ~ treatment, data = _)\n\nfit1 <- df %>% # %>% パイプを使う場合\n  lm(voted2006 ~ treatment, data = .)\n\n　Factor型、または文字型変数が説明変数の場合、自動的にダミー変数として処理され、Factor型の場合、最初の水準（ここでは\"Control\"）がベースカテゴリとなる。説明変数が文字型ならアルファベット順で最初の水準がベースカテゴリとなり、今回の例だと\"Civic Duty\"がベースカテゴリとなる。処置効果は「統制群に比べて〜」が重要となるので、数値型以外の説明変数は予めfactor化しておいた方が望ましい。\n　Civic Dutyの推定値は約0.018であり、これは統制群に比べ、Civic Duty群のvoted2006の平均値は約0.018高いことを意味する。応答変数が0、1であるため、これを割合（=投票率）で換算すると、約1.8%p高いことを意味する。つまり、Civic Dutyのはがきをもらった被験者はそうでない被験者に比べて投票率が約1.8%p高いことを意味する。他の推定値も同じやり方で解釈すれば良い。\n　それではこれらの処置効果が統計的に有意なものかを確認してみよう。統計的有意か否かを判定するためには有意と非有意の境界線が必要である、これは通常、有意水準（significance level; \\(\\alpha\\)）と呼ばれる。この有意水準は分析者が決めるものであるが、社会科学で広く使われる基準は\\(\\alpha = 0.05\\)、つまり5%だ。分析結果の画面にはPr(>|t|)列が表示されているが、これが\\(p\\)値と呼ばれるもので、これが0.05を下回る場合、統計的に有意と判定する。もし、\\(\\alpha = 0.1\\)を採用するなら、\\(p < 0.1\\)の場合において統計的に有意と判定する。Civic Dutyの\\(p\\)値は3.3e-08であり、これは\\(3.3 \\times 10^{-8}\\)を意味する。\\(10^{-1}\\)は0.1、\\(10^{-2}\\)は0.01であることを考えると非常に小さい数値であり、統計的に有意であると考えられる。また、\\(p\\)値が一定値以下であれば< 2e-16と表示される。今回の結果は、2つの処置群（SelfとNeighbors）において処置効果は統計的に有意であると判定できよう。\n　今回はサンプルサイズ34万から無作為抽出した\\(n\\)=5000のデータを使ったが、実際の論文ではいずれも統計的に有意である。なぜなら統計的有意性を判定する\\(p\\)値は処置効果の大きさ以外にも、推定値のばらつき具合（=標準誤差）の影響を受けるが、この標準誤差はサンプルサイズに反比例するからだ。ここで重要なことが分かる。それは「統計的に非有意な処置効果」は「処置効果がない」ことを意味しないことだ。たとえば、我々が日本人から男女3名ずつ抽出し、平均身長が同じだとしよう。ここから「母集団において男女の身長差はない」と解釈できるだろうか。それは全く誤りであろう。統計的に非有意な結果から分かるのは「現在のサンプル/手法/モデルにおいて男女間に身長差があるとは言えない」程度である。もう一回、男女3人ずつ抽出して比較してみれば差はあるかも知れない。また、今回はたまたま平均身長が同じだけであって、サンプルサイズが大きければ統計的に有意な差は得られるかも知れない。\n　一方、統計的に有意な差が得られたのであれば、「母集団において男女の身長差がある」と解釈できるようになる。これはもう一回、男女3人ずつ無作為抽出しても差が確認されることを意味する。むろん、100%ではない。もう一回やってみたところ、差がない可能性もある。ただし、その可能性は非常に小さく、その可能性が小さいことを、統計学では\\(p\\)値が小さいと言う。\\(p\\)値の厳密な意味は「帰無仮説が正しいと仮定した場合、今回得られた統計量と同じか、より極端な結果が得られる確率」である。身長差の例だと、帰無仮説は「男女間に身長差はない」であり、統計量とは\\(t\\)検定や単回帰分析の場合、「\\(t\\)統計量」を意味する。詳細はp値に関するアメリカ統計学会の声明や、矢内・SONG (2019)を参照すること。\n　話がややずれたが、Rの実習に戻そう。続いて、この結果を可視化してみよう。ここでも{ggplot2}パッケージを使って可視化をするが、{ggplot2}で使用可能なオブジェクトは表形式のデータである。Rコンソール上でclass(オブジェクト名)を入力すると、データのクラスが出力されるが、このクラスに\"data.frame\"があれば、{ggplot2}で使用できる。たとえば、fit1オブジェクトのクラスは\"lm\"であるため、そのまま{ggplot2}で使うことはできない。\n\nclass(fit1)\n\n[1] \"lm\"\n\n\n　推定結果を表形式に変換するためには{broom}パッケージのtidy()関数が便利だ。使い方は簡単でtidy()内に回帰分析の推定結果が格納されたオブジェクトを入れるだけである。ただし、デフォルトの設定では95%信頼区間が表示されないため、中にはconf.int = TRUEを追加しておく必要がある。\n\n# 90%信頼区間を使うのであれば conf.int = 0.9 を追加（デフォルトは0.95）\nfit1_coef <- tidy(fit1, conf.int = TRUE)\n\nfit1_coef\n\n# A tibble: 5 × 7\n  term                estimate std.error statistic   p.value conf.low conf.high\n  <chr>                  <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 (Intercept)           0.299    0.00886    33.7   2.80e-224  0.281      0.316 \n2 treatmentCivic Duty   0.0181   0.0214      0.847 3.97e-  1 -0.0238     0.0599\n3 treatmentSelf         0.0658   0.0220      2.99  2.80e-  3  0.0227     0.109 \n4 treatmentNeighbors    0.122    0.0221      5.53  3.30e-  8  0.0788     0.165 \n5 treatmentHawthorne    0.0406   0.0214      1.89  5.82e-  2 -0.00141    0.0827\n\nclass(fit1_coef)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n　fit1_coefのクラスに\"data.frame\"が含まれているので、これを使って作図することができる。\n　作図する前に、fit1_coefの加工しておきたい。それぞれの係数（estimate列）は処置効果を表しているが、切片（\"(Intercept)\"）の推定値は処置効果とは無関係である。したがって、予め切片の行を除外しておきたい。特定の行を残したり、除外する関数はfilter()である。今回はterm列の値が\"(Intercept)\"ではない行を残したいので、同値演算子（==）の否定を意味する!=演算子を使用する。\n\nfit1_coef <- fit1_coef |>\n  filter(term != \"(Intercept)\")\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term                estimate std.error statistic      p.value conf.low conf.…¹\n  <chr>                  <dbl>     <dbl>     <dbl>        <dbl>    <dbl>   <dbl>\n1 treatmentCivic Duty   0.0181    0.0214     0.847 0.397        -0.0238   0.0599\n2 treatmentSelf         0.0658    0.0220     2.99  0.00280       0.0227   0.109 \n3 treatmentNeighbors    0.122     0.0221     5.53  0.0000000330  0.0788   0.165 \n4 treatmentHawthorne    0.0406    0.0214     1.89  0.0582       -0.00141  0.0827\n# … with abbreviated variable name ¹​conf.high\n\n\n　それでは作図に入ろう。処置効果を示す場合は、点推定値以外にもその不確実性を示すのは一般的である。不確実性の指標として幅広く使われるのは標準誤差（standard error; 標準偏差ではない）であるが、可視化の際にはこの標準誤差に基づき計算した信頼区間を示すのが一般的だ。有意水準が5%であれば、95%信頼区間を示し、10%なら90%信頼区間を用いる。\n　点と区間を同時に示すプロットがpoint-rangeプロットであり、{ggplot2}ではgeom_pointrange()レイヤーを使う。必要な情報はpoint-rangeの横軸上の位置（x）、点の縦軸上の位置（y）、区間の上限（ymax）と下限（ymin）である。これらの情報は全てfit1_coefに入っているため、fit1_coefをそのままggplot()関数に渡して作図することができる。\n\nfit1_coef |>\n  ggplot() +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high))\n\n\n\n\n図 8: ?(caption)\n\n\n\n\n　それでは図をカスタマイズしてみよう。図内の様々なラベルを修正するlabs()レイヤーでラベルを修正する。テーマはデフォルトのtheme_gray()の代わりに白黒テーマ（theme_bw()）を使用し、フォントサイズは12とする。また、y = 0の水平線を追加する。95%信頼区間内に0が含まれる場合、「5%水準で統計的に有意でない」と判断できる。水平線を描くにはgeom_hline()レイヤーを追加し、yintercept = 0を指定することで、0のところに水平線が描ける。\n\nfit1_coef |>\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n図 9: ?(caption)\n\n\n\n\n　まだ気になる点がある。それは横軸の目盛りラベルにtreatmentという不要な情報がある点だ。これは作図の時点で修正することも可能だが、まずはdfのterm変数の値を修正する方法を紹介する。変数の値を修正する時にはrecode()関数を使用する。第1引数はリコーディングする変数名であり、引き続き\"元の値\" = \"新しい値\"を指定すれば良い。スペルミスに注意すること。\n\nfit1_coef <- fit1_coef |>\n  mutate(term = recode(term,\n                       \"treatmentCivic Duty\" = \"Civic Duty\",\n                       \"treatmentHawthorne\"  = \"Hawthorne\",\n                       \"treatmentNeighbors\"  = \"Neighbors\",\n                       \"treatmentSelf\"       = \"Self\"))\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term       estimate std.error statistic      p.value conf.low conf.high\n  <chr>         <dbl>     <dbl>     <dbl>        <dbl>    <dbl>     <dbl>\n1 Civic Duty   0.0181    0.0214     0.847 0.397        -0.0238     0.0599\n2 Self         0.0658    0.0220     2.99  0.00280       0.0227     0.109 \n3 Neighbors    0.122     0.0221     5.53  0.0000000330  0.0788     0.165 \n4 Hawthorne    0.0406    0.0214     1.89  0.0582       -0.00141    0.0827\n\n\n　以上の作業はterm列の各値から\"treatment\"文字を\"\"に置換することなので、文字列を置換する関数であるstr_replace()を使えば、より短くすることができる。\n\nfit1_coef <- fit1_coef |>\n  mutate(term = str_replace(term, \"treatment\", \"\"))\n\n　fit1_coefも修正できたので、 図 9 と同じコードでもう一度作図してみよう。\n\nfit1_coef |>\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n図 10: ?(caption)\n\n\n\n\n　最後に横軸の順番を修正してみよう。fit1_coefのterm列は文字型変数であるため、アルファベット順になる。これをdfのtreatment列と同様、Civic Duty、Self、Neighbors、Hawthorneの順にしたい。この場合fit1_coefのterm列をfactor化すれば良い。factor()関数を使っても良いが、ここではまた便利な技を紹介しよう。それはfct_inorder()関数だ。これは表示されている順番をfactorの順番とする関数だ。実際、fit1_coefの中身を見ると、表示順番はCivic Duty、Self、Neighbors、Hawthorneだ。非常に嬉しい状況なので、fct_inorder()を使ってみよう。\n\nfit1_coef <- fit1_coef |>\n  mutate(term = fct_inorder(term))\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term       estimate std.error statistic      p.value conf.low conf.high\n  <fct>         <dbl>     <dbl>     <dbl>        <dbl>    <dbl>     <dbl>\n1 Civic Duty   0.0181    0.0214     0.847 0.397        -0.0238     0.0599\n2 Self         0.0658    0.0220     2.99  0.00280       0.0227     0.109 \n3 Neighbors    0.122     0.0221     5.53  0.0000000330  0.0788     0.165 \n4 Hawthorne    0.0406    0.0214     1.89  0.0582       -0.00141    0.0827\n\n\n　それでは、 図 10 と同じコードでもう一度作図してみよう。\n\nfit1_coef |>\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n図 11: ?(caption)\n\n\n\n\n　これで処置効果の可視化もバッチリだ。\n\n\n多重比較の問題\n　グループが2つ、つまり統制群と統制群のみが存在する場合、我々が比較を行う回数は1回のみである（統制群 - 処置群）。しかし、今回のデータの場合、処置群は4つである。これは比較を4回行うことを意味する。具体的には「統制群 - 処置群1」、「統制群 - 処置群2」、「統制群 - 処置群3」、「統制群 - 処置群4」だ。比較を繰り返すほど、統計的に有意な結果が得られる可能性は高い。極端な話、1000回程度検定を繰り返せば、本当は効果がなくてもたまたま統計的に有意な結果が何回かは得られるだろう。これが多重検定（multiple testing）の問題である。したがって、比較の回数が多くなるにつれ、統計的有意性検定にも何らかのペナルティーを課す必要がある。\n　多重比較におけるペナルティーの付け方はいくつかあるが、ここでは最も保守的な（=研究者にとって都合の悪い）補正法であるボンフェローニ補正（Bonferroni correction）を紹介する。これは非常に単純で、\\(p\\)値や信頼区間を計算する際、「統計的有意」と判定されるハードルを上げる方法である。予め決めておいた有意水準（\\(\\alpha\\)）が0.05で、比較の回数が4回であれば、\\(p\\)値が\\(0.05 \\times \\frac{1}{4} = 0.0125\\)を下回る場合において「5%水準で有意である」と判定する。信頼区間でいえば通常の95%信頼区間（1 - 0.05）でなく、98.75%信頼区間（1 - 0.0125）を使うこととなる。この結果、統計的に有意な結果が得られたら「1.25%水準で〜」と解釈するのではなく、「5%水準で〜」と解釈する必要がある。\n　95%以外の信頼区間を求めるのは簡単で、tidy()関数内にconf.levelを修正すれば良い。指定されていない場合はデフォルトで0.95が割り当てられているが、これを0.9875と修正する。\n\nfit1_coef <- tidy(fit1, conf.int = TRUE, conf.level = 0.9875)\n\nfit1_coef\n\n# A tibble: 5 × 7\n  term                estimate std.error statistic   p.value conf.low conf.high\n  <chr>                  <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 (Intercept)           0.299    0.00886    33.7   2.80e-224   0.276     0.321 \n2 treatmentCivic Duty   0.0181   0.0214      0.847 3.97e-  1  -0.0353    0.0714\n3 treatmentSelf         0.0658   0.0220      2.99  2.80e-  3   0.0108    0.121 \n4 treatmentNeighbors    0.122    0.0221      5.53  3.30e-  8   0.0669    0.177 \n5 treatmentHawthorne    0.0406   0.0214      1.89  5.82e-  2  -0.0130    0.0942\n\n\n　それでは 図 11 と同じ図を作ってみよう。まず、切片の行を除外するが、ここではfilter()を使わず、slice()の使った方法を紹介する。slice()は()内に指定した行を残す関数だ。たとえば、slice(fit1_coef, 2)ならfit1_coefの2行目のみを残す。fit1_coefはslice()の第1引数だから、パイプ演算子を使うことも可能で、こちらの方を推奨する。そうすれば()内には残す行のみの指定で済む。slice(2)のみなら2行目を残し、slice(1, 3, 5)なら1、3、5行目を残す。:を使うと「〜行目から〜行目まで」の指定ができる。処置効果の係数はfit1_coefの2行目から5行目までなので、2:5と指定すれば良い。\n\nfit1_coef <- fit1_coef |>\n  slice(2:5)\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term                estimate std.error statistic      p.value conf.low conf.…¹\n  <chr>                  <dbl>     <dbl>     <dbl>        <dbl>    <dbl>   <dbl>\n1 treatmentCivic Duty   0.0181    0.0214     0.847 0.397         -0.0353  0.0714\n2 treatmentSelf         0.0658    0.0220     2.99  0.00280        0.0108  0.121 \n3 treatmentNeighbors    0.122     0.0221     5.53  0.0000000330   0.0669  0.177 \n4 treatmentHawthorne    0.0406    0.0214     1.89  0.0582        -0.0130  0.0942\n# … with abbreviated variable name ¹​conf.high\n\n\n　続いて、term変数の値から\"treatment\"の文字を除去し、fit1_coefでの出力順番でtermをfactor化する。\n\nfit1_coef <- fit1_coef |>\n  mutate(term = recode(term,\n                       \"treatmentCivic Duty\" = \"Civic Duty\",\n                       \"treatmentHawthorne\"  = \"Hawthorne\",\n                       \"treatmentNeighbors\"  = \"Neighbors\",\n                       \"treatmentSelf\"       = \"Self\"),\n         term = fct_inorder(term))\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term       estimate std.error statistic      p.value conf.low conf.high\n  <fct>         <dbl>     <dbl>     <dbl>        <dbl>    <dbl>     <dbl>\n1 Civic Duty   0.0181    0.0214     0.847 0.397         -0.0353    0.0714\n2 Self         0.0658    0.0220     2.99  0.00280        0.0108    0.121 \n3 Neighbors    0.122     0.0221     5.53  0.0000000330   0.0669    0.177 \n4 Hawthorne    0.0406    0.0214     1.89  0.0582        -0.0130    0.0942\n\n\n　最後に 図 11 と同じコードで作図する。\n\nfit1_coef |>\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", \n       y = \"Average Treatment Effects (w/ 98.75% CI)\") +\n  theme_bw(base_size = 12)\n\n\n\n\n図 12: ?(caption)\n\n\n\n\n\n\n統計的推定（重回帰分析）\n　今回の例は無作為割当が成功しており、処置前変数の偏りは見られない。しかし、何らかの理由で処置前変数の偏りが生じる場合がある。その「何らかの理由」が応答変数にまで影響を与えるのであれば、それは交絡変数（confounder）となり、バイアスの原因となる。この場合、偏りが生じている処置前変数を統制（control）することによってバイアスを小さくすることができる。今回は不要であるが、性別や誕生年などの共変量を統制した推定をしてみよう。\n　やり方は簡単で、lm()内の回帰式を応答変数 ~ 説明変数1 + 説明変数2 + ...のように説明変数を+で足していけば良い。\n\nfit2 <-lm(voted2006 ~ treatment + female + yob + hh_size +\n            voted2000 + voted2002 + voted2004, data = df)\n\nsummary(fit2)\n\n\nCall:\nlm(formula = voted2006 ~ treatment + female + yob + hh_size + \n    voted2000 + voted2002 + voted2004, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7573 -0.3447 -0.1953  0.5184  0.9506 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          6.0886118  0.9164461   6.644 3.39e-11 ***\ntreatmentCivic Duty  0.0307108  0.0205474   1.495 0.135074    \ntreatmentSelf        0.0703356  0.0211562   3.325 0.000892 ***\ntreatmentNeighbors   0.1147107  0.0212088   5.409 6.65e-08 ***\ntreatmentHawthorne   0.0423327  0.0206241   2.053 0.040165 *  \nfemale              -0.0240666  0.0127276  -1.891 0.058696 .  \nyob                 -0.0030326  0.0004705  -6.445 1.27e-10 ***\nhh_size              0.0025215  0.0085056   0.296 0.766896    \nvoted2000            0.0666981  0.0147950   4.508 6.69e-06 ***\nvoted2002            0.1644528  0.0133278  12.339  < 2e-16 ***\nvoted2004            0.1583835  0.0130339  12.152  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.449 on 4989 degrees of freedom\nMultiple R-squared:  0.08363,   Adjusted R-squared:  0.0818 \nF-statistic: 45.53 on 10 and 4989 DF,  p-value: < 2.2e-16\n\n\n　{modelsummary}パッケージのmodelsummary()関数を使えば、推定結果がより見やすくなる。\n\nmodelsummary(fit2)\n\n\n\n \n  \n      \n    Model 1 \n  \n \n\n  \n    (Intercept) \n    6.089 \n  \n  \n     \n    (0.916) \n  \n  \n    treatmentCivic Duty \n    0.031 \n  \n  \n     \n    (0.021) \n  \n  \n    treatmentSelf \n    0.070 \n  \n  \n     \n    (0.021) \n  \n  \n    treatmentNeighbors \n    0.115 \n  \n  \n     \n    (0.021) \n  \n  \n    treatmentHawthorne \n    0.042 \n  \n  \n     \n    (0.021) \n  \n  \n    female \n    −0.024 \n  \n  \n     \n    (0.013) \n  \n  \n    yob \n    −0.003 \n  \n  \n     \n    (0.0005) \n  \n  \n    hh_size \n    0.003 \n  \n  \n     \n    (0.009) \n  \n  \n    voted2000 \n    0.067 \n  \n  \n     \n    (0.015) \n  \n  \n    voted2002 \n    0.164 \n  \n  \n     \n    (0.013) \n  \n  \n    voted2004 \n    0.158 \n  \n  \n     \n    (0.013) \n  \n  \n    Num.Obs. \n    5000 \n  \n  \n    R2 \n    0.084 \n  \n  \n    R2 Adj. \n    0.082 \n  \n  \n    AIC \n    6195.0 \n  \n  \n    BIC \n    6273.2 \n  \n  \n    Log.Lik. \n    −3085.506 \n  \n  \n    F \n    45.533 \n  \n  \n    RMSE \n    0.45 \n  \n\n\n\n\n\n　また、複数のモデルをlist()関数でまとめると、モデル間比較もできる。\n\nmodelsummary(list(\"w/o Covariates\" = fit1, \"w/ Covariates\" = fit2))\n\n\n\n \n  \n      \n    w/o Covariates \n    w/ Covariates \n  \n \n\n  \n    (Intercept) \n    0.299 \n    6.089 \n  \n  \n     \n    (0.009) \n    (0.916) \n  \n  \n    treatmentCivic Duty \n    0.018 \n    0.031 \n  \n  \n     \n    (0.021) \n    (0.021) \n  \n  \n    treatmentSelf \n    0.066 \n    0.070 \n  \n  \n     \n    (0.022) \n    (0.021) \n  \n  \n    treatmentNeighbors \n    0.122 \n    0.115 \n  \n  \n     \n    (0.022) \n    (0.021) \n  \n  \n    treatmentHawthorne \n    0.041 \n    0.042 \n  \n  \n     \n    (0.021) \n    (0.021) \n  \n  \n    female \n     \n    −0.024 \n  \n  \n     \n     \n    (0.013) \n  \n  \n    yob \n     \n    −0.003 \n  \n  \n     \n     \n    (0.0005) \n  \n  \n    hh_size \n     \n    0.003 \n  \n  \n     \n     \n    (0.009) \n  \n  \n    voted2000 \n     \n    0.067 \n  \n  \n     \n     \n    (0.015) \n  \n  \n    voted2002 \n     \n    0.164 \n  \n  \n     \n     \n    (0.013) \n  \n  \n    voted2004 \n     \n    0.158 \n  \n  \n     \n     \n    (0.013) \n  \n  \n    Num.Obs. \n    5000 \n    5000 \n  \n  \n    R2 \n    0.007 \n    0.084 \n  \n  \n    R2 Adj. \n    0.006 \n    0.082 \n  \n  \n    AIC \n    6584.0 \n    6195.0 \n  \n  \n    BIC \n    6623.1 \n    6273.2 \n  \n  \n    Log.Lik. \n    −3285.982 \n    −3085.506 \n  \n  \n    F \n    8.959 \n    45.533 \n  \n  \n    RMSE \n    0.47 \n    0.45 \n  \n\n\n\n\n\n　modelsummary()は推定値と標準誤差（カッコ内）が別々の行として出力する。これを一行でまとめるためには、以下のようにコードを修正する。\n\nmodelsummary(list(\"w/o Covariates\" = fit1, \"w/ Covariates\" = fit2),\n             estimate  = \"{estimate} ({std.error})\",\n             statistic = NULL)\n\n\n\n \n  \n      \n    w/o Covariates \n    w/ Covariates \n  \n \n\n  \n    (Intercept) \n    0.299 (0.009) \n    6.089 (0.916) \n  \n  \n    treatmentCivic Duty \n    0.018 (0.021) \n    0.031 (0.021) \n  \n  \n    treatmentSelf \n    0.066 (0.022) \n    0.070 (0.021) \n  \n  \n    treatmentNeighbors \n    0.122 (0.022) \n    0.115 (0.021) \n  \n  \n    treatmentHawthorne \n    0.041 (0.021) \n    0.042 (0.021) \n  \n  \n    female \n     \n    −0.024 (0.013) \n  \n  \n    yob \n     \n    −0.003 (0.0005) \n  \n  \n    hh_size \n     \n    0.003 (0.009) \n  \n  \n    voted2000 \n     \n    0.067 (0.015) \n  \n  \n    voted2002 \n     \n    0.164 (0.013) \n  \n  \n    voted2004 \n     \n    0.158 (0.013) \n  \n  \n    Num.Obs. \n    5000 \n    5000 \n  \n  \n    R2 \n    0.007 \n    0.084 \n  \n  \n    R2 Adj. \n    0.006 \n    0.082 \n  \n  \n    AIC \n    6584.0 \n    6195.0 \n  \n  \n    BIC \n    6623.1 \n    6273.2 \n  \n  \n    Log.Lik. \n    −3285.982 \n    −3085.506 \n  \n  \n    F \n    8.959 \n    45.533 \n  \n  \n    RMSE \n    0.47 \n    0.45 \n  \n\n\n\n\n\n　また、alignで各列を左寄せや右寄せに（文字列は左寄せ、数値は右寄せが一般的）、coef_rename引数で表示される変数名を変更することもできる。\n\nmodelsummary(list(\"w/o Covariates\" = fit1, \"w/ Covariates\" = fit2),\n             estimate  = \"{estimate} ({std.error})\",\n             statistic = NULL,\n             align = \"lrr\", # 1列は左寄せ、2列は右寄せ、3列は右寄せ\n             coef_rename = c(\"treatmentCivic Duty\" = \"Civic Duty\",\n                             \"treatmentSelf\"       = \"Self\",\n                             \"treatmentNeighbors\"  = \"Neighbors\",\n                             \"treatmentHawthorne\"  = \"Hawthorne\",\n                             \"female\"              = \"Female\",\n                             \"yob\"                 = \"Year of Birth\",\n                             \"hh_size\"             = \"Household Size\",\n                             \"voted2000\"           = \"Voted (2000)\",\n                             \"voted2002\"           = \"Voted (2002)\",\n                             \"voted2004\"           = \"Voted (2004)\"))\n\n\n\n \n  \n      \n    w/o Covariates \n    w/ Covariates \n  \n \n\n  \n    (Intercept) \n    0.299 (0.009) \n    6.089 (0.916) \n  \n  \n    Civic Duty \n    0.018 (0.021) \n    0.031 (0.021) \n  \n  \n    Self \n    0.066 (0.022) \n    0.070 (0.021) \n  \n  \n    Neighbors \n    0.122 (0.022) \n    0.115 (0.021) \n  \n  \n    Hawthorne \n    0.041 (0.021) \n    0.042 (0.021) \n  \n  \n    Female \n     \n    −0.024 (0.013) \n  \n  \n    Year of Birth \n     \n    −0.003 (0.0005) \n  \n  \n    Household Size \n     \n    0.003 (0.009) \n  \n  \n    Voted (2000) \n     \n    0.067 (0.015) \n  \n  \n    Voted (2002) \n     \n    0.164 (0.013) \n  \n  \n    Voted (2004) \n     \n    0.158 (0.013) \n  \n  \n    Num.Obs. \n    5000 \n    5000 \n  \n  \n    R2 \n    0.007 \n    0.084 \n  \n  \n    R2 Adj. \n    0.006 \n    0.082 \n  \n  \n    AIC \n    6584.0 \n    6195.0 \n  \n  \n    BIC \n    6623.1 \n    6273.2 \n  \n  \n    Log.Lik. \n    −3285.982 \n    −3085.506 \n  \n  \n    F \n    8.959 \n    45.533 \n  \n  \n    RMSE \n    0.47 \n    0.45 \n  \n\n\n\n\n\n　処置効果に注目すると、共変量の有無が推定結果に影響をほぼ与えないことが分かる。これは無作為割当に成功したことを意味する。"
  },
  {
    "objectID": "material/r.html#番外編",
    "href": "material/r.html#番外編",
    "title": "Rの復習",
    "section": "番外編",
    "text": "番外編\n　modelsummary()を使えば、複数のモデルの推定結果を一つの表としてまとめられる。しかし、図の場合はどうだろう。共変量なしモデルとありモデルを 図 12 のように一つにまとめることはできるだろうか。もちろん出来る。\n　まず、重回帰分析を行った結果（fit2）から処置効果の推定値情報を抽出し、fit1_coefと同じ構造のデータとしてまとめる。\n\nfit2_coef <- tidy(fit2, conf.int = TRUE, conf.level = 0.9875)\n\nfit2_coef <- fit2_coef |>\n  slice(2:5) |>\n  mutate(term = recode(term,\n                       \"treatmentCivic Duty\" = \"Civic Duty\",\n                       \"treatmentHawthorne\"  = \"Hawthorne\",\n                       \"treatmentNeighbors\"  = \"Neighbors\",\n                       \"treatmentSelf\"       = \"Self\"),\n         term = fct_inorder(term))\n\nfit2_coef\n\n# A tibble: 4 × 7\n  term       estimate std.error statistic      p.value conf.low conf.high\n  <fct>         <dbl>     <dbl>     <dbl>        <dbl>    <dbl>     <dbl>\n1 Civic Duty   0.0307    0.0205      1.49 0.135        -0.0206     0.0821\n2 Self         0.0703    0.0212      3.32 0.000892      0.0175     0.123 \n3 Neighbors    0.115     0.0212      5.41 0.0000000665  0.0617     0.168 \n4 Hawthorne    0.0423    0.0206      2.05 0.0402       -0.00920    0.0939\n\n\n　処置効果の推定値や標準誤差などが異なるが、構造としては同じである。続いて、bind_rows()を用い、この2つのデータを一つの表として結合する。2つの表はlist()関数でまとめるが、それぞれ\"モデル名\" = データ名と指定する。最後に、.id = \"Model\"を追加する。\n\nbind_rows(list(\"Model 1\" = fit1_coef, \n               \"Model 2\" = fit2_coef),\n          .id = \"Model\")\n\n# A tibble: 8 × 8\n  Model   term       estimate std.error statistic      p.value conf.low conf.h…¹\n  <chr>   <fct>         <dbl>     <dbl>     <dbl>        <dbl>    <dbl>    <dbl>\n1 Model 1 Civic Duty   0.0181    0.0214     0.847 0.397        -0.0353    0.0714\n2 Model 1 Self         0.0658    0.0220     2.99  0.00280       0.0108    0.121 \n3 Model 1 Neighbors    0.122     0.0221     5.53  0.0000000330  0.0669    0.177 \n4 Model 1 Hawthorne    0.0406    0.0214     1.89  0.0582       -0.0130    0.0942\n5 Model 2 Civic Duty   0.0307    0.0205     1.49  0.135        -0.0206    0.0821\n6 Model 2 Self         0.0703    0.0212     3.32  0.000892      0.0175    0.123 \n7 Model 2 Neighbors    0.115     0.0212     5.41  0.0000000665  0.0617    0.168 \n8 Model 2 Hawthorne    0.0423    0.0206     2.05  0.0402       -0.00920   0.0939\n# … with abbreviated variable name ¹​conf.high\n\n\n　2つの表が1つとなり、Modelという列が追加される（これは.idで指定した名前）。そして、fit1_coefだった行は\"Model 1\"、fit2_coefだった行は\"Model 2\"が付く。ただし、これだけだと表が結合されて出力されるだけなので、fit_coefという名のオブジェクトとして作業環境内に格納しておく。\n\nfit_coef <- bind_rows(list(\"Model 1\" = fit1_coef, \n                           \"Model 2\" = fit2_coef),\n                      .id = \"Model\")\n\n　それではfit_coefを使って、作図をしてみよう。コードは 図 12 と同じであるが、facet_wrap()レイヤーを追加する。これはグラフのファセット（facet）分割を意味し、ファセットとは「面」を意味する。()内には~分割の基準となる変数名を入れる。2つのモデルがあり、fit_coefだとModel列がどのモデルの推定値かを示している。\n\nfit_coef |>\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  facet_wrap(~ Model) +\n  theme_bw(base_size = 12)\n\n\n\n\n図 13: ?(caption)\n\n\n\n\n　今回の結果だとモデル1もモデル2も推定値がほぼ同じである。ファセット分割の場合、小さい差の比較が難しいというデメリットがある。この場合、ファセット分割をせず、一つのファセットにpoint-rangeの色分けした方が読みやすくなる。point-rangeをModelの値に応じて色分けする場合、aes()内にcolor = Modelを追加する。\n\nfit_coef |>\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high,\n                      color = Model)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n図 14: ?(caption)\n\n\n\n\n　何かおかしい。point-rangeの横軸上の位置が同じということから重なってしまい、モデル1のpoint-rangeがよく見えない。これをずらすためにaes()の外側にposition = position_dodge2(1/2)を追加する。\n\nfit_coef |>\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high,\n                      color = Model),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n図 15: ?(caption)\n\n\n\n\n　これで図は完成だが、少し修正してみよう。{ggplot2}の場合、凡例は右側に表示されるが、これを下側へ移動させるためにはtheme()レイヤーを追加し、legend.position = \"bottom\"を指定する。また、モデル1とモデル2が具体的に何を意味するのかを明確に示したい。これはfit_coefのModel列を修正しても良いが、今回はscale_color_discrete()レイヤーで修正する例を紹介する。\n\nfit_coef |>\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high,\n                      color = Model),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  scale_color_discrete(labels = c(\"Model 1\" = \"w/o Covariates\",\n                                  \"Model 2\" = \"w/ Covariates\")) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n図 16: ?(caption)"
  },
  {
    "objectID": "material/rct.html",
    "href": "material/rct.html",
    "title": "無作為化比較試験",
    "section": "",
    "text": "新しいタブで開く"
  },
  {
    "objectID": "material/foundation.html",
    "href": "material/foundation.html",
    "title": "因果推論の考え方",
    "section": "",
    "text": "新しいタブで開く"
  },
  {
    "objectID": "material/matching.html",
    "href": "material/matching.html",
    "title": "回帰分析とマッチング",
    "section": "",
    "text": "新しいタブで開く"
  },
  {
    "objectID": "material/matching.html#セットアップ",
    "href": "material/matching.html#セットアップ",
    "title": "回帰分析とマッチング",
    "section": "セットアップ",
    "text": "セットアップ\n　本日の実習で使用するパッケージを読み込む。\n\npacman::p_load(tidyverse, \n               broom,\n               MatchIt, \n               WeightIt, \n               cobalt, \n               summarytools,\n               modelsummary,\n               fastDummies)\npacman::p_load_gh(\"JaehyunSong/BalanceR\")\n\n　マッチングにおける古典的なデータセット、lalondeを読み込む。data(lalonde, package = \"cobalt\")を入力するだけで、{cobalt}パッケージ内のlaondeという名前のデータフレームが作業環境内にlalondeという名で格納される1。このデータをla_dfという名のオブジェクトとして改めて保存しておこう。ただし、lalondeデータセットの形式はdata.frameである。このままでも全く問題ないが、data.frameの拡張版であるtibble形式の方がより読みやすいので、格納する前にlalondeのデータ構造をdata.frameからtibbleへ変更しておこう（as_tibble()関数を使う）。\n\n# cobaltパッケージが提供するデータセットの読み込み\ndata(\"lalonde\", package = \"cobalt\")\n\nla_df <- as_tibble(lalonde)\n\n　それでは、データの中身を確認してみよう。\n\nla_df\n\n# A tibble: 614 × 9\n   treat   age  educ race   married nodegree  re74  re75   re78\n   <int> <int> <int> <fct>    <int>    <int> <dbl> <dbl>  <dbl>\n 1     1    37    11 black        1        1     0     0  9930.\n 2     1    22     9 hispan       0        1     0     0  3596.\n 3     1    30    12 black        0        0     0     0 24909.\n 4     1    27    11 black        0        1     0     0  7506.\n 5     1    33     8 black        0        1     0     0   290.\n 6     1    22     9 black        0        1     0     0  4056.\n 7     1    23    12 black        0        0     0     0     0 \n 8     1    32    11 black        0        1     0     0  8472.\n 9     1    22    16 black        0        0     0     0  2164.\n10     1    33    12 white        1        0     0     0 12418.\n# … with 604 more rows\n\n\n　分析に入る前に、名目変数である人種（race）をダミー変数に変換する。raceは3種類の値で構成されているため、生成するダミー変数も3つとなる。ダミー化には{fastDummies}パッケージのdummy_cols()関数を使用する。\n\nla_df <- la_df |>\n  dummy_cols(select_columns = \"race\")\n\nla_df\n\n# A tibble: 614 × 12\n   treat   age  educ race   married nodegree  re74  re75   re78 race_b…¹ race_…²\n   <int> <int> <int> <fct>    <int>    <int> <dbl> <dbl>  <dbl>    <int>   <int>\n 1     1    37    11 black        1        1     0     0  9930.        1       0\n 2     1    22     9 hispan       0        1     0     0  3596.        0       1\n 3     1    30    12 black        0        0     0     0 24909.        1       0\n 4     1    27    11 black        0        1     0     0  7506.        1       0\n 5     1    33     8 black        0        1     0     0   290.        1       0\n 6     1    22     9 black        0        1     0     0  4056.        1       0\n 7     1    23    12 black        0        0     0     0     0         1       0\n 8     1    32    11 black        0        1     0     0  8472.        1       0\n 9     1    22    16 black        0        0     0     0  2164.        1       0\n10     1    33    12 white        1        0     0     0 12418.        0       0\n# … with 604 more rows, 1 more variable: race_white <int>, and abbreviated\n#   variable names ¹​race_black, ²​race_hispan\n\n\n　このまま記述統計を見たり、分析に入っても良いが、もう少しデータを加工してみよう。まずrace_で始まる3つのダミー変数の位置をraceの前へ変更する。また、race変数は不要なので、race変数を除外する。最後に、race_で始まるダミー変数の名前を変更してみよう。変数の位置変更はrelocate()関数を使用する。\n\nla_df <- la_df |>\n  relocate(starts_with(\"race_\"), .before = race) |>\n  select(-race) |>\n  rename(\"black\"    = \"race_black\",\n         \"hispanic\" = \"race_hispan\",\n         \"white\"    = \"race_white\")\n\nla_df\n\n# A tibble: 614 × 11\n   treat   age  educ black hispanic white married nodegree  re74  re75   re78\n   <int> <int> <int> <int>    <int> <int>   <int>    <int> <dbl> <dbl>  <dbl>\n 1     1    37    11     1        0     0       1        1     0     0  9930.\n 2     1    22     9     0        1     0       0        1     0     0  3596.\n 3     1    30    12     1        0     0       0        0     0     0 24909.\n 4     1    27    11     1        0     0       0        1     0     0  7506.\n 5     1    33     8     1        0     0       0        1     0     0   290.\n 6     1    22     9     1        0     0       0        1     0     0  4056.\n 7     1    23    12     1        0     0       0        0     0     0     0 \n 8     1    32    11     1        0     0       0        1     0     0  8472.\n 9     1    22    16     1        0     0       0        0     0     0  2164.\n10     1    33    12     0        0     1       1        0     0     0 12418.\n# … with 604 more rows\n\n\n　それでは記述統計量を確認してみよう。\n\ndescr(la_df,\n      stats = c(\"mean\", \"sd\", \"min\", \"max\"),\n      transpose = TRUE,\n      order = \"p\")\n\n\n\n\n\n \nMean\nStd.Dev\nMin\nMax\n\n\n\n\ntreat\n0.30\n0.46\n0.00\n1.00\n\n\nage\n27.36\n9.88\n16.00\n55.00\n\n\neduc\n10.27\n2.63\n0.00\n18.00\n\n\nblack\n0.40\n0.49\n0.00\n1.00\n\n\nhispanic\n0.12\n0.32\n0.00\n1.00\n\n\nwhite\n0.49\n0.50\n0.00\n1.00\n\n\nmarried\n0.42\n0.49\n0.00\n1.00\n\n\nnodegree\n0.63\n0.48\n0.00\n1.00\n\n\nre74\n4557.55\n6477.96\n0.00\n35040.07\n\n\nre75\n2184.94\n3295.68\n0.00\n25142.24\n\n\nre78\n6792.83\n7470.73\n0.00\n60307.93"
  },
  {
    "objectID": "material/matching.html#回帰分析",
    "href": "material/matching.html#回帰分析",
    "title": "回帰分析とマッチング",
    "section": "回帰分析",
    "text": "回帰分析\n\nDiM推定量\n　処置効果を確認するために、まずはグループごとの応答変数の差分（Difference-in-Means; DiM）を計算してみよう。処置変数はtreatであり、職業訓練を受けた回答者は1、受けなかった回答者は0となる。応答変数re78は1978年における回答者の収入である。\n\nDiff_Mean_df <- la_df |> \n    group_by(treat) |>\n    summarise(Outcome = mean(re78),\n              .groups = \"drop\")\n\nDiff_Mean_df\n\n# A tibble: 2 × 2\n  treat Outcome\n  <int>   <dbl>\n1     0   6984.\n2     1   6349.\n\n\n　この結果を可視化する必要はあまり無いかも知れないが、以下のようなコードで可視化することもできる。\n\nDiff_Mean_df |>\n  ggplot() +\n  geom_bar(aes(x = treat, y = Outcome), \n           stat = \"identity\", width = 0.5) +\n  geom_label(aes(x = treat, y = Outcome,\n                 label = round(Outcome, 3))) +\n  labs(x = \"Treatment\",\n       y = \"Outcome (US Dollars)\") +\n  # scale_x_continuous()を使って0/1をControl/Treatmentに置換する\n  # 目盛りはX軸上の0と1、各目盛りのラベルはControlとTreatmentに\n  scale_x_continuous(breaks = c(0, 1), labels = c(\"Control\", \"Treatment\")) +\n  coord_cartesian(xlim = c(-0.5, 1.5))\n\n\n\n\n\n\n\n\n　treat == 0の回答者、つまり職業訓練を受けていない回答者の平均所得は約6984ドル、treat == 1の回答者、つまり職業訓練を受けた回答者の平均所得は約6394ドルだ。その差は約-650ドルだが、職業訓練を受けた回答者の方が低所得になっている。これは直感的に納得できる結果ではないだろう。むろん、実際、職業訓練が所得を減らす可能性もあるが、今回の結果はより詳しく分析してみる価値があろう。\n　ちなみに、以上の結果は単回帰分析からも確認できる (ただし、統計的に有意ではない)。\n\nDiM_fit <- lm(re78 ~ treat, data = la_df)\nmodelsummary(DiM_fit,\n             # 係数の点推定値と95%信頼区間を示す場合\n             estimate   = \"{estimate} [{conf.low}, {conf.high}]\",\n             statistic  = NULL,\n             conf_level = 0.95,\n             # ケース数、決定係数、調整済み決定係数を出力\n             gof_map    = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n \n  \n      \n    Model 1 \n  \n \n\n  \n    (Intercept) \n    6984.170 [6275.791, 7692.549] \n  \n  \n    treat \n    −635.026 [−1925.544, 655.492] \n  \n  \n    Num.Obs. \n    614 \n  \n  \n    R2 \n    0.002 \n  \n  \n    R2 Adj. \n    −0.0001 \n  \n\n\n\n\n\n　この直感的でない結果は、もしかしたらセレクションバイアスが原因かも知れない。職業訓練の対象が元々非常に所得が低い回答者になっている可能性がある。たとえば、下の図のように職業訓練の有無が教育水準や人種、これまでの所得などと関係しているとしよう。これらの要因は回答者の現在所得にも関係していると考えられる。この場合、処置有無と所得の間には内生性が存在することになる。\n\n\n作図用のコード\npacman::p_load(ggdag)\ndagify(Income ~ Race + Training + Educ,\n       Training ~ Race + Educ,\n       exposure = \"Training\",\n       outcome  = \"Income\",\n       coords   = list(\n         x = c(Race = 1.5, Educ = 2.5, Training = 1, Income = 3),\n         y = c(Race = 2,   Educ = 2,   Training = 1, Income = 1)\n       )\n       ) |>\n  tidy_dagitty() |>\n  ggdag(confounder_triangle(), node_size = 20) +\n  coord_cartesian(xlim = c(0.8, 3.2), ylim = c(0.8, 2.2)) +\n  theme_dag_blank()\n\n\n\n\n\n\n\n\n\n　本当にそうなのかを、共変量のバランスチェックをしてみよう。もし、処置有無によって回答者の社会経済的要因に大きな差があれば、内生性が存在する証拠になろう。ここでは誰かが作成しました{BalanceR}パッケージを使ってみよう。\n\nblc_chk <- la_df |>\n  BalanceR(group = treat, cov = age:re75)\n\n　{BalanceR}パッケージで共変量を指定する際、:演算子が使える。age:re75は、データセットのageからre75変数までをすべて指定することを意味する。names(la_df)で変数がどの順番で並んでいるかが分かる。\n\nnames(la_df)\n\n [1] \"treat\"    \"age\"      \"educ\"     \"black\"    \"hispanic\" \"white\"   \n [7] \"married\"  \"nodegree\" \"re74\"     \"re75\"     \"re78\"    \n\n\n　それではバランスチェックの結果を確認してみよう。\n\nblc_chk\n\n  Covariate   Mean:0     SD:0   Mean:1     SD:1   SB:0-1\n1       age   28.030   10.787   25.816    7.155   24.190\n2      educ   10.235    2.855   10.346    2.011   -4.476\n3     black    0.203    0.403    0.843    0.365 -167.083\n4  hispanic    0.142    0.350    0.059    0.237   27.740\n5     white    0.655    0.476    0.097    0.297  140.799\n6   married    0.513    0.500    0.189    0.393   72.076\n7  nodegree    0.597    0.491    0.708    0.456  -23.549\n8      re74 5619.237 6788.751 2095.574 4886.620   59.575\n9      re75 2466.484 3291.996 1532.055 3219.251   28.700\n\n\n　アンバランスと判定する標準化差分（標準化バイアス）の閾値には決まった値が無いが、最も緩い基準でも25程度である（計算時に100を掛けないのであれば0.25）。しかし、いくつか怪しい箇所がある。たとえば、treat == 0の回答者において黒人の割合は約20%だが、treat == 1のそれは約85%だ。つまり、黒人ほどより職業訓練を受ける傾向があることを意味する。また、人種は所得にも影響を与えると考えられる。これは処置と応答変数の間に交絡要因があることを意味する。実際、標準化バイアスは-167という、非常に大きい数値を示している。この結果を図としてまとめてみましょう。\n\n# 絶対値変換。SB = 25に破線\nplot(blc_chk, abs = TRUE, vline = 25) +\n  # 縦軸目盛りラベルの修正\n  scale_y_discrete(labels = c(\"age\"      = \"Age\",\n                              \"educ\"     = \"Education\",\n                              \"black\"    = \"Race (Black)\",\n                              \"hispanic\" = \"Race (Hispanic)\",\n                              \"white\"    = \"Race (White)\",\n                              \"married\"  = \"Married\",\n                              \"nodegree\" = \"No Degree\",\n                              \"re74\"     = \"Revenue (1974)\",\n                              \"re75\"     = \"Revenue (1975)\")) +\n  # 凡例の削除\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n　かなり緩めの基準である25を採用しても、人種、結婚有無、74・75年の所得のバランスが非常に悪く、内生性（=自己選択バイアス）があると判断して良いだろう。以下ではこの内生性に対処する様々な方法を紹介する。\n\n\n重回帰分析\n　まずは、重回帰分析からだ。用いる共変量は年齢、教育水準、黒人ダミー、ヒスパニックダミー2、既婚ダミー、学位なしダミー、74・75年の所得だ。lm()関数で78年の所得をこちらの変数に回帰させてみよう。\n\\[\n\\begin{align}\n\\widehat{\\mbox{re78}} = & \\beta_0 + \\beta_1 \\mbox{treat} + \\beta_2 \\mbox{age} + \\beta_3 \\mbox{educ} + \\\\\n& \\beta_4 \\mbox{black} + \\beta_5 \\mbox{hispanic} + \\beta_6 \\mbox{married} + \\beta_7 \\mbox{nodegree} + \\beta_8 \\mbox{re74} + \\beta_9 \\mbox{re75}.\n\\end{align}\n\\]\n\nmlm_fit <- lm(re78 ~ treat + age + educ + black + hispanic + married + \n                   nodegree + re74 + re75, data = la_df)\n\nmodelsummary(list(\"単回帰分析\" = DiM_fit, \"重回帰分析\" = mlm_fit), \n             estimate  = \"{estimate} ({std.error})\",\n             statistic = NULL,\n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n \n  \n      \n    単回帰分析 \n    重回帰分析 \n  \n \n\n  \n    (Intercept) \n    6984.170 (360.710) \n    66.515 (2436.746) \n  \n  \n    treat \n    −635.026 (657.137) \n    1548.244 (781.279) \n  \n  \n    age \n     \n    12.978 (32.489) \n  \n  \n    educ \n     \n    403.941 (158.906) \n  \n  \n    black \n     \n    −1240.644 (768.764) \n  \n  \n    hispanic \n     \n    498.897 (941.943) \n  \n  \n    married \n     \n    406.621 (695.472) \n  \n  \n    nodegree \n     \n    259.817 (847.442) \n  \n  \n    re74 \n     \n    0.296 (0.058) \n  \n  \n    re75 \n     \n    0.232 (0.105) \n  \n  \n    Num.Obs. \n    614 \n    614 \n  \n  \n    R2 \n    0.002 \n    0.148 \n  \n  \n    R2 Adj. \n    −0.0001 \n    0.135 \n  \n\n\n\n\n\n　共変量を統制したら処置変数の係数は約1548.244ドルだ。単回帰分析の結果とは違って、統計的に有意な正の効果が確認されている。ますます分からなくなってしまう。"
  },
  {
    "objectID": "material/matching.html#マッチング",
    "href": "material/matching.html#マッチング",
    "title": "回帰分析とマッチング",
    "section": "マッチング",
    "text": "マッチング\n\n最近傍マッチング\n　重回帰分析は非常にシンプルで便利な分析方法ですが、いくつかの欠点がある。まず、重回帰分析は変数間の関係（線形結合）および誤差項の分布（平均0の正規分布）などを仮定したパラメトリック分析ということだ。この場合、同じ共変量を持たないケースであっても、勝手に予測を行うこととなる。重回帰分析における処置変数の解釈は「他の共変量がすべて同じ」場合の処置効果である。これは、共変量がすべて同じ場合における（最初に見た）単純差分のようなものである。しかし、「他の共変量がすべて同じ」ケースが存在しない可能性があろう。特に、共変量が多く、連続変数の場合、共変量がすべて同じことは実質あり得ないか、非常に少ないケースに限定されることもある。一方、マッチングを行うと、「他の共変量がすべて同じ」、または「非常に似ている」ケース間で比較を行うことになる。\n　本資料では以下の3つのマッチング手法の実装方法について解説する。\n\n最近傍マッチング（マハラノビス距離）\n最近傍マッチング（傾向スコア）\nCoarsened Exact Matching (CEM)\n\n　まずは、マハラノビス距離を用いた最近傍マッチングから始めよう。だいたいのマッチング手法は{MatchIt}パッケージで解決できる。マッチングデータセットを作成する関数はmatchit()関数であり、使い方は以下の通りである。\n\nmatchit(処置変数 ~ 共変量1 + ... + 共変量k, \n            data = データフレーム名, estimand = \"ATT\",\n            method = \"nearest\", distance = \"mahalanobis\")\n\n　method = \"nearest\"は最近傍マッチングを、distance = \"mahalanobis\"はマハラノビス距離を意味する。estimand = \"ATT\"はATTを推定することを意味する。{MatchIt}の最近傍マッチングの場合、\"ATT\"、または\"ATC\"のみ指定可能である（後で紹介するCEMでは\"ATE\"も指定可能）。早速やってみよう。\n\nmh_mat1 <- matchit(treat ~ age + educ + black + hispanic + married + \n                     nodegree + re74 + re75, \n                   data = la_df, estimand = \"ATT\",\n                   method = \"nearest\", distance = \"mahalanobis\")\n\n　マッチング後のデータでバランスが取れているかを確認するためにはいくつかの方法があるが、ここでは{cobalt}パッケージを使って、標準化差分を確認してみよう。\n\nlove.plot(mh_mat1, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　thresholds引数は垂直線（破線）の位置、absは標準化差分を絶対値で示すことを意味する。マッチング後の標準化差分（Adjusted; 赤い点）が0.25より左側に位置している場合、バランスしていると判断できる3。むろん、より厳格な基準として0.03、0.05、0.1を使うこともできる。他にもマッチング後の標準化差分がマッチング前（Unadjusted; 青い点）より改善されるいるか否かも判断できる。今回の例だと、大幅にバランスが改善されている。0.25を基準とした場合、blackはまだバランスが取れていないが、それでも大幅に改善されていることが分かる。\n　それではATTを推定してみよう。推定方法としてはノンパラメトリックな方法とパラメトリック方法があるが、結果は変わらない。ノンパラメトリックな方法はペアごとの差分を計算し、その平均値を求める方法だが、マッチング済みのデータに対し、処置変数を結果変数を回帰させることも、結果的には同じことを行うことになる。したがって、もっと簡単なパラメトリック方法、つまり単回帰分析でATTを推定しよう。\n　回帰分析を行うためにはデータが必要だ。つまり、マッチングされないケースをデータから除去する必要がある。ここではmatch.data()関数を使ったマッチングされたケースのみを抽出してみよう。抽出したデータはmh_data1と名付ける。\n\nmh_data1 <- match.data(mh_mat1)\n\nマッチングデータが取れたら、その中身を確認してみましょう。\n\nmh_data1\n\n# A tibble: 370 × 13\n   treat   age  educ black hispanic white married nodegree  re74  re75   re78\n   <int> <int> <int> <int>    <int> <int>   <int>    <int> <dbl> <dbl>  <dbl>\n 1     1    37    11     1        0     0       1        1     0     0  9930.\n 2     1    22     9     0        1     0       0        1     0     0  3596.\n 3     1    30    12     1        0     0       0        0     0     0 24909.\n 4     1    27    11     1        0     0       0        1     0     0  7506.\n 5     1    33     8     1        0     0       0        1     0     0   290.\n 6     1    22     9     1        0     0       0        1     0     0  4056.\n 7     1    23    12     1        0     0       0        0     0     0     0 \n 8     1    32    11     1        0     0       0        1     0     0  8472.\n 9     1    22    16     1        0     0       0        0     0     0  2164.\n10     1    33    12     0        0     1       1        0     0     0 12418.\n# … with 360 more rows, and 2 more variables: weights <dbl>, subclass <fct>\n\n\n　データのサイズは370行14列であり、この370行には意味がある。それは処置群の大きさの2倍という点だ。多くの場合、マッチングから計算される処置効果はATEではなく、ATTである。したがって、処置群のデータを100%活用し、共変量（のマハラノビス距離）が最も近いケースを統制群から抽出&マッチングすることになる。だから、マッチング後のサンプルサイズは処置群のサイズの2倍になる。\n　それでは職業訓練のATTを推定してみよう。方法は簡単だ。マッチング後のデータ（mh_data1）を用い、単回帰分析を行うだけである。\n\nmh_fit1 <- lm(re78 ~ treat, data = mh_data1)\n\nmodelsummary(mh_fit1)\n\n\n\n \n  \n      \n    Model 1 \n  \n \n\n  \n    (Intercept) \n    5832.507 \n  \n  \n     \n    (527.987) \n  \n  \n    treat \n    516.637 \n  \n  \n     \n    (746.686) \n  \n  \n    Num.Obs. \n    370 \n  \n  \n    R2 \n    0.001 \n  \n  \n    R2 Adj. \n    −0.001 \n  \n  \n    AIC \n    7624.7 \n  \n  \n    BIC \n    7636.4 \n  \n  \n    Log.Lik. \n    −3809.327 \n  \n  \n    F \n    0.479 \n  \n  \n    RMSE \n    7161.96 \n  \n\n\n\n\nmodelsummary(list(\"単回帰・非復元\" = mh_fit1), \n             estimate  = \"{estimate} ({std.error})\",\n             statistic = NULL,\n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n \n  \n      \n    単回帰・非復元 \n  \n \n\n  \n    (Intercept) \n    5832.507 (527.987) \n  \n  \n    treat \n    516.637 (746.686) \n  \n  \n    Num.Obs. \n    370 \n  \n  \n    R2 \n    0.001 \n  \n  \n    R2 Adj. \n    −0.001 \n  \n\n\n\n\n\n　処置効果は約516.637ドルである。今回の結果は重回帰分析よりも推定値が低めであり、統計的に有意に職業訓練の効果があったとは言えないという結果が得られましたね。また、マッチング後のデータを使って重回帰分析を行うこともできる。マッチング後のデータを見ると、黒人ダミーのバランスは大幅に改善されたが、それでもまだアンバランスしていると言える。他にも、74・75年の所得や年齢もそれなりに標準化差分が大きい。このような場合、もう一度共変量を投入して分析を行うこともできる。\n\nmh_fit2 <- lm(re78 ~ treat + age + educ + black + hispanic + married + \n                   nodegree + re74 + re75, data = mh_data1)\n\nmodelsummary(list(\"単回帰・非復元\" = mh_fit1,\n                  \"重回帰・非復元\" = mh_fit2), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n \n  \n      \n    単回帰・非復元 \n    重回帰・非復元 \n  \n \n\n  \n    (Intercept) \n    5832.507 \n    −453.365 \n  \n  \n     \n    (527.987) \n    (3546.028) \n  \n  \n    treat \n    516.637 \n    1239.696 \n  \n  \n     \n    (746.686) \n    (812.039) \n  \n  \n    age \n     \n    15.112 \n  \n  \n     \n     \n    (45.720) \n  \n  \n    educ \n     \n    533.042 \n  \n  \n     \n     \n    (243.621) \n  \n  \n    black \n     \n    −1158.148 \n  \n  \n     \n     \n    (906.948) \n  \n  \n    hispanic \n     \n    1120.562 \n  \n  \n     \n     \n    (1676.953) \n  \n  \n    married \n     \n    653.748 \n  \n  \n     \n     \n    (984.773) \n  \n  \n    nodegree \n     \n    −170.705 \n  \n  \n     \n     \n    (1116.240) \n  \n  \n    re74 \n     \n    0.071 \n  \n  \n     \n     \n    (0.098) \n  \n  \n    re75 \n     \n    0.272 \n  \n  \n     \n     \n    (0.155) \n  \n  \n    Num.Obs. \n    370 \n    370 \n  \n  \n    R2 \n    0.001 \n    0.076 \n  \n  \n    R2 Adj. \n    −0.001 \n    0.053 \n  \n\n\n\n\n\n　ちなみに、{MatchIt}パッケージを使った最近傍マッチングのの結果は行う度に変化することがある。{MatchIt}パッケージを使った最近傍マッチングの場合、処置群 (統制群)から一つのケースを選択し、最も近い統制群 (処置群)とマッチングする。マッチングされたケースは次のステップからはマッチング対象から除外されることになる4。また、1:1マッチングの場合5、同距離に複数のマッチング対象があると、ランダムに1つのみを選択する。最近傍マッチングを用いる際は、複数推定を行い、推定が安定するかを確認し、不安定な場合は他の手法を使うか、k-最近傍マッチングなどを使ってみよう。\n　ここでは復元マッチングの例を紹介しよう。やり方はmatchit()内にreplace = TRUEを追加するだけだ。\n\nmh_mat2 <- matchit(treat ~ age + educ + black + hispanic + married + \n                     nodegree + re74 + re75, \n                   data = la_df, estimand = \"ATT\", replace = TRUE,\n                   method = \"nearest\", distance = \"mahalanobis\")\nmh_data2 <- match.data(mh_mat2)\n\n　マッチング後のデータを確認する前に、バランスチェックをしてみよう。\n\nlove.plot(mh_mat2, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　復元マッチングのメリットは非復元マッチングに比べ、バランス改善の程度が大きいという点だ。非復元マッチングの場合、マッチングに使われた統制群は二度と使われないため、場合によっては近いマッチングケースがあるにも関わらず、マッチングできないからだ。ただし、復元マッチングにもデメリットはある。たとえば、有効サンプルサイズ（Effective Sample Size; ESS）が小さくなり、精度が悪くなる点、場合によっては特殊な標準誤差6を使う必要があるといった欠点もある。\n　それではマッチング後のデータを確認してみよう。\n\nmh_data2\n\n# A tibble: 260 × 12\n   treat   age  educ black hispanic white married nodegree  re74  re75   re78\n   <int> <int> <int> <int>    <int> <int>   <int>    <int> <dbl> <dbl>  <dbl>\n 1     1    37    11     1        0     0       1        1     0     0  9930.\n 2     1    22     9     0        1     0       0        1     0     0  3596.\n 3     1    30    12     1        0     0       0        0     0     0 24909.\n 4     1    27    11     1        0     0       0        1     0     0  7506.\n 5     1    33     8     1        0     0       0        1     0     0   290.\n 6     1    22     9     1        0     0       0        1     0     0  4056.\n 7     1    23    12     1        0     0       0        0     0     0     0 \n 8     1    32    11     1        0     0       0        1     0     0  8472.\n 9     1    22    16     1        0     0       0        0     0     0  2164.\n10     1    33    12     0        0     1       1        0     0     0 12418.\n# … with 250 more rows, and 1 more variable: weights <dbl>\n\n\n　今回は370行ではないことが分かる。なぜなら統制群のケースが複数マッチングされることもあるからだ。処置群は100%使われるので、マッチングに使われた統制群のケースは260-185=75ケースである。この特徴により推定の際は一点、注意が必要である。推定のやり方自体はほぼ同じである。しかし、非復元マッチングの場合、統制群からマッチングされたケースは1回のみ使われるため、一つ一つのケースの重みは同じである。match.data()から得られーたデータにはweights列が含まれており、mh_data1のweights列を見ると全ての重みが1だということが分かる。\n\nmh_data1$weights\n\n  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n181 182 183 184 185 186 190 191 192 193 195 200 202 203 205 208 209 212 226 228 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n231 233 244 254 257 271 273 274 275 276 278 279 280 281 282 283 284 285 288 290 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n295 296 297 303 306 312 319 322 323 325 327 335 339 342 343 344 352 353 356 358 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n362 363 364 365 367 368 369 370 372 374 376 378 381 384 387 390 393 394 398 399 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n402 403 405 409 411 413 414 415 416 419 420 422 423 427 430 432 436 438 441 443 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n445 446 450 451 453 454 455 457 458 459 462 463 465 466 467 470 474 475 476 478 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n485 493 499 500 501 507 508 510 511 512 515 516 518 520 522 524 525 526 527 530 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n536 537 538 539 540 541 542 544 546 551 552 553 555 556 557 558 559 560 561 562 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n563 565 566 567 571 572 573 574 576 577 578 580 581 582 583 584 585 586 591 592 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n593 594 596 597 601 604 607 608 610 613 \n  1   1   1   1   1   1   1   1   1   1 \n\n\n　一方、復元マッチングの場合、一つのケースが複数回マッチングされる場合もある。たとえば、191番目のケースは統制群であるが、重みが1.2162162だ。この意味は191番目のケースは計3回（\\(1.2162162\\times\\frac{185}{75}\\)）マッチングに使われたことを意味する。\n\nmh_data2$weights\n\n        1         2         3         4         5         6         7         8 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n        9        10        11        12        13        14        15        16 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       17        18        19        20        21        22        23        24 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       25        26        27        28        29        30        31        32 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       33        34        35        36        37        38        39        40 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       41        42        43        44        45        46        47        48 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       49        50        51        52        53        54        55        56 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       57        58        59        60        61        62        63        64 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       65        66        67        68        69        70        71        72 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       73        74        75        76        77        78        79        80 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       81        82        83        84        85        86        87        88 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       89        90        91        92        93        94        95        96 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       97        98        99       100       101       102       103       104 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      105       106       107       108       109       110       111       112 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      113       114       115       116       117       118       119       120 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      121       122       123       124       125       126       127       128 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      129       130       131       132       133       134       135       136 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      137       138       139       140       141       142       143       144 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      145       146       147       148       149       150       151       152 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      153       154       155       156       157       158       159       160 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      161       162       163       164       165       166       167       168 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      169       170       171       172       173       174       175       176 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      177       178       179       180       181       182       183       184 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      185       191       202       244       257       280       281       282 \n1.0000000 1.2162162 0.4054054 0.4054054 0.4054054 0.4054054 0.4054054 0.4054054 \n      284       295       297       303       312       319       325       335 \n1.6216216 0.8108108 0.4054054 3.6486486 0.4054054 1.6216216 2.4324324 0.4054054 \n      343       344       353       362       364       384       387       403 \n0.4054054 0.8108108 0.4054054 0.4054054 0.8108108 0.4054054 0.4054054 0.8108108 \n      405       409       411       413       420       422       423       432 \n0.4054054 0.4054054 2.0270270 0.8108108 0.4054054 0.4054054 0.4054054 0.4054054 \n      438       450       451       454       463       475       476       493 \n1.6216216 0.4054054 0.8108108 1.2162162 0.4054054 0.4054054 0.4054054 1.2162162 \n      507       511       512       515       516       518       520       524 \n0.4054054 0.4054054 0.4054054 0.4054054 0.8108108 0.8108108 0.8108108 0.4054054 \n      526       530       537       538       539       540       546       551 \n0.4054054 0.4054054 3.2432432 0.8108108 0.4054054 0.8108108 0.4054054 0.4054054 \n      552       553       557       558       559       561       565       566 \n1.6216216 5.2702703 0.8108108 2.8378378 1.2162162 1.6216216 0.4054054 0.4054054 \n      573       576       577       578       584       585       592       597 \n2.4324324 0.4054054 1.6216216 0.4054054 1.2162162 1.2162162 0.8108108 0.8108108 \n      601       604       608       613 \n1.2162162 0.4054054 7.2972973 0.4054054 \n\n\n　したがって、復元マッチングの場合、lm()内にweights引数を必ず指定する必要がある。\n\nmh_fit3 <- lm(re78 ~ treat, \n              data = mh_data2, weights = weights)\nmh_fit4 <- lm(re78 ~ treat + age + educ + black + hispanic + married + \n                   nodegree + re74 + re75, \n              data = mh_data2, weights = weights)\n\nmodelsummary(list(\"単回帰・非復元\" = mh_fit1,\n                  \"重回帰・非復元\" = mh_fit2,\n                  \"単回帰・復元\"   = mh_fit3,\n                  \"重回帰・復元\"   = mh_fit4), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n \n  \n      \n    単回帰・非復元 \n    重回帰・非復元 \n    単回帰・復元 \n    重回帰・復元 \n  \n \n\n  \n    (Intercept) \n    5832.507 \n    −453.365 \n    5744.482 \n    1371.865 \n  \n  \n     \n    (527.987) \n    (3546.028) \n    (854.641) \n    (4808.980) \n  \n  \n    treat \n    516.637 \n    1239.696 \n    604.661 \n    524.037 \n  \n  \n     \n    (746.686) \n    (812.039) \n    (1013.175) \n    (1011.417) \n  \n  \n    age \n     \n    15.112 \n     \n    8.365 \n  \n  \n     \n     \n    (45.720) \n     \n    (64.228) \n  \n  \n    educ \n     \n    533.042 \n     \n    476.666 \n  \n  \n     \n     \n    (243.621) \n     \n    (319.397) \n  \n  \n    black \n     \n    −1158.148 \n     \n    −1562.414 \n  \n  \n     \n     \n    (906.948) \n     \n    (1568.526) \n  \n  \n    hispanic \n     \n    1120.562 \n     \n    −17.586 \n  \n  \n     \n     \n    (1676.953) \n     \n    (2423.801) \n  \n  \n    married \n     \n    653.748 \n     \n    330.704 \n  \n  \n     \n     \n    (984.773) \n     \n    (1285.183) \n  \n  \n    nodegree \n     \n    −170.705 \n     \n    106.692 \n  \n  \n     \n     \n    (1116.240) \n     \n    (1421.140) \n  \n  \n    re74 \n     \n    0.071 \n     \n    0.091 \n  \n  \n     \n     \n    (0.098) \n     \n    (0.134) \n  \n  \n    re75 \n     \n    0.272 \n     \n    0.193 \n  \n  \n     \n     \n    (0.155) \n     \n    (0.208) \n  \n  \n    Num.Obs. \n    370 \n    370 \n    260 \n    260 \n  \n  \n    R2 \n    0.001 \n    0.076 \n    0.001 \n    0.041 \n  \n  \n    R2 Adj. \n    −0.001 \n    0.053 \n    −0.002 \n    0.007 \n  \n\n\n\n\n\n　推定の結果は、いずれも正であり、職業訓練は所得に正の影響を与えるという結果が得られている。しかし、いずれも標準誤差が非常に大きく、統計的に有意な結果は得られていない。\n\n\n傾向スコア\n　傾向スコアマッチングも、これまでのコードとほぼ同じだ。マハラノビス最近傍マッチングのコマンドからdistance = ...引数を抜けば、傾向スコアマッチングができる7。ここでもreplace = TRUEを指定し、復元マッチングをやってみよう。\n\nps_mat <- matchit(treat ~ age + educ + black + hispanic + married + \n                    nodegree + re74 + re75, \n                  data = la_df, replace = TRUE,\n                  method = \"nearest\", estimand = \"ATT\")\n\n　続いて、バランスチェックをしよう。\n\nlove.plot(ps_mat, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　バランスが大幅に改善されていることが分かる。ちなみに最上段のdistanceは傾向スコアを意味する。\n　それでは、ATT推定のためにマッチング後のデータを抽出しよう。\n\n# 傾向スコアマッチング後のデータセットを抽出\nps_data <- match.data(ps_mat)\n\n　傾向スコアを用いたATTをの推定もこれまでと同様、回帰分析を使用する。ここでも共変量なしの単回帰とありの重回帰を行い、マハラノビス距離最近傍マッチング（復元）と結果を比べてみよう。。\n\n# 処置効果の推定\nps_fit1 <- lm(re78 ~ treat, \n             data = ps_data, weights = weights)\nps_fit2 <- lm(re78 ~ treat + age + educ + black + hispanic + \n                married + nodegree + re74 + re75, \n             data = ps_data, weights = weights)\n\nmodelsummary(list(\"MH (単回帰)\"   = mh_fit3,\n                  \"MH (重回帰)\"   = mh_fit4,\n                  \"PS (単回帰)\"   = ps_fit1,\n                  \"PS (重回帰)\"   = ps_fit2), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n \n  \n      \n    MH (単回帰) \n    MH (重回帰) \n    PS (単回帰) \n    PS (重回帰) \n  \n \n\n  \n    (Intercept) \n    5744.482 \n    1371.865 \n    4381.204 \n    −985.292 \n  \n  \n     \n    (854.641) \n    (4808.980) \n    (811.618) \n    (4370.562) \n  \n  \n    treat \n    604.661 \n    524.037 \n    1967.940 \n    1903.412 \n  \n  \n     \n    (1013.175) \n    (1011.417) \n    (971.379) \n    (975.164) \n  \n  \n    age \n     \n    8.365 \n     \n    42.898 \n  \n  \n     \n     \n    (64.228) \n     \n    (60.174) \n  \n  \n    educ \n     \n    476.666 \n     \n    444.829 \n  \n  \n     \n     \n    (319.397) \n     \n    (278.130) \n  \n  \n    black \n     \n    −1562.414 \n     \n    −893.748 \n  \n  \n     \n     \n    (1568.526) \n     \n    (1538.965) \n  \n  \n    hispanic \n     \n    −17.586 \n     \n    −184.643 \n  \n  \n     \n     \n    (2423.801) \n     \n    (2343.260) \n  \n  \n    married \n     \n    330.704 \n     \n    299.425 \n  \n  \n     \n     \n    (1285.183) \n     \n    (1292.304) \n  \n  \n    nodegree \n     \n    106.692 \n     \n    92.911 \n  \n  \n     \n     \n    (1421.140) \n     \n    (1379.407) \n  \n  \n    re74 \n     \n    0.091 \n     \n    0.056 \n  \n  \n     \n     \n    (0.134) \n     \n    (0.122) \n  \n  \n    re75 \n     \n    0.193 \n     \n    0.160 \n  \n  \n     \n     \n    (0.208) \n     \n    (0.200) \n  \n  \n    Num.Obs. \n    260 \n    260 \n    265 \n    265 \n  \n  \n    R2 \n    0.001 \n    0.041 \n    0.015 \n    0.051 \n  \n  \n    R2 Adj. \n    −0.002 \n    0.007 \n    0.012 \n    0.018 \n  \n\n\n\n\n\n　傾向スコアマッチングでも正の処置効果（ATT）が確認され、今回は統計的に有意な結果が得られている。\n\n\nCEM\n　Coarsened Exact Matching（CEM）はマハラノビス最近傍マッチング同様、matchit()関数を使うが、事前に{cem}パッケージをインストールしておく必要がある（install.pacakges(\"cem\")）。\n　CEMのようなExact Matching類の手法は距離を図る必要がないので、distance引数は不要である。マッチング方法を指定するmethod引数はこれまで使ってきた\"nearest\"（最近傍）でなく、\"cem\"に替えよう。推定可能な処置効果はATE（最近傍マッチングでは指定できなかったもの）、ATT、ATCであるが、ここではATTを推定してみよう。\n　マッチングをしたらmatch.data()でマッチングされたデータを抽出する。\n\ncem_mat <- matchit(treat ~ age + educ + black + hispanic + married + \n                     nodegree + re74 + re75, data = la_df,\n                   method = \"cem\", estimand = \"ATT\")\n\n　つづいて、{cobalt}のlove.plot()を使用して、バランスチェックを行う。\n\nlove.plot(cem_mat, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　CEMの場合、（非復元）最近傍マッチングよりもバランスが大きく改善されることが分かる。その理由は簡単だ。最近傍マッチングの場合、最も近いケースであれば、どれほど離れていてもマッチングされる。一方、CEMは正確マッチングの一種であるため、ある程度離れているケースを捨ててしまうため、結局は共変量が非常に近いケースのみを残すことになります。\n　それでは、match.data()関数を使ってマッチング後のデータを抽出してみよう。\n\ncem_data <- match.data(cem_mat)\n\ncem_data\n\n# A tibble: 140 × 13\n   treat   age  educ black hispanic white married nodegree  re74  re75   re78\n   <int> <int> <int> <int>    <int> <int>   <int>    <int> <dbl> <dbl>  <dbl>\n 1     1    22     9     0        1     0       0        1     0     0  3596.\n 2     1    27    11     1        0     0       0        1     0     0  7506.\n 3     1    22     9     1        0     0       0        1     0     0  4056.\n 4     1    23    12     1        0     0       0        0     0     0     0 \n 5     1    22    16     1        0     0       0        0     0     0  2164.\n 6     1    19     9     1        0     0       0        1     0     0  8174.\n 7     1    21    13     1        0     0       0        0     0     0 17095.\n 8     1    18     8     1        0     0       0        1     0     0     0 \n 9     1    17     7     1        0     0       0        1     0     0  3024.\n10     1    19    10     1        0     0       0        1     0     0  3229.\n# … with 130 more rows, and 2 more variables: weights <dbl>, subclass <fct>\n\n\n　CEMの場合、マッチングされないブロックは捨てられるため、マハラノビス距離最近傍マッチングよりもサンプルサイズが小さくなりやすい。マッチング相手がなければ、たとえ処置群だとしても除外される。また、処置群と統制群のサンプルサイズも不均衡になる。マッチング結果を見ると、処置群からは65ケース、統制群からは75サンプルのみ残っている。\n\ncem_data |>\n  count(treat)\n\n# A tibble: 2 × 2\n  treat     n\n  <int> <int>\n1     0    75\n2     1    65\n\n\n　処置効果はこれまでの復元マッチングと同様、重み付き回帰分析で推定するｙ。ここでも共変量ありとなし、2パターンで推定してみよう。\n\ncem_fit1 <- lm(re78 ~ treat, \n               data = cem_data, weights = weights)\ncem_fit2 <- lm(re78 ~ treat + age + educ + black + hispanic +\n                 married + nodegree + re74 + re75, \n               data = cem_data, weights = weights)\n\nmodelsummary(list(\"MH (単回帰)\"   = mh_fit3,\n                  \"MH (重回帰)\"   = mh_fit4,\n                  \"PS (単回帰)\"   = ps_fit1,\n                  \"PS (重回帰)\"   = ps_fit2,\n                  \"CEM (単回帰)\"  = cem_fit1,\n                  \"CEM (重回帰)\"  = cem_fit2), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n \n  \n      \n    MH (単回帰) \n    MH (重回帰) \n    PS (単回帰) \n    PS (重回帰) \n    CEM (単回帰) \n    CEM (重回帰) \n  \n \n\n  \n    (Intercept) \n    5744.482 \n    1371.865 \n    4381.204 \n    −985.292 \n    5265.785 \n    −7253.717 \n  \n  \n     \n    (854.641) \n    (4808.980) \n    (811.618) \n    (4370.562) \n    (850.457) \n    (7031.576) \n  \n  \n    treat \n    604.661 \n    524.037 \n    1967.940 \n    1903.412 \n    1070.907 \n    1207.183 \n  \n  \n     \n    (1013.175) \n    (1011.417) \n    (971.379) \n    (975.164) \n    (1248.129) \n    (1245.959) \n  \n  \n    age \n     \n    8.365 \n     \n    42.898 \n     \n    147.970 \n  \n  \n     \n     \n    (64.228) \n     \n    (60.174) \n     \n    (107.716) \n  \n  \n    educ \n     \n    476.666 \n     \n    444.829 \n     \n    879.978 \n  \n  \n     \n     \n    (319.397) \n     \n    (278.130) \n     \n    (472.982) \n  \n  \n    black \n     \n    −1562.414 \n     \n    −893.748 \n     \n    −1941.465 \n  \n  \n     \n     \n    (1568.526) \n     \n    (1538.965) \n     \n    (2485.215) \n  \n  \n    hispanic \n     \n    −17.586 \n     \n    −184.643 \n     \n    437.208 \n  \n  \n     \n     \n    (2423.801) \n     \n    (2343.260) \n     \n    (4223.958) \n  \n  \n    married \n     \n    330.704 \n     \n    299.425 \n     \n    −3213.470 \n  \n  \n     \n     \n    (1285.183) \n     \n    (1292.304) \n     \n    (4445.151) \n  \n  \n    nodegree \n     \n    106.692 \n     \n    92.911 \n     \n    1779.900 \n  \n  \n     \n     \n    (1421.140) \n     \n    (1379.407) \n     \n    (2019.035) \n  \n  \n    re74 \n     \n    0.091 \n     \n    0.056 \n     \n    −0.262 \n  \n  \n     \n     \n    (0.134) \n     \n    (0.122) \n     \n    (0.601) \n  \n  \n    re75 \n     \n    0.193 \n     \n    0.160 \n     \n    2.034 \n  \n  \n     \n     \n    (0.208) \n     \n    (0.200) \n     \n    (0.883) \n  \n  \n    Num.Obs. \n    260 \n    260 \n    265 \n    265 \n    140 \n    140 \n  \n  \n    R2 \n    0.001 \n    0.041 \n    0.015 \n    0.051 \n    0.005 \n    0.079 \n  \n  \n    R2 Adj. \n    −0.002 \n    0.007 \n    0.012 \n    0.018 \n    −0.002 \n    0.015 \n  \n\n\n\n\n\n　推定の結果は、いずれも正であり、職業訓練は所得に正の影響を与えるという結果が得られている。しかし、いずれも標準誤差が非常に大きく、統計的に有意な結果は得られていない。"
  },
  {
    "objectID": "material/matching.html#ipw",
    "href": "material/matching.html#ipw",
    "title": "回帰分析とマッチング",
    "section": "IPW",
    "text": "IPW\n　最後に、{WeightIt}パッケージを使ってIPW推定を行ってみよう。このパッケージはこれまで使ってた{MatchIt}パッケージと非常に似ている。まず、第一引数として処置変数を結果変数、処置有無に影響を与えると考えられる共変量を説明変数とした回帰式を入れる。続いて、データ（data）、IPW算出の方法（method）、推定の対象（estimand）を指定する。データはdata = la_dfとし、傾向スコアからIPWを算出するためmethod = \"ps\"を指定、最後にATT推定のためにestimand = \"ATT\"を指定する。今回はIPW算出のために今回は傾向スコアを使うが、「処置を受ける確率」が計算できるなら何でも良い。たとえば、Imai and Ratkovic (2014)8が推奨しているCovariate Balancing Propensity Score (CBPS) を使用する場合は\"ps\"の代わりに\"cbps\"を、複数の推定を組み合わせるスーパーラーニングをする場合は\"super\"9などが使える。他にもエントロピーバランシングなど様々なオプションが提供されている。\n\nipw_data <- weightit(treat ~ age + educ + black + hispanic + \n                       married + nodegree + re74 + re75, \n                     data = la_df, method = \"ps\", estimand = \"ATT\")\n\n　matchit()とは違って、別途match.data()などの関数は不要である。weightit()パッケージを使うと、IPW推定のための重み変数を返してくれる。また、weightit()から得られたデータは{cobalt}でバランスチェックもできる。\n\nlove.plot(ipw_data, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　読み方は最近傍マッチング（傾向スコア）と同じである。ここでもバランスが大幅に改善されていることが分かる。\n　それではIPW推定量を計算してみよう。ここで一つ注意が必要だ。それはdataをipw_dataでなく、元のデータであるla_dfを使うという点だ。また、重み変数はla_dfには含まれていないため、ipw_data$weightsを使う必要がある。\n\nipw_fit1 <- lm(re78 ~ treat, \n               data = la_df, weights = ipw_data$weights)\nipw_fit2 <- lm(re78 ~ treat + age + educ + black + hispanic + \n                       married + nodegree + re74 + re75, \n               data = la_df, weights = ipw_data$weights)\n\nmodelsummary(list(\"MH (単)\"   = mh_fit3,\n                  \"MH (重)\"   = mh_fit4,\n                  \"PS (単)\"   = ps_fit1,\n                  \"PS (重)\"   = ps_fit2,\n                  \"CEM (単)\"  = cem_fit1,\n                  \"CEM (重)\"  = cem_fit2,\n                  \"IPW (単)\"  = ipw_fit1,\n                  \"IPW (重)\"  = ipw_fit2), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n \n  \n      \n    MH (単) \n    MH (重) \n    PS (単) \n    PS (重) \n    CEM (単) \n    CEM (重) \n    IPW (単) \n    IPW (重) \n  \n \n\n  \n    (Intercept) \n    5744.482 \n    1371.865 \n    4381.204 \n    −985.292 \n    5265.785 \n    −7253.717 \n    5135.072 \n    853.666 \n  \n  \n     \n    (854.641) \n    (4808.980) \n    (811.618) \n    (4370.562) \n    (850.457) \n    (7031.576) \n    (401.194) \n    (2708.329) \n  \n  \n    treat \n    604.661 \n    524.037 \n    1967.940 \n    1903.412 \n    1070.907 \n    1207.183 \n    1214.071 \n    1237.405 \n  \n  \n     \n    (1013.175) \n    (1011.417) \n    (971.379) \n    (975.164) \n    (1248.129) \n    (1245.959) \n    (568.904) \n    (554.929) \n  \n  \n    age \n     \n    8.365 \n     \n    42.898 \n     \n    147.970 \n     \n    −17.562 \n  \n  \n     \n     \n    (64.228) \n     \n    (60.174) \n     \n    (107.716) \n     \n    (33.570) \n  \n  \n    educ \n     \n    476.666 \n     \n    444.829 \n     \n    879.978 \n     \n    489.248 \n  \n  \n     \n     \n    (319.397) \n     \n    (278.130) \n     \n    (472.982) \n     \n    (172.550) \n  \n  \n    black \n     \n    −1562.414 \n     \n    −893.748 \n     \n    −1941.465 \n     \n    −1149.368 \n  \n  \n     \n     \n    (1568.526) \n     \n    (1538.965) \n     \n    (2485.215) \n     \n    (950.708) \n  \n  \n    hispanic \n     \n    −17.586 \n     \n    −184.643 \n     \n    437.208 \n     \n    202.126 \n  \n  \n     \n     \n    (2423.801) \n     \n    (2343.260) \n     \n    (4223.958) \n     \n    (1463.378) \n  \n  \n    married \n     \n    330.704 \n     \n    299.425 \n     \n    −3213.470 \n     \n    424.461 \n  \n  \n     \n     \n    (1285.183) \n     \n    (1292.304) \n     \n    (4445.151) \n     \n    (807.171) \n  \n  \n    nodegree \n     \n    106.692 \n     \n    92.911 \n     \n    1779.900 \n     \n    −92.470 \n  \n  \n     \n     \n    (1421.140) \n     \n    (1379.407) \n     \n    (2019.035) \n     \n    (844.246) \n  \n  \n    re74 \n     \n    0.091 \n     \n    0.056 \n     \n    −0.262 \n     \n    0.050 \n  \n  \n     \n     \n    (0.134) \n     \n    (0.122) \n     \n    (0.601) \n     \n    (0.078) \n  \n  \n    re75 \n     \n    0.193 \n     \n    0.160 \n     \n    2.034 \n     \n    0.318 \n  \n  \n     \n     \n    (0.208) \n     \n    (0.200) \n     \n    (0.883) \n     \n    (0.121) \n  \n  \n    Num.Obs. \n    260 \n    260 \n    265 \n    265 \n    140 \n    140 \n    614 \n    614 \n  \n  \n    R2 \n    0.001 \n    0.041 \n    0.015 \n    0.051 \n    0.005 \n    0.079 \n    0.007 \n    0.071 \n  \n  \n    R2 Adj. \n    −0.002 \n    0.007 \n    0.012 \n    0.018 \n    −0.002 \n    0.015 \n    0.006 \n    0.057 \n  \n\n\n\n\n\n　IPWの場合、正の処置効果（ATT）が確認され、今回は統計的に有意な結果が得られた。"
  },
  {
    "objectID": "material/matching.html#バランスチェック",
    "href": "material/matching.html#バランスチェック",
    "title": "回帰分析とマッチング",
    "section": "バランスチェック",
    "text": "バランスチェック\n　ここでは標準化差分以外のバランスチェック方法について紹介する。まず、特定の共変量の分布をヒストグラムを用い、マッチング前後で比較する方法だ。これもまた{coblat}パッケージを使用するが、今回はlove.plot()でなく、bal.plot()を使う。\n　第1引数はmatchit()から得られたオブジェクト名、続いてvar.nameにはバランスをチェックする共変量名（傾向スコアの場合は\"distance\"）、他は以下のコードの通りに打てばよい。\n\nbal.plot(ps_mat, var.name = \"distance\", which = \"both\",\n         type = \"histogram\", mirror = TRUE)\n\n\n\n\n\n\n\n\n　左がマッチング前、右が後である。また、上部の赤いヒストグラムは統制群、下部の青は処置群を意味する。もし、傾向スコアのバランスが取れているならヒストグラムは上下対称となる。マッチング前だと統制群は傾向スコアの値が小さく、処置群のそれは大きい傾向があったが、マッチング後はほぼ上下対称となっていることからバランスが改善されたことが分かる。\n　ちなみに、ヒストグラムが作成できないダミー変数の場合、棒グラフが表示される。読み方は同じであるが、今回は上下対称ではなく、赤い棒と青い棒の高さが一致すればバランスが取れていると確認できる。\n\nbal.plot(ps_mat, var.name = \"black\", which = \"both\",\n         type = \"histogram\", mirror = TRUE)\n\n\n\n\n\n\n\n\n　このようにヒストグラム（棒グラフ）を使うと、一つ一つの変数の図が必要となってくるので、実際の論文には掲載しにくい。それでも分析の段階では一つ一つのバランスを詳細に見ることは重要である。たとえば、傾向スコアマッチングの場合、回答者の年齢（age）のバランスは改善されている。本当にそうだろうか。ageのバランスを確認してみよう。\n\nbal.plot(ps_mat, var.name = \"age\", which = \"both\",\n         type = \"histogram\", mirror = TRUE)\n\n\n\n\n\n\n\n\n　改善ところか、改悪されているとも読み取れる。標準化差分は平均値と標準誤差のみに依存するため、分布の情報までは分からない。このような場合は、処置効果の推定の際、共変量を投入して更に調整が必要であることを示唆する。"
  },
  {
    "objectID": "material/matching.html#推定値の比較",
    "href": "material/matching.html#推定値の比較",
    "title": "回帰分析とマッチング",
    "section": "推定値の比較",
    "text": "推定値の比較\n　これまで見てきたように、同じく「マッチング」とは言っても手法によって結果のばらつきが大きいことが分かる。また、同じ手法であっても復元か、非復元か、1:1マッチングか、1:nマッチングか、CEMならレイヤーをどれほど細かくするかなどによっても結果は大きく変わる。\n　ここまで得られた多くの結果から自分にとって都合の良い結果のみを報告するのは、あるいみ研究不正に近い。なぜなら、これを逆にいうと自分にとって都合の悪い結果を隠蔽しているものだからだ。したがって、実際の論文にはそれぞれの結果を報告・比較し、その結果を慎重に解釈する必要がある。ここではこれまで推定してきたマッチングの結果を一つの図としてまとめてみよう。\n　まずは、{broom}パッケージのtidy()関数で回帰分析の結果を表でまとめ、bind_rows()を使って一つに統合する。tidy()内にconf.int = TRUEを入れておくと、95%信頼区間も出してくれるので、今の段階で入れておこう。\n\natt_df <- bind_rows(list(\"単回帰_最近傍（マハラノビス）\" = tidy(mh_fit3, conf.int = TRUE),\n                         \"重回帰_最近傍（マハラノビス）\" = tidy(mh_fit4, conf.int = TRUE),\n                         \"単回帰_最近傍（傾向スコア）\"   = tidy(ps_fit1, conf.int = TRUE),\n                         \"重回帰_最近傍（傾向スコア）\"   = tidy(ps_fit2, conf.int = TRUE),\n                         \"単回帰_CEM\" = tidy(cem_fit1, conf.int = TRUE),\n                         \"重回帰_CEM\" = tidy(cem_fit2, conf.int = TRUE),\n                         \"単回帰_IPW\" = tidy(ipw_fit1, conf.int = TRUE),\n                         \"重回帰_IPW\" = tidy(ipw_fit2, conf.int = TRUE)),\n                    .id = \"Model\")\n\natt_df\n\n# A tibble: 48 × 8\n   Model                term   estim…¹ std.e…² statis…³  p.value conf.…⁴ conf.…⁵\n   <chr>                <chr>    <dbl>   <dbl>    <dbl>    <dbl>   <dbl>   <dbl>\n 1 単回帰_最近傍（マハ… (Inte…  5.74e3   855.   6.72    1.15e-10   4062.   7427.\n 2 単回帰_最近傍（マハ… treat   6.05e2  1013.   0.597   5.51e- 1  -1390.   2600.\n 3 重回帰_最近傍（マハ… (Inte…  1.37e3  4809.   0.285   7.76e- 1  -8099.  10843.\n 4 重回帰_最近傍（マハ… treat   5.24e2  1011.   0.518   6.05e- 1  -1468.   2516.\n 5 重回帰_最近傍（マハ… age     8.36e0    64.2  0.130   8.96e- 1   -118.    135.\n 6 重回帰_最近傍（マハ… educ    4.77e2   319.   1.49    1.37e- 1   -152.   1106.\n 7 重回帰_最近傍（マハ… black  -1.56e3  1569.  -0.996   3.20e- 1  -4652.   1527.\n 8 重回帰_最近傍（マハ… hispa… -1.76e1  2424.  -0.00726 9.94e- 1  -4791.   4756.\n 9 重回帰_最近傍（マハ… marri…  3.31e2  1285.   0.257   7.97e- 1  -2200.   2862.\n10 重回帰_最近傍（マハ… nodeg…  1.07e2  1421.   0.0751  9.40e- 1  -2692.   2906.\n# … with 38 more rows, and abbreviated variable names ¹​estimate, ²​std.error,\n#   ³​statistic, ⁴​conf.low, ⁵​conf.high\n\n\n　続いて、処置効果（ATT）を意味する行のみを残す。termの値が\"treat\"と一致する行が処置効果である。\n\natt_df <- att_df |>\n  filter(term == \"treat\")\n\natt_df\n\n# A tibble: 8 × 8\n  Model                    term  estim…¹ std.e…² stati…³ p.value conf.…⁴ conf.…⁵\n  <chr>                    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 単回帰_最近傍（マハラノ… treat    605.   1013.   0.597  0.551  -1390.    2600.\n2 重回帰_最近傍（マハラノ… treat    524.   1011.   0.518  0.605  -1468.    2516.\n3 単回帰_最近傍（傾向スコ… treat   1968.    971.   2.03   0.0438    55.3   3881.\n4 重回帰_最近傍（傾向スコ… treat   1903.    975.   1.95   0.0520   -17.0   3824.\n5 単回帰_CEM               treat   1071.   1248.   0.858  0.392  -1397.    3539.\n6 重回帰_CEM               treat   1207.   1246.   0.969  0.334  -1258.    3672.\n7 単回帰_IPW               treat   1214.    569.   2.13   0.0332    96.8   2331.\n8 重回帰_IPW               treat   1237.    555.   2.23   0.0261   148.    2327.\n# … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic,\n#   ⁴​conf.low, ⁵​conf.high\n\n\n　ここでは新しく登場した関数を使用する。separate()関数は文字列で構成されている列を、特定の文字を基準に列分割する関数である。Model行のそれぞれの値は回帰モデル_マッチングモデルで構成され、これを_文字を基準にRegressionとMethod列に分割する。分割する列名はcol、分割後の列名はinto、分割の基準となる文字はsepに指定する。\n\natt_df <- att_df |>\n  separate(col  = Model,\n           into = c(\"Regression\", \"Method\"),\n           sep  = \"_\")\n\natt_df\n\n# A tibble: 8 × 9\n  Regression Method        term  estim…¹ std.e…² stati…³ p.value conf.…⁴ conf.…⁵\n  <chr>      <chr>         <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 単回帰     最近傍（マハ… treat    605.   1013.   0.597  0.551  -1390.    2600.\n2 重回帰     最近傍（マハ… treat    524.   1011.   0.518  0.605  -1468.    2516.\n3 単回帰     最近傍（傾向… treat   1968.    971.   2.03   0.0438    55.3   3881.\n4 重回帰     最近傍（傾向… treat   1903.    975.   1.95   0.0520   -17.0   3824.\n5 単回帰     CEM           treat   1071.   1248.   0.858  0.392  -1397.    3539.\n6 重回帰     CEM           treat   1207.   1246.   0.969  0.334  -1258.    3672.\n7 単回帰     IPW           treat   1214.    569.   2.13   0.0332    96.8   2331.\n8 重回帰     IPW           treat   1237.    555.   2.23   0.0261   148.    2327.\n# … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic,\n#   ⁴​conf.low, ⁵​conf.high\n\n\n　後はこのデータを使って作図するだけである。データをggplot()に渡す前にRegressionとMethod列をfactor化しておこう。\n\natt_df |>\n  mutate(Regression = fct_inorder(Regression),\n         Method     = fct_inorder(Method)) |>\n  ggplot() +\n  geom_pointrange(aes(x = estimate, y = Method,\n                      xmin = conf.low, xmax = conf.high,\n                      color = Regression),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"処置群における処置効果（ATT）\", y = \"\", color = \"モデル\",\n       caption = \"注: マッチングの場合、復元マッチングを行った。\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\n　もし、縦軸の順番を逆にしたい場合は、fct_rev()関数で要素の順番を逆にする。\n\natt_df |>\n  mutate(Regression = fct_inorder(Regression),\n         Method     = fct_inorder(Method),\n         Method     = fct_rev(Method)) |>\n  ggplot() +\n  geom_vline(xintercept = 0) +\n  geom_pointrange(aes(x = estimate, y = Method,\n                      xmin = conf.low, xmax = conf.high,\n                      color = Regression),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"処置群における処置効果（ATT）\", y = \"\", color = \"モデル\",\n       caption = \"注: マッチングの場合、復元マッチングを行った。\") +\n  theme_bw(base_size = 12)"
  }
]